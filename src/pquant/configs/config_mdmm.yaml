# file: /src/pquant/configs/config_mdmm.yaml

pruning_parameters:
  pruning_method: mdmm
  enable_pruning: true
  disable_pruning_for_layers:
    - 
  constraint_type: "Equality"
  target_value: 0.0
  metric_type: "UnstructuredSparsity"
  target_sparsity: 0.9
  rf: 1
  epsilon: 1.0e-03
  scale: 50.0
  damping: 1.0
  use_grad: false 
  l0_mode: "coarse" # 'coarse' or 'smooth'

quantization_parameters:
  enable_quantization: false
  default_integer_bits: 0.
  default_fractional_bits: 7.
  hgq_gamma: 0.0003
  hgq_heterogeneous: True
  layer_specific: []
  use_high_granularity_quantization: false
  use_real_tanh: false
  use_symmetric_quantization: false

training_parameters:
  epochs: 1000
  fine_tuning_epochs: 30
  pretraining_epochs: 0
  pruning_first: false
  rewind: never
  rounds: 1
  save_weights_epoch: -1
batch_size: 128
cosine_tmax: 200
gamma: 0.1
l2_decay: 0.0001
label_smoothing: 0.0
lr: 0.001
lr_schedule: multistep
milestones:
- 75
- 120
momentum: 0.9
optimizer: sgd
plot_frequency: 100

# Note: 
# use_grad: true is having some bug... flip gradient impl not working as intended
# Confirmed: grad for both 'coarse' or 'smooth' are non None
