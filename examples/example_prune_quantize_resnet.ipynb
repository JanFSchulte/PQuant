{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5676e100-c255-4871-b167-01a788309112",
   "metadata": {},
   "source": [
    "## In this tutorial we create a CNN and dataloaders, and train / prune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27cf8b22-eca4-48eb-8343-1dc144ee5737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (0.23.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: numpy in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.8.0 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torchvision) (2.8.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (10.3.9.90)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (3.4.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (12.8.93)\n",
      "Requirement already satisfied: networkx in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (12.8.90)\n",
      "Requirement already satisfied: fsspec in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (2025.9.0)\n",
      "Requirement already satisfied: filelock in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (3.19.1)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (0.7.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (2.27.3)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (1.13.1.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (9.10.2.21)\n",
      "Requirement already satisfied: jinja2 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from torch==2.8.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from triton==3.4.0->torch==2.8.0->torchvision) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from sympy>=1.13.3->torch==2.8.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from jinja2->torch==2.8.0->torchvision) (3.0.3)\n",
      "Requirement already satisfied: matplotlib in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (3.10.6)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/jschulte/.conda/envs/pquant-tutorial/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27197caf-85a2-48b7-af76-a5ff943408ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\" # Needs to be set, some pruning layers as well as the quantizers are Keras\n",
    "import keras\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "keras.backend.set_image_data_format(\"channels_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ea5a763-a029-495d-a03a-390048d749f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet18()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c72d3-05c8-4c68-a87c-fb0ee8570ee8",
   "metadata": {},
   "source": [
    "## Add pruning and quantization\n",
    "![Layer replacement](images/replace_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd31d4a-5246-47d0-9426-32113265d787",
   "metadata": {},
   "source": [
    "To add pruning and quantization, we need a config file that defines how to do that. Let's load a config file from pquant/configs/configs_pdp.yaml. The training function we use later will add the pruning layers and quantized activations automatically using this config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec145f1-502c-4fd0-84ed-e87b84a27374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pquant import get_default_config\n",
    "\n",
    "# pruning_methods: \"autosparse, cl, cs, dst, mdmm, pdp, wanda\"\n",
    "pruning_method = \"pdp\"\n",
    "config = get_default_config(pruning_method)\n",
    "# Set target sparsity to 80% (20% of weights are non-zero). This parameter exists only for some pruning methods\n",
    "config[\"pruning_parameters\"][\"sparsity\"] = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3ef3115-2f3d-43e1-a199-4a19d667f796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): CompressedLayerConv2d(\n",
       "    (pruning_layer): <PDP name=pdp, built=True>\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): <QuantizedReLU name=quantized_re_lu, built=True>\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <PDP name=pdp_1, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): <QuantizedReLU name=quantized_re_lu_1, built=True>\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <PDP name=pdp_2, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <PDP name=pdp_3, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): <QuantizedReLU name=quantized_re_lu_2, built=True>\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <PDP name=pdp_4, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <PDP name=pdp_5, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): <QuantizedReLU name=quantized_re_lu_3, built=True>\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <PDP name=pdp_6, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): CompressedLayerConv2d(\n",
       "          (pruning_layer): <PDP name=pdp_7, built=True>\n",
       "        )\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <PDP name=pdp_8, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): <QuantizedReLU name=quantized_re_lu_4, built=True>\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <PDP name=pdp_9, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <PDP name=pdp_10, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): <QuantizedReLU name=quantized_re_lu_5, built=True>\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <PDP name=pdp_11, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): CompressedLayerConv2d(\n",
       "          (pruning_layer): <PDP name=pdp_12, built=True>\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <PDP name=pdp_13, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): <QuantizedReLU name=quantized_re_lu_6, built=True>\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <PDP name=pdp_14, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <PDP name=pdp_15, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): <QuantizedReLU name=quantized_re_lu_7, built=True>\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <PDP name=pdp_16, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): CompressedLayerConv2d(\n",
       "          (pruning_layer): <PDP name=pdp_17, built=True>\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <PDP name=pdp_18, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): <QuantizedReLU name=quantized_re_lu_8, built=True>\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <PDP name=pdp_19, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): CompressedLayerLinear(\n",
       "    (pruning_layer): <PDP name=pdp_20, built=True>\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace layers with compressed layers\n",
    "from pquant import add_compression_layers\n",
    "input_shape = (256,3,32,32)\n",
    "model = add_compression_layers(model, config, input_shape)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a7241c-0ebd-492c-b4d4-3b269e5afc4d",
   "metadata": {},
   "source": [
    "## Pruning and quantization in the config\n",
    "From the config we see that we are using the PDP pruning method, unstructured version. We aim for 80% weights pruned (sparsity 0.8), and we quantize the model to 8 bits (1 bit goes to sign). \n",
    "By default, all convolutional and linear layers, as well as activations will be quantized using the default values ```default_integer_bits``` and ```default_fractional_bits```. Similarly, by default all convolutional and linear layers will be pruned.\n",
    "\n",
    "What is in a config? The config consists of 3 main parts: the `pruning_parameters`, the `quantization_parameters` and the `training_parameters`. The parameters outside of these at the end are values mostly related to optimizers and schedulers used in testing with a ResNet. They will be removed in the future, we don't have to worry about them. \n",
    "\n",
    "![Config example](images/config_example.png)\n",
    "\n",
    "The `pruning_parameters` are different for each pruning algorithm, and they are explained in more detail [here](https://github.com/nroope/PQuant/blob/dev/docs/pruning_methods.md). \n",
    "\n",
    "The `quantization_parameters` are explained [here](https://github.com/nroope/PQuant/blob/dev/docs/quantization_parameters.md) \n",
    "\n",
    "The `training_parameters`:\n",
    "\n",
    "Hyperparameters related to the training loop. The training loop has 3 possible stages: pretraining, training, fine-tuning. Generally speaking, during pretraining, no pruning is done, and for HGQ no loss is calculated. During training, pruning is done and HGQ loss calculated. During fine-tuning, the pruning mask is fixed and rounded to 0s and 1s. Quantization is done in all 3 stages.\n",
    "\n",
    "![Training stages](images/training_loop.png)\n",
    "\n",
    "If `pruning_first` is true, run pruning before quantization, else quantize first. `rewind`, `rounds` and `save_weights_epoch` are related to multi-round training (CS pruning method). `rounds` sets the number of training rounds of length `epochs`, `save_weights_epoch` sets the epoch at the first round at which to save the weights as a checkpoint. \n",
    "\n",
    "`rewind` defines when to reset the weights to the saved weights checkpoint, and it has 3 possible settings: \n",
    "  \n",
    "   - `rounds` resets the weights back to the checkpoint after each round, \n",
    "   - `post-ticket-search` resets the weights only after all the rounds are finished\n",
    "   - `never` never resets the weights\n",
    "\n",
    "\n",
    "We'll show later how to create a custom quantization / pruning config file from an existing config for a given model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bf6ec9-9fb3-4f56-bffc-8676341cde32",
   "metadata": {},
   "source": [
    "## About the different epochs\n",
    "\n",
    "The config above defines 20 ```pretraining_epochs```, 100 ```epochs``` and 20 ```fine_tuning_epochs```. What stages are used and what happens during each stage is pruning algorithm specific.\n",
    "\n",
    "![Pruning method stages](images/pruning_method_stages.png)\n",
    "\n",
    "In PDP, the pretraining phase consists of training without pruning, followed by calculation of layerwise pruning budgets. After pretraining is finished and the layerwise pruning budgets have been calculated, the training with pruning begins. The mask during this training is a soft mask, consisting of values ranging between (and including) 0 and 1. \n",
    "\n",
    "The fine-tuning step in PDP is optional (not mentioned in the original paper), and during it the mask is fixed and rounded to 0s and 1s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251515c3-00ac-4110-b8d8-a8c9100f6e6b",
   "metadata": {},
   "source": [
    "## Create data set\n",
    "#### Let's create the data loader and the training and validation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90c24bff-9937-4670-8cff-022ddc7a0aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 170M/170M [00:02<00:00, 59.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def get_cifar10_data(batch_size):\n",
    "    normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    train_transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), \n",
    "                                          transforms.ToTensor(), normalize])\n",
    "    test_transform = transforms.Compose([transforms.ToTensor(), normalize])  \n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "    valset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                       download=True, transform=test_transform)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "from quantizers.fixed_point.fixed_point_ops import get_fixed_quantizer\n",
    "# Set up input quantizer\n",
    "quantizer = get_fixed_quantizer(overflow_mode=\"SAT\")\n",
    "\n",
    "\n",
    "def train_resnet(model, trainloader, device, loss_func, epoch, optimizer, scheduler, *args, **kwargs):\n",
    "    for data in trainloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        inputs = quantizer(inputs, k=torch.tensor(1.), i=torch.tensor(0.), f=torch.tensor(7.)) # 8 bits input quantization (1 bit for sign)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        losses = get_model_losses(model, torch.tensor(0.).to(device))\n",
    "        loss += losses\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch += 1\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "from pquant import get_layer_keep_ratio, get_model_losses\n",
    "\n",
    "def validate_resnet(model, testloader, device, loss_func, epoch, *args, **kwargs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs = quantizer(inputs, k=torch.tensor(1.), i=torch.tensor(0.), f=torch.tensor(7.)) # 8 bits input quantization (1 bit for sign)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        ratio = get_layer_keep_ratio(model)\n",
    "        print(f'Accuracy: {100 * correct / total:.2f}%, remaining_weights: {ratio * 100:.2f}%')\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "train_loader, val_loader = get_cifar10_data(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3794868-9103-47cd-9baf-4cbcd703115a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d28865b-afdb-4773-be30-717486d9786a",
   "metadata": {},
   "source": [
    "## Create loss function, scheduler and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f88af88-ef7a-4d30-8cff-f39225d5a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0001, momentum=0.9)\n",
    "scheduler = CosineAnnealingLR(optimizer, 200)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850c23a-2abc-4904-9c69-859492b450a8",
   "metadata": {},
   "source": [
    "## Train model\n",
    "Training time. We use the train_compressed_model function from pquant to train. We need to provide some parameters such as training and validation functions, their input parameters, the model and the config file. The function automatically adds pruning layers and replaces activations with a quantized variant, trains the model, and removes the pruning layers after training is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18f2414c-1f4d-4a30-a143-920497e60ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp, built=True>\n",
      ") target: 0.7766793966293335\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_1, built=True>\n",
      ") target: 0.3998752236366272\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_2, built=True>\n",
      ") target: 0.4004177451133728\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_3, built=True>\n",
      ") target: 0.4018012285232544\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_4, built=True>\n",
      ") target: 0.4080946147441864\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_5, built=True>\n",
      ") target: 0.5405002236366272\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_6, built=True>\n",
      ") target: 0.5403984785079956\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_7, built=True>\n",
      ") target: 0.1947021484375\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_8, built=True>\n",
      ") target: 0.5427585244178772\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_9, built=True>\n",
      ") target: 0.54095458984375\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_10, built=True>\n",
      ") target: 0.7064955234527588\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_11, built=True>\n",
      ") target: 0.7062191367149353\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_12, built=True>\n",
      ") target: 0.272735595703125\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_13, built=True>\n",
      ") target: 0.7059953808784485\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_14, built=True>\n",
      ") target: 0.7058733105659485\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_15, built=True>\n",
      ") target: 0.8619266152381897\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_16, built=True>\n",
      ") target: 0.8625348210334778\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_17, built=True>\n",
      ") target: 0.3791961669921875\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_18, built=True>\n",
      ") target: 0.8626658320426941\n",
      "PDP Layer CompressedLayerConv2d(\n",
      "  (pruning_layer): <PDP name=pdp_19, built=True>\n",
      ") target: 0.8621224164962769\n",
      "PDP Layer CompressedLayerLinear(\n",
      "  (pruning_layer): <PDP name=pdp_20, built=True>\n",
      ") target: 0.6996309161186218\n",
      "Accuracy: 32.76%, remaining_weights: 86.35%\n",
      "Accuracy: 41.27%, remaining_weights: 86.12%\n",
      "Accuracy: 47.17%, remaining_weights: 85.98%\n",
      "Accuracy: 53.28%, remaining_weights: 85.86%\n",
      "Accuracy: 55.14%, remaining_weights: 85.76%\n",
      "Accuracy: 57.29%, remaining_weights: 85.66%\n",
      "Accuracy: 50.06%, remaining_weights: 85.57%\n",
      "Accuracy: 51.52%, remaining_weights: 85.49%\n",
      "Accuracy: 63.30%, remaining_weights: 85.41%\n",
      "Accuracy: 63.78%, remaining_weights: 85.33%\n",
      "Accuracy: 36.25%, remaining_weights: 85.25%\n",
      "Accuracy: 66.84%, remaining_weights: 85.11%\n",
      "Accuracy: 60.67%, remaining_weights: 84.63%\n",
      "Accuracy: 60.38%, remaining_weights: 84.26%\n",
      "Accuracy: 67.54%, remaining_weights: 84.01%\n",
      "Accuracy: 65.33%, remaining_weights: 83.77%\n",
      "Accuracy: 65.36%, remaining_weights: 83.60%\n",
      "Accuracy: 69.00%, remaining_weights: 83.45%\n",
      "Accuracy: 69.95%, remaining_weights: 83.30%\n",
      "Accuracy: 72.74%, remaining_weights: 83.17%\n",
      "Accuracy: 63.54%, remaining_weights: 83.03%\n",
      "Accuracy: 74.30%, remaining_weights: 82.91%\n",
      "Accuracy: 76.52%, remaining_weights: 82.79%\n",
      "Accuracy: 77.92%, remaining_weights: 82.69%\n",
      "Accuracy: 73.59%, remaining_weights: 82.58%\n",
      "Accuracy: 76.39%, remaining_weights: 82.48%\n",
      "Accuracy: 26.68%, remaining_weights: 81.58%\n",
      "Accuracy: 80.45%, remaining_weights: 81.45%\n",
      "Accuracy: 63.59%, remaining_weights: 81.32%\n",
      "Accuracy: 68.82%, remaining_weights: 81.14%\n",
      "Accuracy: 80.81%, remaining_weights: 80.72%\n",
      "Accuracy: 80.72%, remaining_weights: 80.12%\n",
      "Accuracy: 82.62%, remaining_weights: 78.01%\n",
      "Accuracy: 80.96%, remaining_weights: 77.71%\n",
      "Accuracy: 12.27%, remaining_weights: 58.94%\n",
      "Accuracy: 80.68%, remaining_weights: 58.80%\n",
      "Accuracy: 82.07%, remaining_weights: 58.62%\n",
      "Accuracy: 78.31%, remaining_weights: 58.45%\n",
      "Accuracy: 80.73%, remaining_weights: 58.24%\n",
      "Accuracy: 80.04%, remaining_weights: 58.05%\n",
      "Accuracy: 78.80%, remaining_weights: 57.87%\n",
      "Accuracy: 76.79%, remaining_weights: 57.63%\n",
      "Accuracy: 78.30%, remaining_weights: 57.40%\n",
      "Accuracy: 77.86%, remaining_weights: 57.09%\n",
      "Accuracy: 78.39%, remaining_weights: 56.72%\n",
      "Accuracy: 77.14%, remaining_weights: 55.21%\n",
      "Accuracy: 76.43%, remaining_weights: 54.02%\n",
      "Accuracy: 70.02%, remaining_weights: 53.81%\n",
      "Accuracy: 76.05%, remaining_weights: 53.62%\n",
      "Accuracy: 49.32%, remaining_weights: 53.32%\n",
      "Accuracy: 61.05%, remaining_weights: 53.08%\n",
      "Accuracy: 65.56%, remaining_weights: 50.83%\n",
      "Accuracy: 66.33%, remaining_weights: 37.89%\n",
      "Accuracy: 65.84%, remaining_weights: 37.64%\n",
      "Accuracy: 62.89%, remaining_weights: 37.34%\n",
      "Accuracy: 70.07%, remaining_weights: 37.07%\n",
      "Accuracy: 69.88%, remaining_weights: 36.74%\n",
      "Accuracy: 67.92%, remaining_weights: 36.48%\n",
      "Accuracy: 61.60%, remaining_weights: 35.64%\n",
      "Accuracy: 70.87%, remaining_weights: 35.05%\n",
      "Accuracy: 68.05%, remaining_weights: 34.86%\n",
      "Accuracy: 66.59%, remaining_weights: 34.59%\n",
      "Accuracy: 67.47%, remaining_weights: 33.16%\n",
      "Accuracy: 41.19%, remaining_weights: 32.65%\n",
      "Accuracy: 70.54%, remaining_weights: 23.85%\n",
      "Accuracy: 68.69%, remaining_weights: 22.84%\n",
      "Accuracy: 68.84%, remaining_weights: 22.55%\n",
      "Accuracy: 69.61%, remaining_weights: 22.46%\n",
      "Accuracy: 74.02%, remaining_weights: 22.38%\n",
      "Accuracy: 72.17%, remaining_weights: 22.31%\n",
      "Accuracy: 72.62%, remaining_weights: 22.24%\n",
      "Accuracy: 73.04%, remaining_weights: 22.23%\n",
      "Accuracy: 73.84%, remaining_weights: 22.95%\n",
      "Accuracy: 75.67%, remaining_weights: 22.81%\n",
      "Accuracy: 77.07%, remaining_weights: 22.87%\n",
      "Accuracy: 75.66%, remaining_weights: 22.78%\n",
      "Accuracy: 74.77%, remaining_weights: 22.73%\n",
      "Accuracy: 76.79%, remaining_weights: 22.70%\n",
      "Accuracy: 77.43%, remaining_weights: 22.65%\n",
      "Accuracy: 75.98%, remaining_weights: 22.59%\n",
      "Accuracy: 76.06%, remaining_weights: 22.54%\n",
      "Accuracy: 76.45%, remaining_weights: 22.49%\n",
      "Accuracy: 77.85%, remaining_weights: 22.43%\n",
      "Accuracy: 77.05%, remaining_weights: 22.38%\n",
      "Accuracy: 75.89%, remaining_weights: 22.33%\n",
      "Accuracy: 76.19%, remaining_weights: 22.28%\n",
      "Accuracy: 77.83%, remaining_weights: 22.23%\n",
      "Accuracy: 58.27%, remaining_weights: 22.18%\n",
      "Accuracy: 78.67%, remaining_weights: 22.13%\n",
      "Accuracy: 73.75%, remaining_weights: 22.08%\n",
      "Accuracy: 78.18%, remaining_weights: 22.04%\n",
      "Accuracy: 78.89%, remaining_weights: 21.99%\n",
      "Accuracy: 76.80%, remaining_weights: 21.94%\n",
      "Accuracy: 77.70%, remaining_weights: 21.89%\n",
      "Accuracy: 76.04%, remaining_weights: 21.85%\n",
      "Accuracy: 79.04%, remaining_weights: 21.81%\n",
      "Accuracy: 79.85%, remaining_weights: 21.80%\n",
      "Accuracy: 80.78%, remaining_weights: 21.76%\n",
      "Accuracy: 80.38%, remaining_weights: 21.72%\n",
      "Accuracy: 75.05%, remaining_weights: 21.64%\n",
      "Accuracy: 76.48%, remaining_weights: 21.64%\n",
      "Accuracy: 76.91%, remaining_weights: 21.64%\n",
      "Accuracy: 75.04%, remaining_weights: 21.64%\n",
      "Accuracy: 71.69%, remaining_weights: 21.64%\n",
      "Accuracy: 57.40%, remaining_weights: 21.64%\n",
      "Accuracy: 78.22%, remaining_weights: 21.64%\n",
      "Accuracy: 72.30%, remaining_weights: 21.64%\n",
      "Accuracy: 65.53%, remaining_weights: 21.64%\n",
      "Accuracy: 68.86%, remaining_weights: 21.64%\n",
      "Accuracy: 82.02%, remaining_weights: 21.64%\n",
      "Accuracy: 76.60%, remaining_weights: 21.64%\n",
      "Accuracy: 78.64%, remaining_weights: 21.64%\n",
      "Accuracy: 82.72%, remaining_weights: 21.64%\n",
      "Accuracy: 80.02%, remaining_weights: 21.64%\n",
      "Accuracy: 78.79%, remaining_weights: 21.64%\n",
      "Accuracy: 75.65%, remaining_weights: 21.64%\n",
      "Accuracy: 63.08%, remaining_weights: 21.64%\n",
      "Accuracy: 82.76%, remaining_weights: 21.64%\n",
      "Accuracy: 78.61%, remaining_weights: 21.64%\n",
      "Accuracy: 83.53%, remaining_weights: 21.64%\n",
      "Accuracy: 84.40%, remaining_weights: 21.64%\n",
      "Accuracy: 84.19%, remaining_weights: 21.64%\n",
      "Accuracy: 76.50%, remaining_weights: 21.64%\n",
      "Accuracy: 79.38%, remaining_weights: 21.64%\n",
      "Accuracy: 82.34%, remaining_weights: 21.64%\n",
      "Accuracy: 84.69%, remaining_weights: 21.64%\n",
      "Accuracy: 73.21%, remaining_weights: 21.64%\n",
      "Accuracy: 83.58%, remaining_weights: 21.64%\n",
      "Accuracy: 78.94%, remaining_weights: 21.64%\n",
      "Accuracy: 83.78%, remaining_weights: 21.64%\n",
      "Accuracy: 80.34%, remaining_weights: 21.64%\n",
      "Accuracy: 71.59%, remaining_weights: 21.64%\n",
      "Accuracy: 83.76%, remaining_weights: 21.64%\n",
      "Accuracy: 80.49%, remaining_weights: 21.64%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.54%, remaining_weights: 21.64%\n",
      "Accuracy: 74.44%, remaining_weights: 21.64%\n",
      "Accuracy: 79.93%, remaining_weights: 21.64%\n",
      "Accuracy: 82.03%, remaining_weights: 21.64%\n",
      "Accuracy: 77.36%, remaining_weights: 21.64%\n",
      "Accuracy: 87.12%, remaining_weights: 21.64%\n",
      "Accuracy: 78.65%, remaining_weights: 21.64%\n",
      "Accuracy: 84.11%, remaining_weights: 21.64%\n",
      "Accuracy: 86.73%, remaining_weights: 21.64%\n",
      "Accuracy: 85.49%, remaining_weights: 21.64%\n",
      "Accuracy: 87.27%, remaining_weights: 21.64%\n",
      "Accuracy: 63.98%, remaining_weights: 21.64%\n",
      "Accuracy: 81.54%, remaining_weights: 21.64%\n",
      "Accuracy: 84.81%, remaining_weights: 21.64%\n",
      "Accuracy: 83.44%, remaining_weights: 21.64%\n",
      "Accuracy: 86.32%, remaining_weights: 21.64%\n",
      "Accuracy: 84.12%, remaining_weights: 21.64%\n",
      "Accuracy: 80.88%, remaining_weights: 21.64%\n",
      "Accuracy: 85.86%, remaining_weights: 21.64%\n",
      "Accuracy: 70.96%, remaining_weights: 21.64%\n",
      "Accuracy: 86.82%, remaining_weights: 21.63%\n",
      "Accuracy: 80.41%, remaining_weights: 21.63%\n",
      "Accuracy: 80.67%, remaining_weights: 21.63%\n",
      "Accuracy: 88.74%, remaining_weights: 21.63%\n",
      "Accuracy: 81.27%, remaining_weights: 21.63%\n",
      "Accuracy: 86.62%, remaining_weights: 21.63%\n",
      "Accuracy: 80.03%, remaining_weights: 21.63%\n",
      "Accuracy: 80.28%, remaining_weights: 21.63%\n",
      "Accuracy: 87.43%, remaining_weights: 21.63%\n",
      "Accuracy: 88.18%, remaining_weights: 21.63%\n",
      "Accuracy: 87.51%, remaining_weights: 21.63%\n",
      "Accuracy: 82.97%, remaining_weights: 21.63%\n",
      "Accuracy: 86.41%, remaining_weights: 21.63%\n",
      "Accuracy: 77.27%, remaining_weights: 21.63%\n",
      "Accuracy: 89.03%, remaining_weights: 21.63%\n",
      "Accuracy: 89.23%, remaining_weights: 21.63%\n",
      "Accuracy: 73.44%, remaining_weights: 21.63%\n",
      "Accuracy: 75.17%, remaining_weights: 21.63%\n",
      "Accuracy: 79.58%, remaining_weights: 21.63%\n",
      "Accuracy: 87.74%, remaining_weights: 21.63%\n",
      "Accuracy: 83.70%, remaining_weights: 21.63%\n",
      "Accuracy: 83.90%, remaining_weights: 21.63%\n",
      "Accuracy: 80.96%, remaining_weights: 21.63%\n",
      "Accuracy: 70.77%, remaining_weights: 21.63%\n",
      "Accuracy: 89.85%, remaining_weights: 21.63%\n",
      "Accuracy: 75.21%, remaining_weights: 21.63%\n",
      "Accuracy: 85.48%, remaining_weights: 21.63%\n",
      "Accuracy: 84.44%, remaining_weights: 21.63%\n",
      "Accuracy: 86.05%, remaining_weights: 21.63%\n",
      "Accuracy: 86.87%, remaining_weights: 21.63%\n",
      "Accuracy: 84.56%, remaining_weights: 21.63%\n",
      "Accuracy: 88.18%, remaining_weights: 21.63%\n",
      "Accuracy: 87.07%, remaining_weights: 21.63%\n",
      "Accuracy: 84.66%, remaining_weights: 21.63%\n",
      "Accuracy: 89.92%, remaining_weights: 21.63%\n",
      "Accuracy: 89.95%, remaining_weights: 21.63%\n",
      "Accuracy: 85.23%, remaining_weights: 21.63%\n",
      "Accuracy: 86.84%, remaining_weights: 21.63%\n",
      "Accuracy: 74.14%, remaining_weights: 21.63%\n",
      "Accuracy: 89.14%, remaining_weights: 21.63%\n",
      "Accuracy: 86.41%, remaining_weights: 21.63%\n",
      "Accuracy: 90.09%, remaining_weights: 21.63%\n",
      "Accuracy: 89.78%, remaining_weights: 21.63%\n",
      "Accuracy: 79.82%, remaining_weights: 21.63%\n",
      "Accuracy: 90.05%, remaining_weights: 21.63%\n",
      "Accuracy: 88.26%, remaining_weights: 21.63%\n"
     ]
    }
   ],
   "source": [
    "from pquant import iterative_train\n",
    "\"\"\"\n",
    "Inputs to train_resnet we defined previously are:\n",
    "          model, trainloader, device, loss_func, epoch, optimizer, scheduler, **kwargs\n",
    "\"\"\"\n",
    "\n",
    "trained_model = iterative_train(model = model, \n",
    "                                config = config, \n",
    "                                train_func = train_resnet, \n",
    "                                valid_func = validate_resnet, \n",
    "                                trainloader = train_loader, \n",
    "                                testloader = val_loader, \n",
    "                                device = device, \n",
    "                                loss_func = loss_function,\n",
    "                                optimizer = optimizer, \n",
    "                                scheduler = scheduler\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a02f27-e2c7-4f0c-ac90-10b6b4ac09e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8994c123-92ad-4815-9217-c2dca2f80a6b",
   "metadata": {},
   "source": [
    "We see from that with PDP, the number of weights goes down during training, until it reaches the target sparsity (sparsity of 80%, or ~20% remaining weights). The function that calculates the remaining weights feeds the weights through the quantizer and pruning method, and calculates the ratio between non-zero weights and all weights. However, since PDP uses a soft mask during training, the percentage of remaining weights seems to go down rather noisily (can even drop from 80% to ~20% remaining weights). The algorithm actually increases the sparsity linearly.\n",
    "During fine-tuning the mask is fixed, and turned into a mask of 0s and 1s by a simple rounding operation, so the remaining weights stay the same during each epoch.\n",
    "\n",
    "In the original paper for PDP there was no fine-tuning after the creation of the final hard mask. We have added fine-tuning here as an option that can be turned off by simply setting ```fine_tuning_epochs``` to 0 in the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "678209db-91ad-4090-9480-76f6061fdf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1520326/4147432696.py:29: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax[0].set_yticklabels(new_ytick)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pquant import remove_pruning_from_model\n",
    "import matplotlib.pyplot as plt\n",
    "# Remove compression layers, leaves Quantized activations in place\n",
    "model = remove_pruning_from_model(trained_model, config)\n",
    "\n",
    "# Plot remaining weights\n",
    "names = []\n",
    "remaining = []\n",
    "total_w = []\n",
    "nonzeros = []\n",
    "for n, m in trained_model.named_modules():\n",
    "    if isinstance(m, (torch.nn.Conv1d, torch.nn.Conv2d, torch.nn.Linear)):\n",
    "        names.append(n)\n",
    "        nonzero = np.count_nonzero(m.weight.detach().cpu())\n",
    "        remaining_pct = nonzero / m.weight.numel()\n",
    "        remaining.append(remaining_pct)\n",
    "        total_w.append(m.weight.numel())\n",
    "        nonzeros.append(nonzero)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].bar(range(len(names)), remaining)\n",
    "ax[0].set_xticks(range(len(names)))\n",
    "ax[0].set_xticklabels(names)\n",
    "ax[0].tick_params(axis='x', labelrotation=270)\n",
    "new_ytick = []\n",
    "for i in ax[0].get_yticklabels():\n",
    "    ytick = f\"{float(i.get_text()) * 100}%\"\n",
    "    new_ytick.append(ytick)\n",
    "ax[0].set_yticklabels(new_ytick)\n",
    "ax[0].title.set_text(\"Remaining weights per layer\")\n",
    "\n",
    "ax[1].bar(range(len(nonzeros)), total_w, color=\"lightcoral\", label=\"total weights\")\n",
    "ax[1].bar(range(len(nonzeros)), nonzeros, color=\"steelblue\", label=\"nonzero weights\")\n",
    "ax[1].set_xticks(range(len(names)))\n",
    "ax[1].set_xticklabels(names)\n",
    "ax[1].tick_params(axis='x', labelrotation=270)\n",
    "ax[1].title.set_text(\"Weights per layer\")\n",
    "ax[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98f0f07-4f01-40d8-a162-8778ec310b9a",
   "metadata": {},
   "source": [
    "## Custom config from existing config\n",
    "Using the ```pquant/configs/config_pdp.yaml``` as base, let's customize the quantization and pruning scheme. \n",
    "\n",
    "The function we use will go through the model's layers and do the following: \n",
    "\n",
    "Quantization:\n",
    "\n",
    "        1. Looks for the names of convolutional, linear and average pooling layers, as well as names of the activations (layer type activations and functional types)\n",
    "        2. Adds the name of the layer to the layer_specific list, along with a default quantization scheme of 0 and 7 for weight and bias (if bias is not None)\n",
    "\n",
    "Pruning: \n",
    "\n",
    "        1. Looks for convolutional and linear layers and adds their name to the disable_pruning_for_layers list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62cc068a-4e3b-4e61-8c23-2b8ba37adcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pruning_parameters': {'disable_pruning_for_layers': ['conv1',\n",
       "   'layer1.0.conv1',\n",
       "   'layer1.0.conv2',\n",
       "   'layer1.1.conv1',\n",
       "   'layer1.1.conv2',\n",
       "   'layer2.0.conv1',\n",
       "   'layer2.0.conv2',\n",
       "   'layer2.0.downsample.0',\n",
       "   'layer2.1.conv1',\n",
       "   'layer2.1.conv2',\n",
       "   'layer3.0.conv1',\n",
       "   'layer3.0.conv2',\n",
       "   'layer3.0.downsample.0',\n",
       "   'layer3.1.conv1',\n",
       "   'layer3.1.conv2',\n",
       "   'layer4.0.conv1',\n",
       "   'layer4.0.conv2',\n",
       "   'layer4.0.downsample.0',\n",
       "   'layer4.1.conv1',\n",
       "   'layer4.1.conv2',\n",
       "   'fc'],\n",
       "  'enable_pruning': True,\n",
       "  'epsilon': 0.015,\n",
       "  'pruning_method': 'pdp',\n",
       "  'sparsity': 0.8,\n",
       "  'temperature': 1e-05,\n",
       "  'threshold_decay': 0.0,\n",
       "  'structured_pruning': False},\n",
       " 'quantization_parameters': {'default_integer_bits': 0.0,\n",
       "  'default_fractional_bits': 7.0,\n",
       "  'enable_quantization': True,\n",
       "  'hgq_gamma': 0.0003,\n",
       "  'hgq_heterogeneous': True,\n",
       "  'layer_specific': {'conv1': {'weight': {'integer_bits': 0,\n",
       "     'fractional_bits': 7}},\n",
       "   'relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer1.0.conv1': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer1.0.relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer1.0.conv2': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer1.1.conv1': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer1.1.relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer1.1.conv2': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer2.0.conv1': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer2.0.relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer2.0.conv2': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer2.0.downsample.0': {'weight': {'integer_bits': 0,\n",
       "     'fractional_bits': 7}},\n",
       "   'layer2.1.conv1': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer2.1.relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer2.1.conv2': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer3.0.conv1': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer3.0.relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer3.0.conv2': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer3.0.downsample.0': {'weight': {'integer_bits': 0,\n",
       "     'fractional_bits': 7}},\n",
       "   'layer3.1.conv1': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer3.1.relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer3.1.conv2': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer4.0.conv1': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer4.0.relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer4.0.conv2': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer4.0.downsample.0': {'weight': {'integer_bits': 0,\n",
       "     'fractional_bits': 7}},\n",
       "   'layer4.1.conv1': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer4.1.relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer4.1.conv2': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'fc': {'weight': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "    'bias': {'integer_bits': 0, 'fractional_bits': 7}}},\n",
       "  'use_high_granularity_quantization': False,\n",
       "  'use_real_tanh': False,\n",
       "  'use_relu_multiplier': True,\n",
       "  'use_symmetric_quantization': False},\n",
       " 'fitcompress_parameters': {'enable_fitcompress': False,\n",
       "  'optimize_quantization': True,\n",
       "  'quantization_schedule': [7.0, 4.0, 3.0, 2.0, 1.0],\n",
       "  'pruning_schedule': {'start': 0, 'end': -3, 'steps': 40},\n",
       "  'compression_goal': 0.1,\n",
       "  'optimize_pruning': True,\n",
       "  'greedy_astar': True,\n",
       "  'approximate': True,\n",
       "  'lambda': 1},\n",
       " 'training_parameters': {'epochs': 100,\n",
       "  'fine_tuning_epochs': 100,\n",
       "  'pretraining_epochs': 0,\n",
       "  'pruning_first': False,\n",
       "  'rewind': 'never',\n",
       "  'rounds': 1,\n",
       "  'save_weights_epoch': -1},\n",
       " 'batch_size': 64,\n",
       " 'cosine_tmax': 200,\n",
       " 'gamma': 0.1,\n",
       " 'l2_decay': 0.0001,\n",
       " 'label_smoothing': 0.0,\n",
       " 'lr': 0.01,\n",
       " 'lr_schedule': 'cosine',\n",
       " 'milestones': [-1, -1],\n",
       " 'momentum': 0.9,\n",
       " 'optimizer': 'sgd',\n",
       " 'plot_frequency': 100}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base config\n",
    "pruning_method = \"pdp\"\n",
    "config = get_default_config(pruning_method)\n",
    "model = torchvision.models.resnet18()\n",
    "\n",
    "\n",
    "from pquant import add_default_layer_quantization_pruning_to_config\n",
    "config = add_default_layer_quantization_pruning_to_config(model, config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cdfe45b-1432-4cec-a3dd-b46f837beb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save config\n",
    "from pquant.core.utils import write_config_to_yaml\n",
    "write_config_to_yaml(config, \"prune_quantize_example.yaml\", sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdb7669-ea71-4e86-b128-e313e83fbc96",
   "metadata": {},
   "source": [
    "Now that we have the custom config, it is up to us to modify the quantization bits for each layer that will not use the default value. If a layer uses the default value it can be removed from the ```layer_specific``` list.\n",
    "\n",
    "For pruning, leave those layers to the ```disable_pruning_for_layers``` list that will not be pruned, others need to be removed from the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742e0b00-220d-47a7-9774-af694f0afe1f",
   "metadata": {},
   "source": [
    "## About replacing layers and activations\n",
    "Layers that can currently be compressed for PyTorch models: ```nn.Conv1d, nn.Conv2d, nn.Linear nn.AvgPool1d, nn.AvgPool2d, nn.AvgPool3d```.\n",
    "\n",
    "Activations that can currently be automatically be replaced with a quantized variant: ```nn.ReLU, nn.Tanh```. The activations are replaced by a quantized variant, found in ```pquant.core.activations_quantizer.py```.\n",
    "\n",
    "\n",
    "Layers that can currently be compressed for TensorFlow models: ```Conv1D, Conv2D, Dense, DepthwiseConv2D, SeparableConv2D, AveragePooling1D, AveragePooling2D, AveragePooling3D, ReLU, Activation(tanh/relu)```. In TensorFlow the activations can also be a part of the `Dense`, `Conv2D` etc. layer, in which case this activation is extracted and added as a separate quantized layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baece7d0-e23a-4e31-ba1e-1cf61cb05356",
   "metadata": {},
   "source": [
    "## More about activations\n",
    "If using layer type activations, note that if you want to keep the fine-grained control over the quantization of the activation, reusing an activation layer can cause problems, as all activations will use the quantization bits set for that particular layer. To avoid this, use a separate ```nn.Tanh``` / ```nn.ReLU``` for each activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd524cd-0145-4001-9ede-1b85e56171ff",
   "metadata": {},
   "source": [
    "## HGQ\n",
    "To use HGQ, enable it in the config: `config[\"quantization_parameters\"][\"use_high_granularity_quantization\"] = True`. Other relevant parameters to tune are `config[\"quantization_parameters\"][\"default_integer_bits\"]`, `config[\"quantization_parameters\"][\"default_fractional_bits\"]`, `config[\"quantization_parameters\"][\"hgq_gamma\"]`. If the parameter `config[\"quantization_parameters\"][\"hgq_heterogeneous\"]` is true, HGQ learns quantization bits for each weight separately, and if false, it learns one integer and one fractional bit per layer.\n",
    "When using HGQ, we advice using Adam instead of SGD as an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aadafd9-f0df-473c-84de-2c2a72148ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473019d7-502c-44b5-bf06-612b857756c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
