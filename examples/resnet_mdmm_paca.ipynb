{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5676e100-c255-4871-b167-01a788309112",
   "metadata": {},
   "source": [
    "## In this tutorial we create a CNN and dataloaders, and train / prune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27197caf-85a2-48b7-af76-a5ff943408ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\" # Needs to be set, some pruning layers as well as the quantizers are Keras\n",
    "import keras\n",
    "keras.config.set_backend(\"torch\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "keras.backend.set_image_data_format(\"channels_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e520e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir(\"/home/das214/PQuant/mdmm_dev/src\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for f in os.listdir(os.getcwd()):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ea5a763-a029-495d-a03a-390048d749f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "model = model.to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cd71c9-86b2-4911-aa71-bd18b1e75aa1",
   "metadata": {},
   "source": [
    "## Add pruning and quantization\n",
    "Begin prunning with MDMM pruning with Unstructured Sparsity metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec145f1-502c-4fd0-84ed-e87b84a27374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pquant import get_default_config\n",
    "from IPython.display import JSON\n",
    "\n",
    "pruning_method = \"mdmm\"\n",
    "config = get_default_config(pruning_method)\n",
    "JSON(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3ef3115-2f3d-43e1-a199-4a19d667f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace layers with compressed layers\n",
    "from pquant import add_compression_layers\n",
    "input_shape = (256,3,32,32)\n",
    "model = add_compression_layers(model, config, input_shape)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82dd0b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from pquant import get_layer_keep_ratio, get_model_losses\n",
    "from quantizers.fixed_point.fixed_point_ops import get_fixed_quantizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_cifar10_data(batch_size):\n",
    "    normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    train_transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), \n",
    "                                          transforms.ToTensor(), normalize])\n",
    "    test_transform = transforms.Compose([transforms.ToTensor(), normalize])  \n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "    valset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                       download=True, transform=test_transform)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Set up input quantizer\n",
    "quantizer = get_fixed_quantizer(overflow_mode=\"SAT\")\n",
    "\n",
    "def train_resnet(model, trainloader, device, loss_func,\n",
    "                 epoch, optimizer, scheduler, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    One epoch of training with a live ETA/throughput bar.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(trainloader,\n",
    "              desc=f\"Train ‖ Epoch {epoch}\",\n",
    "              total=len(trainloader),\n",
    "              unit=\"batch\",\n",
    "              dynamic_ncols=True) as pbar:\n",
    "\n",
    "        for inputs, labels in pbar:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            inputs = quantizer(inputs, k=torch.tensor(1.), i=torch.tensor(0.), f=torch.tensor(7.))\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)              # cleaner gradient reset\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            losses = get_model_losses(model, torch.tensor(0.).to(device))\n",
    "            loss += losses\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f} \")\n",
    "        \n",
    "    # ----- Diagnostics on Last mini-batch -----\n",
    "    print(f\"Loss={loss_func(outputs, labels).item():.4f} | Reg={loss.item() - loss_func(outputs, labels).item():.4f}\")\n",
    "\n",
    "def validate_resnet(model, testloader, device, loss_func, epoch, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Validation with progress bar and accuracy summary.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(testloader,\n",
    "                  desc=f\"Val   ‖ Epoch {epoch}\",\n",
    "                  total=len(testloader),\n",
    "                  unit=\"batch\",\n",
    "                  dynamic_ncols=True) as pbar:\n",
    "\n",
    "            for inputs, labels in pbar:\n",
    "                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "                inputs = quantizer(inputs, k=torch.tensor(1.), i=torch.tensor(0.), f=torch.tensor(7.))\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                running_acc = 100. * correct / total\n",
    "                pbar.set_postfix(acc=f\"{running_acc:.2f}%\")\n",
    "\n",
    "    ratio = get_layer_keep_ratio(model)\n",
    "    print(f\"Accuracy: {correct/total*100:.2f}% | Remaining weights: {ratio*100:.2f}% \\n\")\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "train_loader, val_loader = get_cifar10_data(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cff4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0001, momentum=0.9)\n",
    "scheduler = CosineAnnealingLR(optimizer, 200)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e20af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pquant import iterative_train\n",
    "# \"\"\"\n",
    "# Inputs to train_resnet we defined previously are:\n",
    "#           model, trainloader, device, loss_func, epoch, optimizer, scheduler, **kwargs\n",
    "# \"\"\"\n",
    "\n",
    "# trained_model = iterative_train(model = model, \n",
    "#                                 config = config, \n",
    "#                                 train_func = train_resnet, \n",
    "#                                 valid_func = validate_resnet, \n",
    "#                                 trainloader = train_loader, \n",
    "#                                 testloader = val_loader, \n",
    "#                                 device = device, \n",
    "#                                 loss_func = loss_function,\n",
    "#                                 optimizer = optimizer, \n",
    "#                                 scheduler = scheduler\n",
    "#                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de9bc4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = 'resnet_mdmm_unstr_pruned.pth'\n",
    "# torch.save(model_copy.state_dict(), SAVE_PATH)\n",
    "\n",
    "model = torchvision.models.resnet18()\n",
    "model.load_state_dict(torch.load(SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b8dc93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot remaining weights\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "names = []\n",
    "remaining = []\n",
    "total_w = []\n",
    "nonzeros = []\n",
    "for n, m in model.named_modules():\n",
    "    if isinstance(m, (torch.nn.Conv1d, torch.nn.Conv2d, torch.nn.Linear)):\n",
    "        names.append(n)\n",
    "        nonzero = np.count_nonzero(m.weight.detach().cpu())\n",
    "        remaining_pct = nonzero / m.weight.numel()\n",
    "        remaining.append(remaining_pct)\n",
    "        total_w.append(m.weight.numel())\n",
    "        nonzeros.append(nonzero)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].bar(range(len(names)), remaining)\n",
    "ax[0].set_xticks(range(len(names)))\n",
    "ax[0].set_xticklabels(names)\n",
    "ax[0].tick_params(axis='x', labelrotation=270)\n",
    "new_ytick = []\n",
    "for i in ax[0].get_yticklabels():\n",
    "    ytick = f\"{float(i.get_text()) * 100:.2f}%\"\n",
    "    new_ytick.append(ytick)\n",
    "ax[0].set_yticklabels(new_ytick)\n",
    "ax[0].title.set_text(\"Remaining weights per layer\")\n",
    "\n",
    "ax[1].bar(range(len(nonzeros)), total_w, color=\"lightcoral\", label=\"total weights\")\n",
    "ax[1].bar(range(len(nonzeros)), nonzeros, color=\"steelblue\", label=\"nonzero weights\")\n",
    "ax[1].set_xticks(range(len(names)))\n",
    "ax[1].set_xticklabels(names)\n",
    "ax[1].tick_params(axis='x', labelrotation=270)\n",
    "ax[1].title.set_text(\"Weights per layer\")\n",
    "ax[1].legend()\n",
    "ax[1].set_yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae1039e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def visualize_conv_patterns(model, layer_name, max_patterns_to_show=16):\n",
    "    \"\"\"\n",
    "    Visualizes the dominant binary patterns for a specific convolutional layer.\n",
    "    \"\"\"\n",
    "    target_module = None\n",
    "    for name, module in model.named_modules():\n",
    "        if name == layer_name and hasattr(module, \"pruning_layer\"):\n",
    "            pruning_layer = module.pruning_layer\n",
    "            if hasattr(pruning_layer, \"metric_fn\") and \"PACAPattern\" in pruning_layer.metric_fn.__class__.__name__:\n",
    "                target_module = module\n",
    "                break\n",
    "    \n",
    "    if target_module is None:\n",
    "        print(f\"Error: Could not find a PACA-pruned layer named '{layer_name}'.\")\n",
    "        return\n",
    "        \n",
    "    metric_fn = target_module.pruning_layer.metric_fn\n",
    "    # Ensure dominant patterns are selected based on the final weights\n",
    "    metric_fn._select_dominant_patterns(target_module.weight)\n",
    "    \n",
    "    patterns = metric_fn.dominant_patterns\n",
    "    if patterns is None or patterns.shape[0] == 0:\n",
    "        print(f\"No dominant patterns found for layer '{layer_name}'.\")\n",
    "        return\n",
    "        \n",
    "    # Convert to NumPy for plotting\n",
    "    patterns_np = keras.ops.convert_to_numpy(patterns)\n",
    "    \n",
    "    # Get original kernel shape from the weight tensor\n",
    "    kernel_h, kernel_w = target_module.weight.shape[2], target_module.weight.shape[3]\n",
    "    \n",
    "    num_patterns = min(patterns_np.shape[0], max_patterns_to_show)\n",
    "    \n",
    "    # Create a subplot grid for the patterns\n",
    "    cols = math.ceil(math.sqrt(num_patterns))\n",
    "    rows = math.ceil(num_patterns / cols)\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n",
    "    if isinstance(axes, plt.Axes):\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    \n",
    "    fig.suptitle(f\"Dominant Patterns for Layer: {layer_name} (found {patterns_np.shape[0]})\", fontsize=16)\n",
    "    \n",
    "    for i in range(num_patterns):\n",
    "        pattern_2d = patterns_np[i].reshape(kernel_h, kernel_w)\n",
    "        # print(pattern_2d.shape)\n",
    "        # print(pattern_2d)\n",
    "        axes[i].imshow(pattern_2d, cmap='binary', vmin=0, vmax=1)\n",
    "        axes[i].set_title(f\"Pattern {i+1}\")\n",
    "        axes[i].set_xticks([])\n",
    "        axes[i].set_yticks([])\n",
    "        \n",
    "    # Hide any unused subplots\n",
    "    for j in range(num_patterns, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "        \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251515c3-00ac-4110-b8d8-a8c9100f6e6b",
   "metadata": {},
   "source": [
    "## Add PACA prunning\n",
    "#### After pruning we will have multiple patterns, so we force all of them to have a lower num,ber of dominant patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5898e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "\n",
    "with open(\"pquant/configs/config_mdmm_paca.yaml\", 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "JSON(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e857a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pquant import add_compression_layers\n",
    "input_shape = (256,3,32,32)\n",
    "model_paca = model.to(device)\n",
    "model_paca = add_compression_layers(model_paca, config, input_shape)\n",
    "model_paca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90c24bff-9937-4670-8cff-022ddc7a0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet(model, trainloader, device, loss_func, epoch, optimizer, scheduler, *args, **kwargs):\n",
    "    first_batch = True\n",
    "    for data in trainloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        inputs = quantizer(inputs, k=torch.tensor(1.), i=torch.tensor(0.), f=torch.tensor(7.)) # 8 bits input quantization\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        losses = get_model_losses(model, torch.tensor(0.).to(device))\n",
    "        loss += losses\n",
    "        loss.backward()\n",
    "\n",
    "        if first_batch:\n",
    "            print(\"\\n ---- Checking Loss values ----\")\n",
    "            print(\"Loss:\", loss_func(outputs, labels).item())\n",
    "            print(\"Model Losses:\", losses.item())\n",
    "            print(\"--------------------------------------------------\")\n",
    "\n",
    "            for name, module in model.named_modules():\n",
    "                if \"conv1\" in name and hasattr(module, \"pruning_layer\"):\n",
    "                    pruning_layer = module.pruning_layer\n",
    "                    if hasattr(pruning_layer, \"metric_fn\") and \"PACAPattern\" in pruning_layer.metric_fn.__class__.__name__:\n",
    "                        metric_fn = pruning_layer.metric_fn\n",
    "                        num_patterns = 0\n",
    "                        if metric_fn.dominant_patterns is not None:\n",
    "                            num_patterns = metric_fn.dominant_patterns.shape[0]\n",
    "\n",
    "                        total_dist = metric_fn(module.weight).item()\n",
    "                        num_kernels = module.weight.shape[0]\n",
    "                        avg_dist = total_dist / num_kernels if num_kernels > 0 else 0\n",
    "\n",
    "                        print(f\"--- PACA Stats for {name} at Epoch {epoch} ---\")\n",
    "                        print(f\"Num Patterns: {num_patterns}, Avg Pattern Dist: {avg_dist:.4f}\")\n",
    "                        print(\"--------------------------------------------------\\n\")\n",
    "                        break\n",
    "            first_batch = False\n",
    "\n",
    "        optimizer.step()\n",
    "        epoch += 1\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "def validate_resnet(model, testloader, device, loss_func, epoch, *args, **kwargs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_paca_patterns = 0\n",
    "    avg_paca_dist = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs = quantizer(inputs, k=torch.tensor(1.), i=torch.tensor(0.), f=torch.tensor(7.))\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        for name, module in model.named_modules():\n",
    "            if \"conv1\" in name and hasattr(module, \"pruning_layer\"):\n",
    "                pruning_layer = module.pruning_layer\n",
    "                if hasattr(pruning_layer, \"metric_fn\") and \"PACAPattern\" in pruning_layer.metric_fn.__class__.__name__:\n",
    "                    metric_fn = pruning_layer.metric_fn\n",
    "                    if metric_fn.dominant_patterns is not None:\n",
    "                        num_paca_patterns = metric_fn.dominant_patterns.shape[0]\n",
    "\n",
    "                    total_dist = metric_fn(module.weight).item()\n",
    "                    num_kernels = module.weight.shape[0]\n",
    "                    avg_paca_dist = total_dist / num_kernels if num_kernels > 0 else 0\n",
    "                    break\n",
    "\n",
    "        ratio = get_layer_keep_ratio(model)\n",
    "        print(f'Accuracy: {100 * correct / total:.2f}%, '\n",
    "              f'Remaining Weights: {ratio * 100:.2f}%, '\n",
    "              f'Num Patterns: {num_paca_patterns}, '\n",
    "              f'Avg Pattern Dist: {avg_paca_dist:.4f}')\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "train_loader, val_loader = get_cifar10_data(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d28865b-afdb-4773-be30-717486d9786a",
   "metadata": {},
   "source": [
    "## Create loss function, scheduler and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f88af88-ef7a-4d30-8cff-f39225d5a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0001, momentum=0.9)\n",
    "scheduler = CosineAnnealingLR(optimizer, 200)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850c23a-2abc-4904-9c69-859492b450a8",
   "metadata": {},
   "source": [
    "## Train model\n",
    "Training time. We use the train_compressed_model function from pquant to train. We need to provide some parameters such as training and validation functions, their input parameters, the model and the config file. The function automatically adds pruning layers and replaces activations with a quantized variant, trains the model, and removes the pruning layers after training is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18f2414c-1f4d-4a30-a143-920497e60ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pquant import iterative_train\n",
    "\"\"\"\n",
    "Inputs to train_resnet we defined previously are:\n",
    "          model, trainloader, device, loss_func, epoch, optimizer, scheduler, **kwargs\n",
    "\"\"\"\n",
    "\n",
    "trained_model_paca = iterative_train(model = model_paca, \n",
    "                                config = config, \n",
    "                                train_func = train_resnet, \n",
    "                                valid_func = validate_resnet, \n",
    "                                trainloader = train_loader, \n",
    "                                testloader = val_loader, \n",
    "                                device = device, \n",
    "                                loss_func = loss_function,\n",
    "                                optimizer = optimizer, \n",
    "                                scheduler = scheduler\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30cdc72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pquant import remove_pruning_from_model\n",
    "\n",
    "model_paca = remove_pruning_from_model(trained_model_paca, config)\n",
    "SAVE_PATH = 'resnet_mdmm_unstr_paca_pruned.pth'\n",
    "torch.save(model_paca.state_dict(), SAVE_PATH)\n",
    "\n",
    "model_paca = torchvision.models.resnet18()\n",
    "model_paca.load_state_dict(torch.load(SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a656bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pquant-gpu-env]",
   "language": "python",
   "name": "conda-env-pquant-gpu-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
