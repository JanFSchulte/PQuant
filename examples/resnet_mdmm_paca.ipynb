{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5676e100-c255-4871-b167-01a788309112",
   "metadata": {},
   "source": [
    "## In this tutorial we create a CNN and dataloaders, and train / prune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27197caf-85a2-48b7-af76-a5ff943408ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\" # Needs to be set, some pruning layers as well as the quantizers are Keras\n",
    "import keras\n",
    "keras.config.set_backend(\"torch\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "keras.backend.set_image_data_format(\"channels_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e520e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir(\"/home/das214/PQuant/mdmm_dev/src\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for f in os.listdir(os.getcwd()):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea5a763-a029-495d-a03a-390048d749f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "model = model.to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cd71c9-86b2-4911-aa71-bd18b1e75aa1",
   "metadata": {},
   "source": [
    "## Add pruning and quantization\n",
    "Begin prunning with MDMM pruning with Unstructured Sparsity metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec145f1-502c-4fd0-84ed-e87b84a27374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pquant import get_default_config\n",
    "from IPython.display import JSON\n",
    "\n",
    "pruning_method = \"mdmm\"\n",
    "config = get_default_config(pruning_method)\n",
    "JSON(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef3115-2f3d-43e1-a199-4a19d667f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace layers with compressed layers\n",
    "from pquant import add_compression_layers\n",
    "input_shape = (256,3,32,32)\n",
    "model = add_compression_layers(model, config, input_shape)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd0b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from pquant import get_layer_keep_ratio, get_model_losses\n",
    "from quantizers.fixed_point.fixed_point_ops import get_fixed_quantizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_cifar10_data(batch_size):\n",
    "    normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    train_transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), \n",
    "                                          transforms.ToTensor(), normalize])\n",
    "    test_transform = transforms.Compose([transforms.ToTensor(), normalize])  \n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "    valset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                       download=True, transform=test_transform)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Set up input quantizer\n",
    "quantizer = get_fixed_quantizer(overflow_mode=\"SAT\")\n",
    "\n",
    "def train_resnet(model, trainloader, device, loss_func,\n",
    "                 epoch, optimizer, scheduler, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    One epoch of training with a live ETA/throughput bar.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(trainloader,\n",
    "              desc=f\"Train ‖ Epoch {epoch}\",\n",
    "              total=len(trainloader),\n",
    "              unit=\"batch\",\n",
    "              dynamic_ncols=True) as pbar:\n",
    "\n",
    "        for inputs, labels in pbar:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            inputs = quantizer(inputs, k=torch.tensor(1.), i=torch.tensor(0.), f=torch.tensor(7.))\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)              # cleaner gradient reset\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            losses = get_model_losses(model, torch.tensor(0.).to(device))\n",
    "            loss += losses\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f} \")\n",
    "        \n",
    "    # ----- Diagnostics on Last mini-batch -----\n",
    "    print(f\"Loss={loss_func(outputs, labels).item():.4f} | Reg={loss.item() - loss_func(outputs, labels).item():.4f}\")\n",
    "\n",
    "def validate_resnet(model, testloader, device, loss_func, epoch, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Validation with progress bar and accuracy summary.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(testloader,\n",
    "                  desc=f\"Val   ‖ Epoch {epoch}\",\n",
    "                  total=len(testloader),\n",
    "                  unit=\"batch\",\n",
    "                  dynamic_ncols=True) as pbar:\n",
    "\n",
    "            for inputs, labels in pbar:\n",
    "                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "                inputs = quantizer(inputs, k=torch.tensor(1.), i=torch.tensor(0.), f=torch.tensor(7.))\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                running_acc = 100. * correct / total\n",
    "                pbar.set_postfix(acc=f\"{running_acc:.2f}%\")\n",
    "\n",
    "    ratio = get_layer_keep_ratio(model)\n",
    "    print(f\"Accuracy: {correct/total*100:.2f}% | Remaining weights: {ratio*100:.2f}% \\n\")\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "train_loader, val_loader = get_cifar10_data(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0001, momentum=0.9)\n",
    "scheduler = CosineAnnealingLR(optimizer, 200)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e20af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pquant import iterative_train\n",
    "# \"\"\"\n",
    "# Inputs to train_resnet we defined previously are:\n",
    "#           model, trainloader, device, loss_func, epoch, optimizer, scheduler, **kwargs\n",
    "# \"\"\"\n",
    "\n",
    "# trained_model = iterative_train(model = model, \n",
    "#                                 config = config, \n",
    "#                                 train_func = train_resnet, \n",
    "#                                 valid_func = validate_resnet, \n",
    "#                                 trainloader = train_loader, \n",
    "#                                 testloader = val_loader, \n",
    "#                                 device = device, \n",
    "#                                 loss_func = loss_function,\n",
    "#                                 optimizer = optimizer, \n",
    "#                                 scheduler = scheduler\n",
    "#                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9bc4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = 'resnet_mdmm_unstr_pruned.pth'\n",
    "# torch.save(model_copy.state_dict(), SAVE_PATH)\n",
    "\n",
    "model = torchvision.models.resnet18()\n",
    "model.load_state_dict(torch.load(SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8dc93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot remaining weights\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "names = []\n",
    "remaining = []\n",
    "total_w = []\n",
    "nonzeros = []\n",
    "for n, m in model.named_modules():\n",
    "    if isinstance(m, (torch.nn.Conv1d, torch.nn.Conv2d, torch.nn.Linear)):\n",
    "        names.append(n)\n",
    "        nonzero = np.count_nonzero(m.weight.detach().cpu())\n",
    "        remaining_pct = nonzero / m.weight.numel()\n",
    "        remaining.append(remaining_pct)\n",
    "        total_w.append(m.weight.numel())\n",
    "        nonzeros.append(nonzero)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].bar(range(len(names)), remaining)\n",
    "ax[0].set_xticks(range(len(names)))\n",
    "ax[0].set_xticklabels(names)\n",
    "ax[0].tick_params(axis='x', labelrotation=270)\n",
    "new_ytick = []\n",
    "for i in ax[0].get_yticklabels():\n",
    "    ytick = f\"{float(i.get_text()) * 100:.2f}%\"\n",
    "    new_ytick.append(ytick)\n",
    "ax[0].set_yticklabels(new_ytick)\n",
    "ax[0].title.set_text(\"Remaining weights per layer\")\n",
    "\n",
    "ax[1].bar(range(len(nonzeros)), total_w, color=\"lightcoral\", label=\"total weights\")\n",
    "ax[1].bar(range(len(nonzeros)), nonzeros, color=\"steelblue\", label=\"nonzero weights\")\n",
    "ax[1].set_xticks(range(len(names)))\n",
    "ax[1].set_xticklabels(names)\n",
    "ax[1].tick_params(axis='x', labelrotation=270)\n",
    "ax[1].title.set_text(\"Weights per layer\")\n",
    "ax[1].legend()\n",
    "ax[1].set_yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251515c3-00ac-4110-b8d8-a8c9100f6e6b",
   "metadata": {},
   "source": [
    "## Add PACA prunning\n",
    "#### After pruning we will have multiple patterns, so we force all of them to have a lower num,ber of dominant patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5898e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "\n",
    "with open(\"pquant/configs/config_mdmm_paca.yaml\", 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "JSON(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e857a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pquant import add_compression_layers\n",
    "input_shape = (256,3,32,32)\n",
    "model_paca = model.to(device)\n",
    "model_paca = add_compression_layers(model_paca, config, input_shape)\n",
    "model_paca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c24bff-9937-4670-8cff-022ddc7a0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet(model, trainloader, device, loss_func,\n",
    "                 epoch, optimizer, scheduler, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    One epoch of training with a live ETA/throughput bar.\n",
    "    \"\"\"\n",
    "    print()\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(trainloader,\n",
    "              desc=f\"Train ‖\\tEpoch {epoch}\",\n",
    "              total=len(trainloader),\n",
    "              unit=\"batch\",\n",
    "              dynamic_ncols=True) as pbar:\n",
    "\n",
    "        for inputs, labels in pbar:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            inputs = quantizer(inputs, k=torch.tensor(1.), i=torch.tensor(0.), f=torch.tensor(7.))\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)              # cleaner gradient reset\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            losses = get_model_losses(model, torch.tensor(0.).to(device))\n",
    "            loss += losses\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f} \")\n",
    "        \n",
    "    # ----- Diagnostics on Last mini-batch -----\n",
    "    print(f\"Loss={loss_func(outputs, labels).item():.4f} | Reg={loss.item() - loss_func(outputs, labels).item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d410086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from keras import ops\n",
    "from tqdm import tqdm\n",
    "from pquant.pruning_methods.utils import patterns\n",
    "\n",
    "def apply_projection_mask(model, src, epsilon, distance_metric, alpha=16, beta=0.85):\n",
    "    \"\"\"\n",
    "    Applies a projection mask to the Conv2d layers of a model, ensuring device consistency.\n",
    "    This version includes extra checks to guarantee the weight remains on its original device.\n",
    "    \"\"\"\n",
    "    module_iterator = tqdm(model.named_modules(), desc=\"Applying Projection Mask\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for name, module in module_iterator:\n",
    "            if isinstance(module, torch.nn.Conv2d):\n",
    "                weight = module.weight\n",
    "                original_device = weight.device\n",
    "                \n",
    "                module_iterator.set_postfix_str(f\"Processing {name} on {original_device}\")\n",
    "                _, all_patterns, _ = patterns._get_kernels_and_patterns(weight)\n",
    "                unique_patterns, counts = patterns._get_unique_patterns_with_counts(all_patterns)\n",
    "                \n",
    "                if ops.shape(unique_patterns)[0] == 0:\n",
    "                    continue\n",
    "                    \n",
    "                dominant_patterns = patterns._select_dominant_patterns(all_patterns, \n",
    "                                                              unique_patterns, counts,\n",
    "                                                              alpha=alpha, beta=beta, dtype=weight.dtype)\n",
    "\n",
    "                projection_mask_keras = patterns._get_projection_mask(weight, dominant_patterns, \n",
    "                                                                      src=src, epsilon=epsilon, \n",
    "                                                                      distance_metric=distance_metric)\n",
    "                \n",
    "\n",
    "                projection_mask_torch = ops.convert_to_tensor(projection_mask_keras, dtype=weight.dtype)\n",
    "                projection_mask_final = projection_mask_torch.to(original_device)\n",
    "                module.weight.data.mul_(projection_mask_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b6b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(model, testloader, device, desc):\n",
    "    \"\"\"\n",
    "    Evaluates the model's accuracy on the provided data loader.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        with tqdm(testloader,\n",
    "                  desc=desc,\n",
    "                  total=len(testloader),\n",
    "                  unit=\"batch\",\n",
    "                  dynamic_ncols=True) as pbar:\n",
    "\n",
    "            for inputs, labels in pbar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                inputs = quantizer(inputs, k=torch.tensor(1.), i=torch.tensor(0.), f=torch.tensor(7.))\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                postfix_stats = {\n",
    "                    'acc': f\"{(100 * correct / total):.2f}%\"\n",
    "                }\n",
    "                pbar.set_postfix(**postfix_stats)\n",
    "    \n",
    "    accuracy = 100. * correct / total\n",
    "    # print(f\"Final Accuracy: {final_accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747361db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "fingerprint = '%08x' % random.randrange(16**8)\n",
    "SAVE_DIR = f'trained_models/resnet/mdmm/{fingerprint}/unstr_paca/'\n",
    "print(fingerprint)\n",
    "print(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433cc107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pquant import remove_pruning_from_model\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "def validate_resnet(model, testloader, device, loss_func, epoch, **kwargs):\n",
    "    model.eval()\n",
    "    \n",
    "    accuracy_bp = evaluate_model(model, testloader, device, desc=f\" - Val (BP)\\t‖\\tEpoch {epoch}\")\n",
    "    print(f\"Accuracy (Before Projection): {accuracy_bp:.2f}%\")\n",
    "    \n",
    "    ratio_bp = get_layer_keep_ratio(model)\n",
    "    print(f'Remaining Weights: {ratio_bp * 100:.2f}%')\n",
    "    \n",
    "    print(\"Saving Before-Projection model...\")\n",
    "    model_to_save_bp = torchvision.models.resnet18()\n",
    "    model_to_save_bp.load_state_dict(model.state_dict(), strict=False)\n",
    "    \n",
    "    clean_model_bp = remove_pruning_from_model(model_to_save_bp, config)\n",
    "    \n",
    "    model_fname_bp = f'BP_e{epoch}_a{accuracy_bp:.2f}_r{ratio_bp:.2f}.pth'\n",
    "    SAVE_PATH_BP = os.path.join(SAVE_DIR, model_fname_bp)\n",
    "    torch.save(clean_model_bp.state_dict(), SAVE_PATH_BP)\n",
    "    print(f\"Saved to {SAVE_PATH_BP}\")\n",
    "    \n",
    "    model_to_save_ap = torchvision.models.resnet18()\n",
    "    model_to_save_ap.load_state_dict(model.state_dict(), strict=False)\n",
    "    model_to_save_ap.to(device)\n",
    "    \n",
    "    apply_projection_mask(model_to_save_ap, \n",
    "                          src=config['pruning_parameters']['src'],\n",
    "                          epsilon=config['pruning_parameters']['epsilon'],\n",
    "                          distance_metric=config['pruning_parameters']['distance_metric'],\n",
    "                          alpha=config['pruning_parameters']['num_patterns_to_keep'], \n",
    "                          beta=config['pruning_parameters']['beta'])\n",
    "        \n",
    "    accuracy_ap = evaluate_model(model_to_save_ap, testloader, device, desc=f\" - Val (AP)\\t‖\\tEpoch {epoch}\")\n",
    "    print(f\"Accuracy (After Projection): {accuracy_ap:.2f}%\\n\")\n",
    "    \n",
    "    ratio_ap = get_layer_keep_ratio(model_to_save_ap)\n",
    "    print(f'Remaining Weights: {ratio_ap * 100:.2f}%')\n",
    "    \n",
    "    print(\"Saving After-Projection model...\")\n",
    "    clean_model_ap = remove_pruning_from_model(model_to_save_ap, config)\n",
    "    \n",
    "    model_fname_ap = f'AP_e{epoch}_a{accuracy_ap:.2f}_r{ratio_ap:.2f}.pth'\n",
    "    SAVE_PATH_AP = os.path.join(SAVE_DIR, model_fname_ap)\n",
    "    torch.save(clean_model_ap.state_dict(), SAVE_PATH_AP)\n",
    "    print(f\"Saved to {SAVE_PATH_AP}\")\n",
    "    \n",
    "    \n",
    "BATCH_SIZE = 256\n",
    "train_loader, val_loader = get_cifar10_data(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850c23a-2abc-4904-9c69-859492b450a8",
   "metadata": {},
   "source": [
    "## Train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f88af88-ef7a-4d30-8cff-f39225d5a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0001, momentum=0.9)\n",
    "scheduler = CosineAnnealingLR(optimizer, 200)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18f2414c-1f4d-4a30-a143-920497e60ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖\tEpoch 0: 100%|██████████| 196/196 [00:10<00:00, 19.09batch/s, loss=2.7553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.5762 | Reg=2.1791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (BP)\t‖\tEpoch 0: 100%|██████████| 196/196 [00:06<00:00, 32.62batch/s, acc=86.97%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Before Projection): 86.97%\n",
      "Remaining Weights: 45.78%\n",
      "Saving Before-Projection model...\n",
      "Saved to trained_models/resnet/mdmm/e92c8d83/unstr_paca/BP_e0_a86.97_r0.46.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (AP)\t‖\tEpoch 0: 100%|██████████| 196/196 [00:02<00:00, 78.31batch/s, acc=86.97%]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (After Projection): 86.97%\n",
      "\n",
      "Remaining Weights: 44.50%\n",
      "Saving After-Projection model...\n",
      "Saved to trained_models/resnet/mdmm/e92c8d83/unstr_paca/AP_e0_a86.97_r0.44.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖\tEpoch 1: 100%|██████████| 196/196 [00:10<00:00, 19.29batch/s, loss=3.9187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.5352 | Reg=3.3835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (BP)\t‖\tEpoch 1: 100%|██████████| 196/196 [00:06<00:00, 31.69batch/s, acc=77.27%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Before Projection): 77.27%\n",
      "Remaining Weights: 45.78%\n",
      "Saving Before-Projection model...\n",
      "Saved to trained_models/resnet/mdmm/e92c8d83/unstr_paca/BP_e1_a77.27_r0.46.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (AP)\t‖\tEpoch 1: 100%|██████████| 196/196 [00:02<00:00, 78.12batch/s, acc=77.27%]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (After Projection): 77.27%\n",
      "\n",
      "Remaining Weights: 44.50%\n",
      "Saving After-Projection model...\n",
      "Saved to trained_models/resnet/mdmm/e92c8d83/unstr_paca/AP_e1_a77.27_r0.44.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖\tEpoch 2: 100%|██████████| 196/196 [00:10<00:00, 18.90batch/s, loss=4.9096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.3528 | Reg=4.5568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (BP)\t‖\tEpoch 2: 100%|██████████| 196/196 [00:06<00:00, 32.40batch/s, acc=87.95%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Before Projection): 87.95%\n",
      "Remaining Weights: 45.78%\n",
      "Saving Before-Projection model...\n",
      "Saved to trained_models/resnet/mdmm/e92c8d83/unstr_paca/BP_e2_a87.95_r0.46.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (AP)\t‖\tEpoch 2: 100%|██████████| 196/196 [00:02<00:00, 77.83batch/s, acc=87.95%]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (After Projection): 87.95%\n",
      "\n",
      "Remaining Weights: 44.50%\n",
      "Saving After-Projection model...\n",
      "Saved to trained_models/resnet/mdmm/e92c8d83/unstr_paca/AP_e2_a87.95_r0.44.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖\tEpoch 3: 100%|██████████| 196/196 [00:10<00:00, 19.46batch/s, loss=6.4855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7320 | Reg=5.7535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (BP)\t‖\tEpoch 3: 100%|██████████| 196/196 [00:06<00:00, 32.49batch/s, acc=81.43%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Before Projection): 81.43%\n",
      "Remaining Weights: 45.78%\n",
      "Saving Before-Projection model...\n",
      "Saved to trained_models/resnet/mdmm/e92c8d83/unstr_paca/BP_e3_a81.43_r0.46.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (AP)\t‖\tEpoch 3: 100%|██████████| 196/196 [00:02<00:00, 79.57batch/s, acc=81.43%]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (After Projection): 81.43%\n",
      "\n",
      "Remaining Weights: 44.49%\n",
      "Saving After-Projection model...\n",
      "Saved to trained_models/resnet/mdmm/e92c8d83/unstr_paca/AP_e3_a81.43_r0.44.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖\tEpoch 4: 100%|██████████| 196/196 [00:10<00:00, 19.21batch/s, loss=7.4137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.4904 | Reg=6.9233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (BP)\t‖\tEpoch 4: 100%|██████████| 196/196 [00:06<00:00, 32.57batch/s, acc=88.78%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Before Projection): 88.78%\n",
      "Remaining Weights: 45.78%\n",
      "Saving Before-Projection model...\n",
      "Saved to trained_models/resnet/mdmm/e92c8d83/unstr_paca/BP_e4_a88.78_r0.46.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (AP)\t‖\tEpoch 4: 100%|██████████| 196/196 [00:02<00:00, 78.11batch/s, acc=88.78%]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (After Projection): 88.78%\n",
      "\n",
      "Remaining Weights: 44.49%\n",
      "Saving After-Projection model...\n",
      "Saved to trained_models/resnet/mdmm/e92c8d83/unstr_paca/AP_e4_a88.78_r0.44.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖\tEpoch 5: 100%|██████████| 196/196 [00:10<00:00, 18.99batch/s, loss=8.5892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.4771 | Reg=8.1121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (BP)\t‖\tEpoch 5: 100%|██████████| 196/196 [00:06<00:00, 31.65batch/s, acc=82.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Before Projection): 82.75%\n",
      "Remaining Weights: 45.78%\n",
      "Saving Before-Projection model...\n",
      "Saved to trained_models/resnet/mdmm/e92c8d83/unstr_paca/BP_e5_a82.75_r0.46.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (AP)\t‖\tEpoch 5: 100%|██████████| 196/196 [00:02<00:00, 77.16batch/s, acc=82.75%]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (After Projection): 82.75%\n",
      "\n",
      "Remaining Weights: 44.49%\n",
      "Saving After-Projection model...\n",
      "Saved to trained_models/resnet/mdmm/e92c8d83/unstr_paca/AP_e5_a82.75_r0.44.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖\tEpoch 6: 100%|██████████| 196/196 [00:10<00:00, 19.23batch/s, loss=9.7694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.4861 | Reg=9.2834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (BP)\t‖\tEpoch 6: 100%|██████████| 196/196 [00:06<00:00, 32.16batch/s, acc=89.23%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Before Projection): 89.23%\n",
      "Remaining Weights: 45.78%\n",
      "Saving Before-Projection model...\n",
      "Saved to trained_models/resnet/mdmm/e92c8d83/unstr_paca/BP_e6_a89.23_r0.46.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (AP)\t‖\tEpoch 6: 100%|██████████| 196/196 [00:02<00:00, 78.08batch/s, acc=89.23%]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (After Projection): 89.23%\n",
      "\n",
      "Remaining Weights: 44.49%\n",
      "Saving After-Projection model...\n",
      "Saved to trained_models/resnet/mdmm/e92c8d83/unstr_paca/AP_e6_a89.23_r0.44.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖\tEpoch 7: 100%|██████████| 196/196 [00:10<00:00, 19.30batch/s, loss=11.0626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.5922 | Reg=10.4703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (BP)\t‖\tEpoch 7: 100%|██████████| 196/196 [00:06<00:00, 31.91batch/s, acc=83.99%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Before Projection): 83.99%\n",
      "Remaining Weights: 45.78%\n",
      "Saving Before-Projection model...\n",
      "Saved to trained_models/resnet/mdmm/e92c8d83/unstr_paca/BP_e7_a83.99_r0.46.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (AP)\t‖\tEpoch 7: 100%|██████████| 196/196 [00:02<00:00, 77.40batch/s, acc=83.99%]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (After Projection): 83.99%\n",
      "\n",
      "Remaining Weights: 44.49%\n",
      "Saving After-Projection model...\n",
      "Saved to trained_models/resnet/mdmm/e92c8d83/unstr_paca/AP_e7_a83.99_r0.44.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖\tEpoch 8: 100%|██████████| 196/196 [00:10<00:00, 19.29batch/s, loss=12.3056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.6655 | Reg=11.6401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (BP)\t‖\tEpoch 8: 100%|██████████| 196/196 [00:06<00:00, 32.08batch/s, acc=89.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Before Projection): 89.75%\n",
      "Remaining Weights: 45.78%\n",
      "Saving Before-Projection model...\n",
      "Saved to trained_models/resnet/mdmm/e92c8d83/unstr_paca/BP_e8_a89.75_r0.46.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Val (AP)\t‖\tEpoch 8: 100%|██████████| 196/196 [00:02<00:00, 77.28batch/s, acc=89.75%]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (After Projection): 89.75%\n",
      "\n",
      "Remaining Weights: 44.49%\n",
      "Saving After-Projection model...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:659] . unexpected pos 64 vs 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/serialization.py:965\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 965\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/serialization.py:1213\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1212\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m-> 1213\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_value\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# .format_version is used to track\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m#     1. version 1 represents the order of storages being changed from\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m#        lexicographical based on keys to numerically ordered based on keys\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m#     2. version 2 represents including storage_alignment as a record\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;66;03m#        within the zipfile\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:857] . PytorchStreamWriter failed writing file data.pkl: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpquant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m iterative_train\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mInputs to train_resnet we defined previously are:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m          model, trainloader, device, loss_func, epoch, optimizer, scheduler, **kwargs\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m trained_model_paca \u001b[38;5;241m=\u001b[39m \u001b[43miterative_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_paca\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtrain_func\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_resnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mvalid_func\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidate_resnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/core/train.py:8\u001b[0m, in \u001b[0;36miterative_train\u001b[0;34m(model, config, train_func, valid_func, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mbackend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpquant\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_impl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain_torch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m iterative_train_torch\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterative_train_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpquant\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_impl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain_tf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m iterative_train_tf\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/core/torch_impl/train_torch.py:37\u001b[0m, in \u001b[0;36miterative_train_torch\u001b[0;34m(model, config, train_func, valid_func, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m train_func(model, epoch\u001b[38;5;241m=\u001b[39mepoch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 37\u001b[0m \u001b[43mvalid_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m post_epoch_functions(model, e, training_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     39\u001b[0m epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[17], line 47\u001b[0m, in \u001b[0;36mvalidate_resnet\u001b[0;34m(model, testloader, device, loss_func, epoch, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m model_fname_ap \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAP_e\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_a\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_ap\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_r\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mratio_ap\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     46\u001b[0m SAVE_PATH_AP \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(SAVE_DIR, model_fname_ap)\n\u001b[0;32m---> 47\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_model_ap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSAVE_PATH_AP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSAVE_PATH_AP\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/serialization.py:964\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    961\u001b[0m     f \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(f)\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 964\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    965\u001b[0m         _save(\n\u001b[1;32m    966\u001b[0m             obj,\n\u001b[1;32m    967\u001b[0m             opened_zipfile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    970\u001b[0m             _disable_byteorder_record,\n\u001b[1;32m    971\u001b[0m         )\n\u001b[1;32m    972\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/serialization.py:798\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 798\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:659] . unexpected pos 64 vs 0"
     ]
    }
   ],
   "source": [
    "from pquant import iterative_train\n",
    "\"\"\"\n",
    "Inputs to train_resnet we defined previously are:\n",
    "          model, trainloader, device, loss_func, epoch, optimizer, scheduler, **kwargs\n",
    "\"\"\"\n",
    "\n",
    "trained_model_paca = iterative_train(model = model_paca, \n",
    "                                config = config, \n",
    "                                train_func = train_resnet, \n",
    "                                valid_func = validate_resnet, \n",
    "                                trainloader = train_loader, \n",
    "                                testloader = val_loader, \n",
    "                                device = device, \n",
    "                                loss_func = loss_function,\n",
    "                                optimizer = optimizer, \n",
    "                                scheduler = scheduler\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cdc72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pquant import remove_pruning_from_model\n",
    "\n",
    "# model_paca = remove_pruning_from_model(trained_model_paca, config)\n",
    "# SAVE_PATH = 'resnet_mdmm_unstr_paca_pruned.pth'\n",
    "# torch.save(model_paca.state_dict(), SAVE_PATH)\n",
    "\n",
    "# model_paca = torchvision.models.resnet18()\n",
    "# model_paca.load_state_dict(torch.load(SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660bd8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4803d015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pquant-gpu-env]",
   "language": "python",
   "name": "conda-env-pquant-gpu-env-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
