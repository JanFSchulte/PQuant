{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5676e100-c255-4871-b167-01a788309112",
   "metadata": {},
   "source": [
    "## In this tutorial we create a CNN and dataloaders, and train / prune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27197caf-85a2-48b7-af76-a5ff943408ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\" # Needs to be set, some pruning layers as well as the quantizers are Keras\n",
    "import keras\n",
    "keras.config.set_backend(\"torch\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "keras.backend.set_image_data_format(\"channels_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e520e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet_paca_pruned.pth\n",
      "pquant\n",
      "data\n",
      "smartpixels\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.chdir(\"/home/das214/PQuant/mdmm_dev/src\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for f in os.listdir(os.getcwd()):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea5a763-a029-495d-a03a-390048d749f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet18()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "model = model.to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cd71c9-86b2-4911-aa71-bd18b1e75aa1",
   "metadata": {},
   "source": [
    "## Add pruning and quantization\n",
    "Begin prunning with MDMM pruning with Unstructured Sparsity metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ec145f1-502c-4fd0-84ed-e87b84a27374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "batch_size": 128,
       "cosine_tmax": 200,
       "gamma": 0.1,
       "l2_decay": 0.0001,
       "label_smoothing": 0,
       "lr": 0.001,
       "lr_schedule": "multistep",
       "milestones": [
        75,
        120
       ],
       "momentum": 0.9,
       "optimizer": "sgd",
       "plot_frequency": 100,
       "pruning_parameters": {
        "constraint_type": "Equality",
        "damping": 1,
        "disable_pruning_for_layers": [
         null
        ],
        "enable_pruning": true,
        "epsilon": 0.001,
        "l0_mode": "coarse",
        "metric_type": "UnstructuredSparsity",
        "pruning_method": "mdmm",
        "rf": 1,
        "scale": 50,
        "target_sparsity": 0.9,
        "target_value": 0,
        "use_grad": false
       },
       "quantization_parameters": {
        "default_fractional_bits": 7,
        "default_integer_bits": 0,
        "enable_quantization": false,
        "hgq_gamma": 0.0003,
        "hgq_heterogeneous": true,
        "layer_specific": [],
        "use_high_granularity_quantization": false,
        "use_real_tanh": false,
        "use_symmetric_quantization": false
       },
       "training_parameters": {
        "epochs": 100,
        "fine_tuning_epochs": 30,
        "pretraining_epochs": 0,
        "pruning_first": false,
        "rewind": "never",
        "rounds": 1,
        "save_weights_epoch": -1
       }
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pquant import get_default_config\n",
    "from IPython.display import JSON\n",
    "\n",
    "pruning_method = \"mdmm\"\n",
    "config = get_default_config(pruning_method)\n",
    "JSON(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3ef3115-2f3d-43e1-a199-4a19d667f796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): CompressedLayerConv2d(\n",
       "    (pruning_layer): <MDMM name=mdmm, built=True>\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_1, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_2, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_3, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_4, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_5, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_6, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): CompressedLayerConv2d(\n",
       "          (pruning_layer): <MDMM name=mdmm_7, built=True>\n",
       "        )\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_8, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_9, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_10, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_11, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): CompressedLayerConv2d(\n",
       "          (pruning_layer): <MDMM name=mdmm_12, built=True>\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_13, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_14, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_15, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_16, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): CompressedLayerConv2d(\n",
       "          (pruning_layer): <MDMM name=mdmm_17, built=True>\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_18, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_19, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): CompressedLayerLinear(\n",
       "    (pruning_layer): <MDMM name=mdmm_20, built=True>\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace layers with compressed layers\n",
    "from pquant import add_compression_layers\n",
    "input_shape = (256,3,32,32)\n",
    "model = add_compression_layers(model, config, input_shape)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82dd0b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from pquant import get_layer_keep_ratio, get_model_losses\n",
    "from quantizers.fixed_point.fixed_point_ops import get_fixed_quantizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_cifar10_data(batch_size):\n",
    "    normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    train_transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), \n",
    "                                          transforms.ToTensor(), normalize])\n",
    "    test_transform = transforms.Compose([transforms.ToTensor(), normalize])  \n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "    valset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                       download=True, transform=test_transform)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Set up input quantizer\n",
    "quantizer = get_fixed_quantizer(overflow_mode=\"SAT\")\n",
    "\n",
    "def train_resnet(model, trainloader, device, loss_func,\n",
    "                 epoch, optimizer, scheduler, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    One epoch of training with a live ETA/throughput bar.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(trainloader,\n",
    "              desc=f\"Train ‖ Epoch {epoch}\",\n",
    "              total=len(trainloader),\n",
    "              unit=\"batch\",\n",
    "              dynamic_ncols=True) as pbar:\n",
    "\n",
    "        for inputs, labels in pbar:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            inputs = quantizer(inputs, k=torch.tensor(1.), i=torch.tensor(0.), f=torch.tensor(7.))\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)              # cleaner gradient reset\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            losses = get_model_losses(model, torch.tensor(0.).to(device))\n",
    "            loss += losses\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f} \")\n",
    "        \n",
    "    # ----- Diagnostics on Last mini-batch -----\n",
    "    print(f\"Loss={loss_func(outputs, labels).item():.4f} | Reg={loss.item() - loss_func(outputs, labels).item():.4f}\")\n",
    "\n",
    "def validate_resnet(model, testloader, device, loss_func, epoch, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Validation with progress bar and accuracy summary.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(testloader,\n",
    "                  desc=f\"Val   ‖ Epoch {epoch}\",\n",
    "                  total=len(testloader),\n",
    "                  unit=\"batch\",\n",
    "                  dynamic_ncols=True) as pbar:\n",
    "\n",
    "            for inputs, labels in pbar:\n",
    "                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "                inputs = quantizer(inputs, k=torch.tensor(1.), i=torch.tensor(0.), f=torch.tensor(7.))\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                running_acc = 100. * correct / total\n",
    "                pbar.set_postfix(acc=f\"{running_acc:.2f}%\")\n",
    "\n",
    "    ratio = get_layer_keep_ratio(model)\n",
    "    print(f\"Accuracy: {correct/total*100:.2f}% | Remaining weights: {ratio*100:.2f}% \\n\")\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "train_loader, val_loader = get_cifar10_data(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cff4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0001, momentum=0.9)\n",
    "scheduler = CosineAnnealingLR(optimizer, 200)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e20af1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 0: 100%|██████████| 196/196 [00:08<00:00, 24.06batch/s, loss=12.3773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.4446 | Reg=10.9328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 0: 100%|██████████| 196/196 [00:05<00:00, 37.40batch/s, acc=47.94%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.94% | Remaining weights: 96.47% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 1: 100%|██████████| 196/196 [00:07<00:00, 25.55batch/s, loss=23.6083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.6338 | Reg=21.9745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 1: 100%|██████████| 196/196 [00:05<00:00, 37.89batch/s, acc=46.52%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 46.52% | Remaining weights: 95.72% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 2: 100%|██████████| 196/196 [00:07<00:00, 25.92batch/s, loss=23.8973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.0892 | Reg=22.8081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 2: 100%|██████████| 196/196 [00:05<00:00, 38.13batch/s, acc=58.02%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.02% | Remaining weights: 94.27% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 3: 100%|██████████| 196/196 [00:07<00:00, 25.27batch/s, loss=25.7729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.4191 | Reg=24.3539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 3: 100%|██████████| 196/196 [00:05<00:00, 37.28batch/s, acc=47.09%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.09% | Remaining weights: 93.09% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 4: 100%|██████████| 196/196 [00:07<00:00, 25.25batch/s, loss=21.7308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.1449 | Reg=20.5859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 4: 100%|██████████| 196/196 [00:05<00:00, 37.94batch/s, acc=62.11%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.11% | Remaining weights: 90.59% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 5: 100%|██████████| 196/196 [00:07<00:00, 25.10batch/s, loss=23.3598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.3947 | Reg=21.9651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 5: 100%|██████████| 196/196 [00:05<00:00, 37.71batch/s, acc=32.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 32.79% | Remaining weights: 89.45% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 6: 100%|██████████| 196/196 [00:07<00:00, 24.64batch/s, loss=18.9369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.0513 | Reg=17.8856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 6: 100%|██████████| 196/196 [00:05<00:00, 37.67batch/s, acc=63.11%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.11% | Remaining weights: 86.23% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 7: 100%|██████████| 196/196 [00:08<00:00, 24.36batch/s, loss=20.5161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.4461 | Reg=19.0700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 7: 100%|██████████| 196/196 [00:05<00:00, 37.84batch/s, acc=41.66%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 41.66% | Remaining weights: 85.29% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 8: 100%|██████████| 196/196 [00:07<00:00, 24.84batch/s, loss=16.4888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9126 | Reg=15.5762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 8: 100%|██████████| 196/196 [00:05<00:00, 38.22batch/s, acc=65.06%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.06% | Remaining weights: 81.50% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 9: 100%|██████████| 196/196 [00:07<00:00, 24.71batch/s, loss=18.0069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.3131 | Reg=16.6939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 9: 100%|██████████| 196/196 [00:05<00:00, 38.31batch/s, acc=45.66%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.66% | Remaining weights: 80.77% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 10: 100%|██████████| 196/196 [00:07<00:00, 25.02batch/s, loss=14.5856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9198 | Reg=13.6658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 10: 100%|██████████| 196/196 [00:05<00:00, 38.03batch/s, acc=63.76%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.76% | Remaining weights: 76.61% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 11: 100%|██████████| 196/196 [00:07<00:00, 25.36batch/s, loss=15.7773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.2031 | Reg=14.5742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 11: 100%|██████████| 196/196 [00:05<00:00, 38.56batch/s, acc=38.01%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 38.01% | Remaining weights: 75.95% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 12: 100%|██████████| 196/196 [00:07<00:00, 25.40batch/s, loss=13.1531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.0850 | Reg=12.0681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 12: 100%|██████████| 196/196 [00:05<00:00, 38.47batch/s, acc=63.52%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.52% | Remaining weights: 71.74% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 13: 100%|██████████| 196/196 [00:07<00:00, 25.79batch/s, loss=13.8810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.0718 | Reg=12.8092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 13: 100%|██████████| 196/196 [00:05<00:00, 38.18batch/s, acc=47.69%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.69% | Remaining weights: 71.18% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 14: 100%|██████████| 196/196 [00:07<00:00, 25.35batch/s, loss=11.8679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.2313 | Reg=10.6366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 14: 100%|██████████| 196/196 [00:05<00:00, 38.81batch/s, acc=64.28%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.28% | Remaining weights: 66.97% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 15: 100%|██████████| 196/196 [00:07<00:00, 25.44batch/s, loss=12.4398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.2508 | Reg=11.1890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 15: 100%|██████████| 196/196 [00:05<00:00, 38.62batch/s, acc=34.99%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 34.99% | Remaining weights: 66.45% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 16: 100%|██████████| 196/196 [00:07<00:00, 25.17batch/s, loss=10.3955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.0073 | Reg=9.3882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 16: 100%|██████████| 196/196 [00:05<00:00, 38.09batch/s, acc=64.03%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.03% | Remaining weights: 62.45% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 17: 100%|██████████| 196/196 [00:07<00:00, 25.16batch/s, loss=11.1640]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.5261 | Reg=9.6379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 17: 100%|██████████| 196/196 [00:05<00:00, 38.25batch/s, acc=45.42%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.42% | Remaining weights: 61.75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 18: 100%|██████████| 196/196 [00:07<00:00, 25.27batch/s, loss=9.3397] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.0561 | Reg=8.2836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 18: 100%|██████████| 196/196 [00:05<00:00, 37.99batch/s, acc=64.61%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.61% | Remaining weights: 58.08% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 19: 100%|██████████| 196/196 [00:07<00:00, 25.43batch/s, loss=9.6715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.2358 | Reg=8.4357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 19: 100%|██████████| 196/196 [00:05<00:00, 38.08batch/s, acc=51.17%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 51.17% | Remaining weights: 57.36% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 20: 100%|██████████| 196/196 [00:07<00:00, 25.79batch/s, loss=8.4744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.1549 | Reg=7.3195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 20: 100%|██████████| 196/196 [00:05<00:00, 37.97batch/s, acc=63.42%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.42% | Remaining weights: 54.04% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 21: 100%|██████████| 196/196 [00:07<00:00, 25.06batch/s, loss=8.4750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.2509 | Reg=7.2240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 21: 100%|██████████| 196/196 [00:05<00:00, 37.48batch/s, acc=62.06%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.06% | Remaining weights: 53.05% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 22: 100%|██████████| 196/196 [00:07<00:00, 25.36batch/s, loss=7.4258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9128 | Reg=6.5130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 22: 100%|██████████| 196/196 [00:05<00:00, 38.57batch/s, acc=61.03%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.03% | Remaining weights: 50.33% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 23: 100%|██████████| 196/196 [00:07<00:00, 25.07batch/s, loss=7.2038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9646 | Reg=6.2392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 23: 100%|██████████| 196/196 [00:05<00:00, 38.48batch/s, acc=61.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.60% | Remaining weights: 49.11% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 24: 100%|██████████| 196/196 [00:07<00:00, 24.73batch/s, loss=6.8300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.0032 | Reg=5.8268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 24: 100%|██████████| 196/196 [00:05<00:00, 38.58batch/s, acc=61.23%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.23% | Remaining weights: 46.99% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 25: 100%|██████████| 196/196 [00:07<00:00, 25.43batch/s, loss=6.3334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9891 | Reg=5.3443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 25: 100%|██████████| 196/196 [00:05<00:00, 38.86batch/s, acc=60.52%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.52% | Remaining weights: 45.45% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 26: 100%|██████████| 196/196 [00:07<00:00, 25.44batch/s, loss=6.3911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.2415 | Reg=5.1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 26: 100%|██████████| 196/196 [00:05<00:00, 38.53batch/s, acc=60.85%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.85% | Remaining weights: 43.76% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 27: 100%|██████████| 196/196 [00:07<00:00, 25.54batch/s, loss=5.5610]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9881 | Reg=4.5729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 27: 100%|██████████| 196/196 [00:05<00:00, 38.57batch/s, acc=63.13%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.13% | Remaining weights: 42.10% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 28: 100%|██████████| 196/196 [00:07<00:00, 25.38batch/s, loss=5.7857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.2331 | Reg=4.5526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 28: 100%|██████████| 196/196 [00:05<00:00, 38.42batch/s, acc=55.05%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.05% | Remaining weights: 40.88% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 29: 100%|██████████| 196/196 [00:07<00:00, 25.03batch/s, loss=4.7685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.8737 | Reg=3.8948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 29: 100%|██████████| 196/196 [00:05<00:00, 38.09batch/s, acc=66.81%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.81% | Remaining weights: 39.18% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 30: 100%|██████████| 196/196 [00:07<00:00, 25.25batch/s, loss=4.9883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9470 | Reg=4.0413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 30: 100%|██████████| 196/196 [00:05<00:00, 38.70batch/s, acc=58.34%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.34% | Remaining weights: 38.32% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 31: 100%|██████████| 196/196 [00:07<00:00, 25.38batch/s, loss=4.1744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7937 | Reg=3.3807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 31: 100%|██████████| 196/196 [00:05<00:00, 38.12batch/s, acc=68.80%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.80% | Remaining weights: 36.58% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 32: 100%|██████████| 196/196 [00:07<00:00, 25.37batch/s, loss=4.9017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.1756 | Reg=3.7261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 32: 100%|██████████| 196/196 [00:05<00:00, 38.97batch/s, acc=59.69%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.69% | Remaining weights: 36.18% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 33: 100%|██████████| 196/196 [00:07<00:00, 25.49batch/s, loss=3.8215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.8926 | Reg=2.9289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 33: 100%|██████████| 196/196 [00:05<00:00, 38.39batch/s, acc=71.30%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.30% | Remaining weights: 34.34% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 34: 100%|██████████| 196/196 [00:07<00:00, 25.23batch/s, loss=4.5809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.1829 | Reg=3.3980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 34: 100%|██████████| 196/196 [00:05<00:00, 38.48batch/s, acc=61.48%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.48% | Remaining weights: 34.25% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 35: 100%|██████████| 196/196 [00:07<00:00, 25.87batch/s, loss=3.5990]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.0569 | Reg=2.5421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 35: 100%|██████████| 196/196 [00:05<00:00, 38.79batch/s, acc=72.35%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.35% | Remaining weights: 32.34% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 36: 100%|██████████| 196/196 [00:07<00:00, 25.56batch/s, loss=4.2675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.1446 | Reg=3.1229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 36: 100%|██████████| 196/196 [00:05<00:00, 38.41batch/s, acc=59.56%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.56% | Remaining weights: 32.45% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 37: 100%|██████████| 196/196 [00:07<00:00, 25.73batch/s, loss=3.2050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9648 | Reg=2.2402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 37: 100%|██████████| 196/196 [00:05<00:00, 38.42batch/s, acc=75.03%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.03% | Remaining weights: 30.59% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 38: 100%|██████████| 196/196 [00:07<00:00, 25.65batch/s, loss=4.0733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.2401 | Reg=2.8331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 38: 100%|██████████| 196/196 [00:05<00:00, 38.36batch/s, acc=54.43%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.43% | Remaining weights: 30.78% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 39: 100%|██████████| 196/196 [00:07<00:00, 26.03batch/s, loss=2.8344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.8551 | Reg=1.9793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 39: 100%|██████████| 196/196 [00:05<00:00, 38.73batch/s, acc=75.52%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.52% | Remaining weights: 28.95% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 40: 100%|██████████| 196/196 [00:07<00:00, 26.07batch/s, loss=3.8724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.2063 | Reg=2.6662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 40: 100%|██████████| 196/196 [00:05<00:00, 38.56batch/s, acc=54.56%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.56% | Remaining weights: 29.44% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 41: 100%|██████████| 196/196 [00:07<00:00, 26.03batch/s, loss=2.4767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.6962 | Reg=1.7805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 41: 100%|██████████| 196/196 [00:05<00:00, 38.35batch/s, acc=75.68%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.68% | Remaining weights: 27.59% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 42: 100%|██████████| 196/196 [00:07<00:00, 25.75batch/s, loss=3.3010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.8848 | Reg=2.4163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 42: 100%|██████████| 196/196 [00:05<00:00, 38.68batch/s, acc=59.66%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.66% | Remaining weights: 28.02% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 43: 100%|██████████| 196/196 [00:07<00:00, 25.83batch/s, loss=2.3353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7402 | Reg=1.5950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 43: 100%|██████████| 196/196 [00:05<00:00, 38.58batch/s, acc=76.06%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.06% | Remaining weights: 26.25% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 44: 100%|██████████| 196/196 [00:07<00:00, 25.87batch/s, loss=3.2159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9658 | Reg=2.2501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 44: 100%|██████████| 196/196 [00:05<00:00, 38.71batch/s, acc=53.51%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.51% | Remaining weights: 26.85% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 45: 100%|██████████| 196/196 [00:07<00:00, 25.38batch/s, loss=2.2311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7763 | Reg=1.4548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 45: 100%|██████████| 196/196 [00:05<00:00, 38.41batch/s, acc=76.33%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.33% | Remaining weights: 25.18% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 46: 100%|██████████| 196/196 [00:07<00:00, 25.58batch/s, loss=3.3386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.1741 | Reg=2.1645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 46: 100%|██████████| 196/196 [00:05<00:00, 38.29batch/s, acc=43.30%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 43.30% | Remaining weights: 25.86% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 47: 100%|██████████| 196/196 [00:07<00:00, 25.23batch/s, loss=2.1457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.8147 | Reg=1.3309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 47: 100%|██████████| 196/196 [00:05<00:00, 38.02batch/s, acc=76.39%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.39% | Remaining weights: 24.13% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 48: 100%|██████████| 196/196 [00:07<00:00, 25.36batch/s, loss=3.1541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.0646 | Reg=2.0894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 48: 100%|██████████| 196/196 [00:05<00:00, 38.18batch/s, acc=61.89%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.89% | Remaining weights: 24.99% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 49: 100%|██████████| 196/196 [00:07<00:00, 25.03batch/s, loss=1.9825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7631 | Reg=1.2194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 49: 100%|██████████| 196/196 [00:05<00:00, 38.11batch/s, acc=76.62%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.62% | Remaining weights: 23.28% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 50: 100%|██████████| 196/196 [00:07<00:00, 25.32batch/s, loss=3.0624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.1186 | Reg=1.9437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 50: 100%|██████████| 196/196 [00:05<00:00, 38.29batch/s, acc=54.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.75% | Remaining weights: 24.04% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 51: 100%|██████████| 196/196 [00:07<00:00, 25.45batch/s, loss=2.0437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9014 | Reg=1.1423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 51: 100%|██████████| 196/196 [00:05<00:00, 38.53batch/s, acc=76.80%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.80% | Remaining weights: 22.50% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 52: 100%|██████████| 196/196 [00:07<00:00, 25.89batch/s, loss=2.8642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.1141 | Reg=1.7501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 52: 100%|██████████| 196/196 [00:05<00:00, 38.76batch/s, acc=62.58%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.58% | Remaining weights: 23.18% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 53: 100%|██████████| 196/196 [00:07<00:00, 25.65batch/s, loss=1.9044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.8379 | Reg=1.0666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 53: 100%|██████████| 196/196 [00:05<00:00, 37.90batch/s, acc=76.72%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.72% | Remaining weights: 21.81% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 54: 100%|██████████| 196/196 [00:07<00:00, 25.76batch/s, loss=2.8847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.1240 | Reg=1.7608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 54: 100%|██████████| 196/196 [00:05<00:00, 38.35batch/s, acc=56.53%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.53% | Remaining weights: 22.58% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 55: 100%|██████████| 196/196 [00:07<00:00, 25.45batch/s, loss=1.8266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.8315 | Reg=0.9951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 55: 100%|██████████| 196/196 [00:05<00:00, 38.29batch/s, acc=76.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.79% | Remaining weights: 21.14% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 56: 100%|██████████| 196/196 [00:07<00:00, 25.12batch/s, loss=2.7393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.1344 | Reg=1.6049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 56: 100%|██████████| 196/196 [00:05<00:00, 38.22batch/s, acc=61.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.54% | Remaining weights: 21.77% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 57: 100%|██████████| 196/196 [00:07<00:00, 25.10batch/s, loss=1.6599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7120 | Reg=0.9479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 57: 100%|██████████| 196/196 [00:05<00:00, 38.36batch/s, acc=76.70%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.70% | Remaining weights: 20.55% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 58: 100%|██████████| 196/196 [00:07<00:00, 25.84batch/s, loss=2.4045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9864 | Reg=1.4181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 58: 100%|██████████| 196/196 [00:05<00:00, 38.15batch/s, acc=57.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.54% | Remaining weights: 21.01% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 59: 100%|██████████| 196/196 [00:07<00:00, 25.61batch/s, loss=1.7127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7721 | Reg=0.9405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 59: 100%|██████████| 196/196 [00:05<00:00, 38.76batch/s, acc=76.21%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.21% | Remaining weights: 20.13% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 60: 100%|██████████| 196/196 [00:07<00:00, 25.28batch/s, loss=2.3458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9672 | Reg=1.3786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 60: 100%|██████████| 196/196 [00:05<00:00, 38.77batch/s, acc=62.91%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.91% | Remaining weights: 20.50% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 61: 100%|██████████| 196/196 [00:07<00:00, 25.27batch/s, loss=1.6244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7318 | Reg=0.8926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 61: 100%|██████████| 196/196 [00:05<00:00, 38.54batch/s, acc=75.48%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.48% | Remaining weights: 19.61% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 62: 100%|██████████| 196/196 [00:07<00:00, 25.46batch/s, loss=2.0155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7104 | Reg=1.3051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 62: 100%|██████████| 196/196 [00:05<00:00, 38.77batch/s, acc=59.29%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.29% | Remaining weights: 19.94% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 63: 100%|██████████| 196/196 [00:07<00:00, 25.26batch/s, loss=1.9216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.0045 | Reg=0.9170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 63: 100%|██████████| 196/196 [00:05<00:00, 38.41batch/s, acc=74.20%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.20% | Remaining weights: 19.24% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 64: 100%|██████████| 196/196 [00:07<00:00, 25.39batch/s, loss=2.2756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.0977 | Reg=1.1779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 64: 100%|██████████| 196/196 [00:05<00:00, 38.80batch/s, acc=58.15%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.15% | Remaining weights: 19.30% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 65: 100%|██████████| 196/196 [00:07<00:00, 25.39batch/s, loss=1.8048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9292 | Reg=0.8757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 65: 100%|██████████| 196/196 [00:05<00:00, 38.37batch/s, acc=74.91%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.91% | Remaining weights: 18.90% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 66: 100%|██████████| 196/196 [00:07<00:00, 25.42batch/s, loss=2.2300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.1194 | Reg=1.1106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 66: 100%|██████████| 196/196 [00:05<00:00, 38.65batch/s, acc=60.22%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.22% | Remaining weights: 18.84% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 67: 100%|██████████| 196/196 [00:07<00:00, 25.59batch/s, loss=1.5277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.6433 | Reg=0.8844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 67: 100%|██████████| 196/196 [00:05<00:00, 38.98batch/s, acc=73.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.54% | Remaining weights: 18.60% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 68: 100%|██████████| 196/196 [00:07<00:00, 25.48batch/s, loss=2.0157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.0041 | Reg=1.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 68: 100%|██████████| 196/196 [00:05<00:00, 38.34batch/s, acc=61.61%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.61% | Remaining weights: 18.37% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 69: 100%|██████████| 196/196 [00:07<00:00, 25.59batch/s, loss=1.8178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.8886 | Reg=0.9292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 69: 100%|██████████| 196/196 [00:05<00:00, 38.08batch/s, acc=71.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.54% | Remaining weights: 18.39% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 70: 100%|██████████| 196/196 [00:07<00:00, 25.46batch/s, loss=1.6255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.6958 | Reg=0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 70: 100%|██████████| 196/196 [00:05<00:00, 37.93batch/s, acc=67.02%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.02% | Remaining weights: 17.96% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 71: 100%|██████████| 196/196 [00:07<00:00, 25.27batch/s, loss=1.9374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9985 | Reg=0.9389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 71: 100%|██████████| 196/196 [00:05<00:00, 38.04batch/s, acc=68.69%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.69% | Remaining weights: 18.15% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 72: 100%|██████████| 196/196 [00:07<00:00, 25.55batch/s, loss=1.6028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7996 | Reg=0.8032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 72: 100%|██████████| 196/196 [00:05<00:00, 38.06batch/s, acc=72.26%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.26% | Remaining weights: 17.56% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 73: 100%|██████████| 196/196 [00:07<00:00, 25.10batch/s, loss=1.7736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7896 | Reg=0.9840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 73: 100%|██████████| 196/196 [00:05<00:00, 37.94batch/s, acc=69.93%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.93% | Remaining weights: 17.97% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 74: 100%|██████████| 196/196 [00:07<00:00, 25.27batch/s, loss=1.3698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.6455 | Reg=0.7243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 74: 100%|██████████| 196/196 [00:05<00:00, 38.46batch/s, acc=68.99%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.99% | Remaining weights: 17.24% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 75: 100%|██████████| 196/196 [00:07<00:00, 25.41batch/s, loss=1.9790]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9851 | Reg=0.9939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 75: 100%|██████████| 196/196 [00:05<00:00, 38.34batch/s, acc=69.57%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.57% | Remaining weights: 17.82% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 76: 100%|██████████| 196/196 [00:07<00:00, 25.57batch/s, loss=1.6130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9531 | Reg=0.6599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 76: 100%|██████████| 196/196 [00:05<00:00, 38.41batch/s, acc=70.46%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.46% | Remaining weights: 16.99% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 77: 100%|██████████| 196/196 [00:07<00:00, 25.43batch/s, loss=1.7068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.6883 | Reg=1.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 77: 100%|██████████| 196/196 [00:05<00:00, 38.39batch/s, acc=68.48%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.48% | Remaining weights: 17.69% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 78: 100%|██████████| 196/196 [00:07<00:00, 25.32batch/s, loss=1.4754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.8600 | Reg=0.6154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 78: 100%|██████████| 196/196 [00:05<00:00, 38.93batch/s, acc=74.11%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.11% | Remaining weights: 16.80% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 79: 100%|██████████| 196/196 [00:07<00:00, 25.44batch/s, loss=2.0501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.0407 | Reg=1.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 79: 100%|██████████| 196/196 [00:05<00:00, 38.55batch/s, acc=65.20%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.20% | Remaining weights: 17.50% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 80: 100%|██████████| 196/196 [00:07<00:00, 25.67batch/s, loss=1.3416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7558 | Reg=0.5857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 80: 100%|██████████| 196/196 [00:05<00:00, 38.68batch/s, acc=76.84%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.84% | Remaining weights: 16.60% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 81: 100%|██████████| 196/196 [00:07<00:00, 25.38batch/s, loss=2.3743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.3263 | Reg=1.0480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 81: 100%|██████████| 196/196 [00:05<00:00, 38.61batch/s, acc=69.82%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.82% | Remaining weights: 17.44% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 82: 100%|██████████| 196/196 [00:07<00:00, 25.30batch/s, loss=1.2417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.6737 | Reg=0.5679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 82: 100%|██████████| 196/196 [00:05<00:00, 38.73batch/s, acc=78.17%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.17% | Remaining weights: 16.48% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 83: 100%|██████████| 196/196 [00:07<00:00, 25.62batch/s, loss=1.8326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7377 | Reg=1.0950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 83: 100%|██████████| 196/196 [00:05<00:00, 38.36batch/s, acc=63.12%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.12% | Remaining weights: 17.28% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 84: 100%|██████████| 196/196 [00:07<00:00, 25.57batch/s, loss=1.3843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.8342 | Reg=0.5501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 84: 100%|██████████| 196/196 [00:05<00:00, 38.61batch/s, acc=78.10%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.10% | Remaining weights: 16.29% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 85: 100%|██████████| 196/196 [00:07<00:00, 25.62batch/s, loss=1.7983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7403 | Reg=1.0580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 85: 100%|██████████| 196/196 [00:05<00:00, 38.30batch/s, acc=65.83%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.83% | Remaining weights: 17.12% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 86: 100%|██████████| 196/196 [00:07<00:00, 25.51batch/s, loss=1.2648]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7239 | Reg=0.5409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 86: 100%|██████████| 196/196 [00:05<00:00, 38.55batch/s, acc=78.83%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.83% | Remaining weights: 16.16% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 87: 100%|██████████| 196/196 [00:07<00:00, 25.45batch/s, loss=2.3026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.1298 | Reg=1.1727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 87: 100%|██████████| 196/196 [00:05<00:00, 38.91batch/s, acc=65.96%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.96% | Remaining weights: 17.11% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 88: 100%|██████████| 196/196 [00:07<00:00, 25.31batch/s, loss=1.2348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.6912 | Reg=0.5436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 88: 100%|██████████| 196/196 [00:05<00:00, 38.47batch/s, acc=79.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.88% | Remaining weights: 16.06% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 89: 100%|██████████| 196/196 [00:07<00:00, 25.43batch/s, loss=2.1509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.0536 | Reg=1.0973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 89: 100%|██████████| 196/196 [00:05<00:00, 38.75batch/s, acc=64.26%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.26% | Remaining weights: 16.88% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 90: 100%|██████████| 196/196 [00:07<00:00, 25.30batch/s, loss=1.2405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7038 | Reg=0.5367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 90: 100%|██████████| 196/196 [00:05<00:00, 38.76batch/s, acc=80.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.54% | Remaining weights: 15.93% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 91: 100%|██████████| 196/196 [00:07<00:00, 25.48batch/s, loss=2.0550]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.8499 | Reg=1.2050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 91: 100%|██████████| 196/196 [00:05<00:00, 38.39batch/s, acc=65.46%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.46% | Remaining weights: 16.92% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 92: 100%|██████████| 196/196 [00:07<00:00, 25.44batch/s, loss=1.2307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.6942 | Reg=0.5366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 92: 100%|██████████| 196/196 [00:05<00:00, 38.99batch/s, acc=80.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.54% | Remaining weights: 15.81% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 93: 100%|██████████| 196/196 [00:07<00:00, 25.61batch/s, loss=2.1410]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.0347 | Reg=1.1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 93: 100%|██████████| 196/196 [00:05<00:00, 38.86batch/s, acc=61.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.75% | Remaining weights: 16.69% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 94: 100%|██████████| 196/196 [00:07<00:00, 25.38batch/s, loss=1.2001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.6618 | Reg=0.5383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 94: 100%|██████████| 196/196 [00:05<00:00, 38.93batch/s, acc=81.15%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.15% | Remaining weights: 15.72% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 95: 100%|██████████| 196/196 [00:07<00:00, 25.31batch/s, loss=1.9488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.8387 | Reg=1.1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 95: 100%|██████████| 196/196 [00:05<00:00, 38.29batch/s, acc=67.47%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.47% | Remaining weights: 16.54% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 96: 100%|██████████| 196/196 [00:07<00:00, 25.32batch/s, loss=1.1792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.6540 | Reg=0.5252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 96: 100%|██████████| 196/196 [00:05<00:00, 38.39batch/s, acc=81.03%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.03% | Remaining weights: 15.54% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 97: 100%|██████████| 196/196 [00:07<00:00, 25.38batch/s, loss=2.4828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.3889 | Reg=1.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 97: 100%|██████████| 196/196 [00:05<00:00, 38.21batch/s, acc=65.97%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.97% | Remaining weights: 16.34% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 98: 100%|██████████| 196/196 [00:07<00:00, 25.29batch/s, loss=1.1184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.5858 | Reg=0.5326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 98: 100%|██████████| 196/196 [00:05<00:00, 38.35batch/s, acc=80.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.88% | Remaining weights: 15.48% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 99: 100%|██████████| 196/196 [00:07<00:00, 25.31batch/s, loss=2.1864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.0187 | Reg=1.1676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 99: 100%|██████████| 196/196 [00:05<00:00, 38.63batch/s, acc=67.77%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.77% | Remaining weights: 16.29% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 100: 100%|██████████| 196/196 [00:03<00:00, 53.18batch/s, loss=0.5966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.5966 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 100: 100%|██████████| 196/196 [00:02<00:00, 79.52batch/s, acc=81.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.54% | Remaining weights: 14.04% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 101: 100%|██████████| 196/196 [00:03<00:00, 52.15batch/s, loss=0.6617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.6617 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 101: 100%|██████████| 196/196 [00:02<00:00, 79.99batch/s, acc=76.14%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.14% | Remaining weights: 13.18% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 102: 100%|██████████| 196/196 [00:03<00:00, 52.76batch/s, loss=0.5068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.5068 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 102: 100%|██████████| 196/196 [00:02<00:00, 81.77batch/s, acc=83.59%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.59% | Remaining weights: 12.52% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 103: 100%|██████████| 196/196 [00:03<00:00, 53.31batch/s, loss=0.7891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7891 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 103: 100%|██████████| 196/196 [00:02<00:00, 79.25batch/s, acc=79.64%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.64% | Remaining weights: 12.23% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 104: 100%|██████████| 196/196 [00:03<00:00, 52.09batch/s, loss=0.7835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7835 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 104: 100%|██████████| 196/196 [00:02<00:00, 80.24batch/s, acc=84.72%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.72% | Remaining weights: 11.85% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 105: 100%|██████████| 196/196 [00:03<00:00, 52.51batch/s, loss=0.6559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.6559 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 105: 100%|██████████| 196/196 [00:02<00:00, 79.56batch/s, acc=81.57%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.57% | Remaining weights: 11.69% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 106: 100%|██████████| 196/196 [00:03<00:00, 52.73batch/s, loss=0.4323]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.4323 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 106: 100%|██████████| 196/196 [00:02<00:00, 80.64batch/s, acc=85.42%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.42% | Remaining weights: 11.42% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 107: 100%|██████████| 196/196 [00:03<00:00, 53.11batch/s, loss=0.5188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.5188 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 107: 100%|██████████| 196/196 [00:02<00:00, 80.47batch/s, acc=83.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.60% | Remaining weights: 11.33% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 108: 100%|██████████| 196/196 [00:03<00:00, 52.62batch/s, loss=0.5311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.5311 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 108: 100%|██████████| 196/196 [00:02<00:00, 79.15batch/s, acc=86.21%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.21% | Remaining weights: 11.10% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 109: 100%|██████████| 196/196 [00:03<00:00, 53.20batch/s, loss=0.5847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.5847 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 109: 100%|██████████| 196/196 [00:02<00:00, 80.43batch/s, acc=84.25%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.25% | Remaining weights: 11.04% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 110: 100%|██████████| 196/196 [00:03<00:00, 53.79batch/s, loss=0.3312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.3312 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 110: 100%|██████████| 196/196 [00:02<00:00, 81.51batch/s, acc=87.04%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.04% | Remaining weights: 10.85% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 111: 100%|██████████| 196/196 [00:03<00:00, 52.78batch/s, loss=0.5172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.5172 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 111: 100%|██████████| 196/196 [00:02<00:00, 82.05batch/s, acc=84.08%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.08% | Remaining weights: 10.81% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 112: 100%|██████████| 196/196 [00:03<00:00, 53.35batch/s, loss=0.5172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.5172 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 112: 100%|██████████| 196/196 [00:02<00:00, 81.63batch/s, acc=87.18%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.18% | Remaining weights: 10.65% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 113: 100%|██████████| 196/196 [00:03<00:00, 52.80batch/s, loss=0.4123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.4123 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 113: 100%|██████████| 196/196 [00:02<00:00, 81.11batch/s, acc=85.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.54% | Remaining weights: 10.62% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 114: 100%|██████████| 196/196 [00:03<00:00, 52.74batch/s, loss=0.5364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.5364 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 114: 100%|██████████| 196/196 [00:02<00:00, 81.69batch/s, acc=87.36%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.36% | Remaining weights: 10.47% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 115: 100%|██████████| 196/196 [00:03<00:00, 52.62batch/s, loss=0.4361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.4361 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 115: 100%|██████████| 196/196 [00:02<00:00, 81.20batch/s, acc=86.77%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.77% | Remaining weights: 10.45% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 116: 100%|██████████| 196/196 [00:03<00:00, 52.49batch/s, loss=0.3802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.3802 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 116: 100%|██████████| 196/196 [00:02<00:00, 80.58batch/s, acc=88.14%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.14% | Remaining weights: 10.32% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 117: 100%|██████████| 196/196 [00:03<00:00, 52.78batch/s, loss=0.4123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.4123 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 117: 100%|██████████| 196/196 [00:02<00:00, 79.19batch/s, acc=87.22%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.22% | Remaining weights: 10.30% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 118: 100%|██████████| 196/196 [00:03<00:00, 52.62batch/s, loss=0.6124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.6124 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 118: 100%|██████████| 196/196 [00:02<00:00, 79.65batch/s, acc=88.41%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.41% | Remaining weights: 10.18% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 119: 100%|██████████| 196/196 [00:03<00:00, 52.06batch/s, loss=0.5266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.5266 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 119: 100%|██████████| 196/196 [00:02<00:00, 77.87batch/s, acc=88.06%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.06% | Remaining weights: 10.17% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 120: 100%|██████████| 196/196 [00:03<00:00, 52.07batch/s, loss=0.3990]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.3990 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 120: 100%|██████████| 196/196 [00:02<00:00, 80.91batch/s, acc=88.49%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.49% | Remaining weights: 10.06% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 121: 100%|██████████| 196/196 [00:03<00:00, 52.51batch/s, loss=0.3918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.3918 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 121: 100%|██████████| 196/196 [00:02<00:00, 82.38batch/s, acc=89.06%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.06% | Remaining weights: 10.05% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 122: 100%|██████████| 196/196 [00:03<00:00, 52.42batch/s, loss=0.6368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.6368 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 122: 100%|██████████| 196/196 [00:02<00:00, 80.18batch/s, acc=88.82%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.82% | Remaining weights: 9.95% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 123: 100%|██████████| 196/196 [00:03<00:00, 52.07batch/s, loss=0.3721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.3721 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 123: 100%|██████████| 196/196 [00:02<00:00, 81.41batch/s, acc=89.67%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.67% | Remaining weights: 9.94% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 124: 100%|██████████| 196/196 [00:03<00:00, 53.51batch/s, loss=0.5262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.5262 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 124: 100%|██████████| 196/196 [00:02<00:00, 79.34batch/s, acc=89.08%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.08% | Remaining weights: 9.84% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 125: 100%|██████████| 196/196 [00:03<00:00, 52.58batch/s, loss=0.4540]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.4540 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 125: 100%|██████████| 196/196 [00:02<00:00, 79.76batch/s, acc=90.40%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.40% | Remaining weights: 9.83% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 126: 100%|██████████| 196/196 [00:03<00:00, 52.84batch/s, loss=0.3604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.3604 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 126: 100%|██████████| 196/196 [00:02<00:00, 80.53batch/s, acc=89.43%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.43% | Remaining weights: 9.75% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 127: 100%|██████████| 196/196 [00:03<00:00, 53.31batch/s, loss=0.3222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.3222 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 127: 100%|██████████| 196/196 [00:02<00:00, 80.05batch/s, acc=90.64%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.64% | Remaining weights: 9.74% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 128: 100%|██████████| 196/196 [00:03<00:00, 52.21batch/s, loss=0.4401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.4401 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 128: 100%|██████████| 196/196 [00:02<00:00, 80.13batch/s, acc=89.35%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.35% | Remaining weights: 9.67% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ‖ Epoch 129: 100%|██████████| 196/196 [00:03<00:00, 52.63batch/s, loss=0.3618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.3618 | Reg=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   ‖ Epoch 129: 100%|██████████| 196/196 [00:02<00:00, 80.53batch/s, acc=90.94%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.94% | Remaining weights: 9.66% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pquant import iterative_train\n",
    "\"\"\"\n",
    "Inputs to train_resnet we defined previously are:\n",
    "          model, trainloader, device, loss_func, epoch, optimizer, scheduler, **kwargs\n",
    "\"\"\"\n",
    "\n",
    "trained_model = iterative_train(model = model, \n",
    "                                config = config, \n",
    "                                train_func = train_resnet, \n",
    "                                valid_func = validate_resnet, \n",
    "                                trainloader = train_loader, \n",
    "                                testloader = val_loader, \n",
    "                                device = device, \n",
    "                                loss_func = loss_function,\n",
    "                                optimizer = optimizer, \n",
    "                                scheduler = scheduler\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd70fed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_403428/1596906618.py:29: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax[0].set_yticklabels(new_ytick)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pquant import remove_pruning_from_model\n",
    "import matplotlib.pyplot as plt\n",
    "# Remove compression layers, leaves Quantized activations in place\n",
    "model = remove_pruning_from_model(trained_model, config)\n",
    "\n",
    "# Plot remaining weights\n",
    "names = []\n",
    "remaining = []\n",
    "total_w = []\n",
    "nonzeros = []\n",
    "for n, m in trained_model.named_modules():\n",
    "    if isinstance(m, (torch.nn.Conv1d, torch.nn.Conv2d, torch.nn.Linear)):\n",
    "        names.append(n)\n",
    "        nonzero = np.count_nonzero(m.weight.detach().cpu())\n",
    "        remaining_pct = nonzero / m.weight.numel()\n",
    "        remaining.append(remaining_pct)\n",
    "        total_w.append(m.weight.numel())\n",
    "        nonzeros.append(nonzero)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].bar(range(len(names)), remaining)\n",
    "ax[0].set_xticks(range(len(names)))\n",
    "ax[0].set_xticklabels(names)\n",
    "ax[0].tick_params(axis='x', labelrotation=270)\n",
    "new_ytick = []\n",
    "for i in ax[0].get_yticklabels():\n",
    "    ytick = f\"{float(i.get_text()) * 100:.2f}%\"\n",
    "    new_ytick.append(ytick)\n",
    "ax[0].set_yticklabels(new_ytick)\n",
    "ax[0].title.set_text(\"Remaining weights per layer\")\n",
    "\n",
    "ax[1].bar(range(len(nonzeros)), total_w, color=\"lightcoral\", label=\"total weights\")\n",
    "ax[1].bar(range(len(nonzeros)), nonzeros, color=\"steelblue\", label=\"nonzero weights\")\n",
    "ax[1].set_xticks(range(len(names)))\n",
    "ax[1].set_xticklabels(names)\n",
    "ax[1].tick_params(axis='x', labelrotation=270)\n",
    "ax[1].title.set_text(\"Weights per layer\")\n",
    "ax[1].legend()\n",
    "ax[1].set_yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19fe7f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_conv_patterns(model):\n",
    "    \"\"\"\n",
    "    Extracts unique binary patterns and their counts from convolutional layers\n",
    "    of a given model in a backend-agnostic way.\n",
    "\n",
    "    Args:\n",
    "        model: A Keras or PyTorch model.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary where keys are the names of convolutional layers and\n",
    "        values are another dictionary containing:\n",
    "        - 'patterns': A NumPy array of the unique binary patterns.\n",
    "        - 'counts': A NumPy array with the count for each unique pattern.\n",
    "        - 'kernel_shape': The original (height, width) of the kernel.\n",
    "    \"\"\"\n",
    "    patterns_by_layer = {}\n",
    "    backend = keras.backend.backend()\n",
    "\n",
    "    # Iterate through model layers/modules\n",
    "    if backend == \"torch\":\n",
    "        modules = model.named_modules()\n",
    "    else: # TensorFlow\n",
    "        modules = [(layer.name, layer) for layer in model.layers]\n",
    "\n",
    "    for name, module in modules:\n",
    "        is_conv_layer = False\n",
    "        if backend == \"torch\" and isinstance(module, (keras.layers.Conv2D, torch.nn.Conv2d)):\n",
    "            weight = module.weight.detach()\n",
    "            is_conv_layer = len(weight.shape) == 4\n",
    "        elif backend == \"tensorflow\" and isinstance(module, keras.layers.Conv2D):\n",
    "            weight = module.kernel\n",
    "            is_conv_layer = True\n",
    "\n",
    "        if is_conv_layer:\n",
    "            all_patterns_flat = keras.ops.reshape(weight, (weight.shape[0], -1))\n",
    "            all_patterns_binary = keras.ops.cast(all_patterns_flat > 0, dtype=\"float32\")\n",
    "\n",
    "            num_bits = all_patterns_binary.shape[1]\n",
    "            if num_bits == 0:\n",
    "                continue\n",
    "\n",
    "            powers_of_2 = keras.ops.power(2.0, keras.ops.arange(num_bits, dtype=\"float32\"))\n",
    "            hashes = keras.ops.sum(all_patterns_binary * powers_of_2, axis=1)\n",
    "\n",
    "            unique_hashes, counts = np.unique(keras.ops.convert_to_numpy(hashes), return_counts=True)\n",
    "            unique_patterns_binary = ((unique_hashes[:, None] & (1 << np.arange(num_bits))) > 0).astype(float)\n",
    "            \n",
    "            sort_indices = np.argsort(counts)[::-1]\n",
    "            patterns_by_layer[name] = {\n",
    "                'patterns': unique_patterns_binary[sort_indices],\n",
    "                'counts': counts[sort_indices],\n",
    "                'kernel_shape': (weight.shape[2], weight.shape[3])\n",
    "            }\n",
    "            print(f\"Processed layer '{name}', found {len(counts)} unique patterns.\")\n",
    "\n",
    "    return patterns_by_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae1039e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def visualize_conv_patterns(model, layer_name, max_patterns_to_show=16):\n",
    "    \"\"\"\n",
    "    Visualizes the dominant binary patterns for a specific convolutional layer.\n",
    "    \"\"\"\n",
    "    target_module = None\n",
    "    for name, module in model.named_modules():\n",
    "        if name == layer_name and hasattr(module, \"pruning_layer\"):\n",
    "            pruning_layer = module.pruning_layer\n",
    "            if hasattr(pruning_layer, \"metric_fn\") and \"PACAPattern\" in pruning_layer.metric_fn.__class__.__name__:\n",
    "                target_module = module\n",
    "                break\n",
    "    \n",
    "    if target_module is None:\n",
    "        print(f\"Error: Could not find a PACA-pruned layer named '{layer_name}'.\")\n",
    "        return\n",
    "        \n",
    "    metric_fn = target_module.pruning_layer.metric_fn\n",
    "    # Ensure dominant patterns are selected based on the final weights\n",
    "    metric_fn._select_dominant_patterns(target_module.weight)\n",
    "    \n",
    "    patterns = metric_fn.dominant_patterns\n",
    "    if patterns is None or patterns.shape[0] == 0:\n",
    "        print(f\"No dominant patterns found for layer '{layer_name}'.\")\n",
    "        return\n",
    "        \n",
    "    # Convert to NumPy for plotting\n",
    "    patterns_np = keras.ops.convert_to_numpy(patterns)\n",
    "    \n",
    "    # Get original kernel shape from the weight tensor\n",
    "    kernel_h, kernel_w = target_module.weight.shape[2], target_module.weight.shape[3]\n",
    "    \n",
    "    num_patterns = min(patterns_np.shape[0], max_patterns_to_show)\n",
    "    \n",
    "    # Create a subplot grid for the patterns\n",
    "    cols = math.ceil(math.sqrt(num_patterns))\n",
    "    rows = math.ceil(num_patterns / cols)\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n",
    "    if isinstance(axes, plt.Axes):\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    \n",
    "    fig.suptitle(f\"Dominant Patterns for Layer: {layer_name} (found {patterns_np.shape[0]})\", fontsize=16)\n",
    "    \n",
    "    for i in range(num_patterns):\n",
    "        pattern_2d = patterns_np[i].reshape(kernel_h, kernel_w)\n",
    "        print(pattern_2d.shape)\n",
    "        print(pattern_2d)\n",
    "        axes[i].imshow(pattern_2d, cmap='binary', vmin=0, vmax=1)\n",
    "        axes[i].set_title(f\"Pattern {i+1}\")\n",
    "        axes[i].set_xticks([])\n",
    "        axes[i].set_yticks([])\n",
    "        \n",
    "    # Hide any unused subplots\n",
    "    for j in range(num_patterns, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "        \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251515c3-00ac-4110-b8d8-a8c9100f6e6b",
   "metadata": {},
   "source": [
    "## Add PACA prunning\n",
    "#### After pruning we will have multiple patterns, so we force all of them to have a lower num,ber of dominant patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5898e23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "batch_size": 128,
       "cosine_tmax": 200,
       "gamma": 0.1,
       "l2_decay": 0.0001,
       "label_smoothing": 0,
       "lr": 0.001,
       "lr_schedule": "multistep",
       "milestones": [
        75,
        120
       ],
       "momentum": 0.9,
       "optimizer": "sgd",
       "plot_frequency": 100,
       "pruning_parameters": {
        "beta": 0.75,
        "damping": 1,
        "disable_pruning_for_layers": [
         null
        ],
        "distance_metric": "valued_hamming",
        "enable_pruning": true,
        "epsilon": 0.001,
        "metric_type": "PACAPatternSparsity",
        "num_patterns_to_keep": 16,
        "pruning_method": "mdmm",
        "scale": "1e-5",
        "use_grad": false
       },
       "quantization_parameters": {
        "default_fractional_bits": 7,
        "default_integer_bits": 0,
        "enable_quantization": false,
        "hgq_gamma": 0.0003,
        "hgq_heterogeneous": true,
        "layer_specific": [],
        "use_high_granularity_quantization": false,
        "use_real_tanh": false,
        "use_symmetric_quantization": false
       },
       "training_parameters": {
        "epochs": 200,
        "fine_tuning_epochs": 30,
        "pretraining_epochs": 0,
        "pruning_first": false,
        "rewind": "never",
        "rounds": 1,
        "save_weights_epoch": -1
       }
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml \n",
    "\n",
    "with open(\"pquant/configs/config_mdmm_paca.yaml\", 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "JSON(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8da0c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE_PATH = 'resnet_paca_pruned.pth'\n",
    "# torch.save(trained_model.state_dict(), SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e857a26e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dtype: str128",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpquant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m add_compression_layers\n\u001b[1;32m      2\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m256\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43madd_compression_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m model\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/core/compressed_layers.py:25\u001b[0m, in \u001b[0;36madd_compression_layers\u001b[0;34m(model, config, input_shape)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mbackend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpquant\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_impl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressed_layers_torch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m         add_compression_layers_torch,\n\u001b[1;32m     23\u001b[0m     )\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43madd_compression_layers_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpquant\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_impl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressed_layers_tf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m add_compression_layers_tf\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/core/torch_impl/compressed_layers_torch.py:212\u001b[0m, in \u001b[0;36madd_compression_layers_torch\u001b[0;34m(model, config, input_shape)\u001b[0m\n\u001b[1;32m    210\u001b[0m model \u001b[38;5;241m=\u001b[39m add_quantized_activations_to_model_layer(model, config)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m# model = add_quantized_activations_to_model_functional(model, config)\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43madd_pruning_to_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m model \u001b[38;5;241m=\u001b[39m disable_pruning_from_layers(model, config)\n\u001b[1;32m    214\u001b[0m model \u001b[38;5;241m=\u001b[39m add_layer_specific_quantization_to_model(model, config)\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/core/torch_impl/compressed_layers_torch.py:316\u001b[0m, in \u001b[0;36madd_pruning_to_model\u001b[0;34m(module, config)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mConv2d:\n\u001b[1;32m    315\u001b[0m     sparse_layer \u001b[38;5;241m=\u001b[39m CompressedLayerConv2d(config, layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 316\u001b[0m     \u001b[43msparse_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpruning_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(module, name, sparse_layer)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mConv1d:\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/layers/layer.py:232\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[1;32m    231\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m current_path()\n\u001b[0;32m--> 232\u001b[0m     \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/pruning_methods/mdmm.py:492\u001b[0m, in \u001b[0;36mMDMM.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    482\u001b[0m common_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_fn,\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_value\u001b[39m\u001b[38;5;124m\"\u001b[39m: target_value,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.0\u001b[39m),\n\u001b[1;32m    489\u001b[0m }\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m constraint_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEquality\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 492\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraint_layer \u001b[38;5;241m=\u001b[39m \u001b[43mEqualityConstraint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcommon_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m constraint_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLessThanOrEqual\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraint_layer \u001b[38;5;241m=\u001b[39m LessThanOrEqualConstraint(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcommon_args)\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/pruning_methods/mdmm.py:103\u001b[0m, in \u001b[0;36mEqualityConstraint.__init__\u001b[0;34m(self, metric_fn, target_value, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, metric_fn, target_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_fn \u001b[38;5;241m=\u001b[39m metric_fn\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_value \u001b[38;5;241m=\u001b[39m target_value\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/pruning_methods/mdmm.py:32\u001b[0m, in \u001b[0;36mConstraint.__init__\u001b[0;34m(self, lmbda_init, scale, damping, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.0\u001b[39m))\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_weight\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscale\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     37\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdamping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m     39\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdamping\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     40\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(),\n\u001b[1;32m     41\u001b[0m     initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m shape, dtype: ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(damping, dtype\u001b[38;5;241m=\u001b[39mdtype),\n\u001b[1;32m     42\u001b[0m     trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlmbda \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m     45\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_lmbda\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     46\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(),\n\u001b[1;32m     47\u001b[0m     initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m shape, dtype: ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(lmbda_init, dtype\u001b[38;5;241m=\u001b[39mdtype),\n\u001b[1;32m     48\u001b[0m     trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_grad_\n\u001b[1;32m     49\u001b[0m )\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/layers/layer.py:575\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[0;34m(self, shape, initializer, dtype, trainable, autocast, regularizer, constraint, aggregation, overwrite_with_gradient, name)\u001b[0m\n\u001b[1;32m    573\u001b[0m initializer \u001b[38;5;241m=\u001b[39m initializers\u001b[38;5;241m.\u001b[39mget(initializer)\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, caller\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 575\u001b[0m     variable \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautocast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautocast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;66;03m# Will be added to layer.losses\u001b[39;00m\n\u001b[1;32m    585\u001b[0m variable\u001b[38;5;241m.\u001b[39mregularizer \u001b[38;5;241m=\u001b[39m regularizers\u001b[38;5;241m.\u001b[39mget(regularizer)\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/backend/common/variables.py:206\u001b[0m, in \u001b[0;36mVariable.__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(initializer):\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_shape(shape)\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_with_initializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize(initializer)\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/backend/common/variables.py:409\u001b[0m, in \u001b[0;36mVariable._initialize_with_initializer\u001b[0;34m(self, initializer)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_initialize_with_initializer\u001b[39m(\u001b[38;5;28mself\u001b[39m, initializer):\n\u001b[1;32m    408\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_to_tensor(\n\u001b[0;32m--> 409\u001b[0m         \u001b[43minitializer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m     )\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize(value)\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/pruning_methods/mdmm.py:35\u001b[0m, in \u001b[0;36mConstraint.__init__.<locals>.<lambda>\u001b[0;34m(shape, dtype)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.0\u001b[39m))\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m     33\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     34\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(),\n\u001b[0;32m---> 35\u001b[0m     initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m shape, dtype: \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     36\u001b[0m     trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdamping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m     39\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdamping\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     40\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(),\n\u001b[1;32m     41\u001b[0m     initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m shape, dtype: ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(damping, dtype\u001b[38;5;241m=\u001b[39mdtype),\n\u001b[1;32m     42\u001b[0m     trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlmbda \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m     45\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_lmbda\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     46\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(),\n\u001b[1;32m     47\u001b[0m     initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m shape, dtype: ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(lmbda_init, dtype\u001b[38;5;241m=\u001b[39mdtype),\n\u001b[1;32m     48\u001b[0m     trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_grad_\n\u001b[1;32m     49\u001b[0m )\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/ops/core.py:958\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse, ragged)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((x,)):\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ConvertToTensor(dtype\u001b[38;5;241m=\u001b[39mdtype, sparse\u001b[38;5;241m=\u001b[39msparse)(x)\n\u001b[0;32m--> 958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mragged\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mragged\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/backend/torch/core.py:229\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse, ragged)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39muint32:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Torch backend does not support uint32.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64)\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mstandardize_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbfloat16\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# Torch backend does not support converting bfloat16 ndarray.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    232\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbfloat16\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/backend/common/variables.py:578\u001b[0m, in \u001b[0;36mstandardize_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    575\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(dtype)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39mALLOWED_DTYPES:\n\u001b[0;32m--> 578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dtype\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid dtype: str128"
     ]
    }
   ],
   "source": [
    "from pquant import add_compression_layers\n",
    "input_shape = (256,3,32,32)\n",
    "model = model.to(device)\n",
    "model = add_compression_layers(model, config, input_shape)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0c3b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "[[0. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "(3, 3)\n",
      "[[1. 1. 0.]\n",
      " [0. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "(3, 3)\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "(3, 3)\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "(3, 3)\n",
      "[[0. 0. 0.]\n",
      " [1. 1. 0.]\n",
      " [1. 1. 1.]]\n",
      "(3, 3)\n",
      "[[0. 1. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 1. 1.]]\n",
      "(3, 3)\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 1. 1.]]\n",
      "(3, 3)\n",
      "[[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 1. 1.]]\n",
      "(3, 3)\n",
      "[[1. 1. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]]\n",
      "(3, 3)\n",
      "[[0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]]\n",
      "(3, 3)\n",
      "[[1. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 1. 1.]]\n",
      "(3, 3)\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 1. 1.]]\n",
      "(3, 3)\n",
      "[[1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 1. 1.]]\n",
      "(3, 3)\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 1. 1.]]\n",
      "(3, 3)\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [0. 1. 1.]]\n",
      "(3, 3)\n",
      "[[1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 1. 1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_conv_patterns(model, 'layer1.0.conv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c24bff-9937-4670-8cff-022ddc7a0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet(model, trainloader, device, loss_func, epoch, optimizer, scheduler, *args, **kwargs):\n",
    "    first_batch = True\n",
    "    for data in trainloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        inputs = quantizer(inputs, k=torch.tensor(1.), i=torch.tensor(0.), f=torch.tensor(7.)) # 8 bits input quantization\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        losses = get_model_losses(model, torch.tensor(0.).to(device))\n",
    "        loss += losses\n",
    "        loss.backward()\n",
    "\n",
    "        if first_batch:\n",
    "            print(\"\\n ---- Checking Loss values ----\")\n",
    "            print(\"Loss:\", loss_func(outputs, labels).item())\n",
    "            print(\"Model Losses:\", losses.item())\n",
    "            print(\"--------------------------------------------------\")\n",
    "\n",
    "            for name, module in model.named_modules():\n",
    "                if \"conv1\" in name and hasattr(module, \"pruning_layer\"):\n",
    "                    pruning_layer = module.pruning_layer\n",
    "                    if hasattr(pruning_layer, \"metric_fn\") and \"PACAPattern\" in pruning_layer.metric_fn.__class__.__name__:\n",
    "                        metric_fn = pruning_layer.metric_fn\n",
    "                        num_patterns = 0\n",
    "                        if metric_fn.dominant_patterns is not None:\n",
    "                            num_patterns = metric_fn.dominant_patterns.shape[0]\n",
    "\n",
    "                        total_dist = metric_fn(module.weight).item()\n",
    "                        num_kernels = module.weight.shape[0]\n",
    "                        avg_dist = total_dist / num_kernels if num_kernels > 0 else 0\n",
    "\n",
    "                        print(f\"--- PACA Stats for {name} at Epoch {epoch} ---\")\n",
    "                        print(f\"Num Patterns: {num_patterns}, Avg Pattern Dist: {avg_dist:.4f}\")\n",
    "                        print(\"--------------------------------------------------\\n\")\n",
    "                        break\n",
    "            first_batch = False\n",
    "\n",
    "        optimizer.step()\n",
    "        epoch += 1\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "def validate_resnet(model, testloader, device, loss_func, epoch, *args, **kwargs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_paca_patterns = 0\n",
    "    avg_paca_dist = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs = quantizer(inputs, k=torch.tensor(1.), i=torch.tensor(0.), f=torch.tensor(7.))\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        for name, module in model.named_modules():\n",
    "            if \"conv1\" in name and hasattr(module, \"pruning_layer\"):\n",
    "                pruning_layer = module.pruning_layer\n",
    "                if hasattr(pruning_layer, \"metric_fn\") and \"PACAPattern\" in pruning_layer.metric_fn.__class__.__name__:\n",
    "                    metric_fn = pruning_layer.metric_fn\n",
    "                    if metric_fn.dominant_patterns is not None:\n",
    "                        num_paca_patterns = metric_fn.dominant_patterns.shape[0]\n",
    "\n",
    "                    total_dist = metric_fn(module.weight).item()\n",
    "                    num_kernels = module.weight.shape[0]\n",
    "                    avg_paca_dist = total_dist / num_kernels if num_kernels > 0 else 0\n",
    "                    break\n",
    "\n",
    "        ratio = get_layer_keep_ratio(model)\n",
    "        print(f'Accuracy: {100 * correct / total:.2f}%, '\n",
    "              f'Remaining Weights: {ratio * 100:.2f}%, '\n",
    "              f'Num Patterns: {num_paca_patterns}, '\n",
    "              f'Avg Pattern Dist: {avg_paca_dist:.4f}')\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "train_loader, val_loader = get_cifar10_data(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d28865b-afdb-4773-be30-717486d9786a",
   "metadata": {},
   "source": [
    "## Create loss function, scheduler and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f88af88-ef7a-4d30-8cff-f39225d5a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0001, momentum=0.9)\n",
    "scheduler = CosineAnnealingLR(optimizer, 200)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850c23a-2abc-4904-9c69-859492b450a8",
   "metadata": {},
   "source": [
    "## Train model\n",
    "Training time. We use the train_compressed_model function from pquant to train. We need to provide some parameters such as training and validation functions, their input parameters, the model and the config file. The function automatically adds pruning layers and replaces activations with a quantized variant, trains the model, and removes the pruning layers after training is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f2414c-1f4d-4a30-a143-920497e60ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.3925909399986267\n",
      "Model Losses: 94639.1484375\n",
      "--------------------------------------------------\n",
      "--- PACA Stats for conv1 at Epoch 0 ---\n",
      "Num Patterns: 16, Avg Pattern Dist: 0.1093\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 10.00%, Remaining Weights: 100.00%, Num Patterns: 1, Avg Pattern Dist: nan\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: nan\n",
      "Model Losses: nan\n",
      "--------------------------------------------------\n",
      "--- PACA Stats for conv1 at Epoch 197 ---\n",
      "Num Patterns: 1, Avg Pattern Dist: nan\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 10.00%, Remaining Weights: 100.00%, Num Patterns: 1, Avg Pattern Dist: nan\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: nan\n",
      "Model Losses: nan\n",
      "--------------------------------------------------\n",
      "--- PACA Stats for conv1 at Epoch 394 ---\n",
      "Num Patterns: 1, Avg Pattern Dist: nan\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 10.00%, Remaining Weights: 100.00%, Num Patterns: 1, Avg Pattern Dist: nan\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: nan\n",
      "Model Losses: nan\n",
      "--------------------------------------------------\n",
      "--- PACA Stats for conv1 at Epoch 591 ---\n",
      "Num Patterns: 1, Avg Pattern Dist: nan\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 10.00%, Remaining Weights: 100.00%, Num Patterns: 1, Avg Pattern Dist: nan\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: nan\n",
      "Model Losses: nan\n",
      "--------------------------------------------------\n",
      "--- PACA Stats for conv1 at Epoch 1773 ---\n",
      "Num Patterns: 1, Avg Pattern Dist: nan\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 10.00%, Remaining Weights: 100.00%, Num Patterns: 1, Avg Pattern Dist: nan\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: nan\n",
      "Model Losses: nan\n",
      "--------------------------------------------------\n",
      "--- PACA Stats for conv1 at Epoch 1970 ---\n",
      "Num Patterns: 1, Avg Pattern Dist: nan\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 10.00%, Remaining Weights: 100.00%, Num Patterns: 1, Avg Pattern Dist: nan\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: nan\n",
      "Model Losses: nan\n",
      "--------------------------------------------------\n",
      "--- PACA Stats for conv1 at Epoch 2167 ---\n",
      "Num Patterns: 1, Avg Pattern Dist: nan\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpquant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m iterative_train\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mInputs to train_resnet we defined previously are:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m          model, trainloader, device, loss_func, epoch, optimizer, scheduler, **kwargs\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43miterative_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtrain_func\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_resnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mvalid_func\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidate_resnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/core/train.py:8\u001b[0m, in \u001b[0;36miterative_train\u001b[0;34m(model, config, train_func, valid_func, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mbackend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpquant\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_impl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain_torch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m iterative_train_torch\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterative_train_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpquant\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_impl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain_tf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m iterative_train_tf\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/core/torch_impl/train_torch.py:35\u001b[0m, in \u001b[0;36miterative_train_torch\u001b[0;34m(model, config, train_func, valid_func, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     save_weights_functions(model)\n\u001b[1;32m     34\u001b[0m pre_epoch_functions(model, e, training_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 35\u001b[0m \u001b[43mtrain_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     37\u001b[0m valid_func(model, epoch\u001b[38;5;241m=\u001b[39mepoch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m, in \u001b[0;36mtrain_resnet\u001b[0;34m(model, trainloader, device, loss_func, epoch, optimizer, scheduler, *args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m inputs \u001b[38;5;241m=\u001b[39m quantizer(inputs, k\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1.\u001b[39m), i\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.\u001b[39m), f\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m7.\u001b[39m)) \u001b[38;5;66;03m# 8 bits input quantization\u001b[39;00m\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(outputs, labels)\n\u001b[1;32m     10\u001b[0m losses \u001b[38;5;241m=\u001b[39m get_model_losses(model, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device))\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torchvision/models/resnet.py:275\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m--> 275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[1;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torchvision/models/resnet.py:96\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m---> 96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/core/torch_impl/compressed_layers_torch.py:161\u001b[0m, in \u001b[0;36mCompressedLayerConv2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 161\u001b[0m     weight, bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprune_and_quantize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpruning_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwanda\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpruning_layer\u001b[38;5;241m.\u001b[39mcollect_input(x, weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/core/torch_impl/compressed_layers_torch.py:119\u001b[0m, in \u001b[0;36mCompressedLayerBase.prune_and_quantize\u001b[0;34m(self, weight, bias)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     weight, bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantize(weight, bias)\n\u001b[0;32m--> 119\u001b[0m     weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weight, bias\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/core/torch_impl/compressed_layers_torch.py:110\u001b[0m, in \u001b[0;36mCompressedLayerBase.prune\u001b[0;34m(self, weight)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprune\u001b[39m(\u001b[38;5;28mself\u001b[39m, weight):\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_pruning:\n\u001b[0;32m--> 110\u001b[0m         weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpruning_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m weight\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/layers/layer.py:936\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    940\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/backend/torch/layer.py:41\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/ops/operation.py:58\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     54\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     55\u001b[0m         call_fn,\n\u001b[1;32m     56\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     57\u001b[0m     )\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/pruning_methods/mdmm.py:516\u001b[0m, in \u001b[0;36mMDMM.call\u001b[0;34m(self, weight)\u001b[0m\n\u001b[1;32m    514\u001b[0m         weight \u001b[38;5;241m=\u001b[39m weight \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_hard_mask(weight)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstraint_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weight\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/layers/layer.py:936\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    940\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/backend/torch/layer.py:41\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/ops/operation.py:58\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     54\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     55\u001b[0m         call_fn,\n\u001b[1;32m     56\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     57\u001b[0m     )\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/pruning_methods/mdmm.py:61\u001b[0m, in \u001b[0;36mConstraint.call\u001b[0;34m(self, weight)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, weight):\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculates the penalty from a given infeasibility measure.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m     raw_infeasibility \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_infeasibility\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     infeasibility \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipe_infeasibility(raw_infeasibility)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_grad_:\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/pruning_methods/mdmm.py:108\u001b[0m, in \u001b[0;36mEqualityConstraint.get_infeasibility\u001b[0;34m(self, weight)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_infeasibility\u001b[39m(\u001b[38;5;28mself\u001b[39m, weight):\n\u001b[0;32m--> 108\u001b[0m     metric_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     infeasibility \u001b[38;5;241m=\u001b[39m metric_value \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_value\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m# return ops.abs(infeasibility)\u001b[39;00m\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/pruning_methods/mdmm.py:411\u001b[0m, in \u001b[0;36mPACAPatternMetric.__call__\u001b[0;34m(self, weight)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(weight\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# For non-conv layers, return zero loss.\u001b[39;00m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\u001b[38;5;241m0.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select_dominant_patterns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pattern_distances(weight)\n\u001b[1;32m    413\u001b[0m min_distances \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmin(distances, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/pquant/pruning_methods/mdmm.py:362\u001b[0m, in \u001b[0;36mPACAPatternMetric._select_dominant_patterns\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m    359\u001b[0m sorted_unique_patterns \u001b[38;5;241m=\u001b[39m unique_patterns[sorted_indices_pdf]\n\u001b[1;32m    361\u001b[0m cdf \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcumsum(sorted_pdf)\n\u001b[0;32m--> 362\u001b[0m indices_where_cdf_exceeds_beta \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcdf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mshape(indices_where_cdf_exceeds_beta)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    364\u001b[0m     n_beta \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mshape(cdf)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/ops/numpy.py:6183\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(condition, x1, x2)\u001b[0m\n\u001b[1;32m   6181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((condition, x1, x2)):\n\u001b[1;32m   6182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Where()\u001b[38;5;241m.\u001b[39msymbolic_call(condition, x1, x2)\n\u001b[0;32m-> 6183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/keras/src/backend/torch/numpy.py:1605\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(condition, x1, x2)\u001b[0m\n\u001b[1;32m   1603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mwhere(condition, x1, x2)\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pquant import iterative_train\n",
    "\"\"\"\n",
    "Inputs to train_resnet we defined previously are:\n",
    "          model, trainloader, device, loss_func, epoch, optimizer, scheduler, **kwargs\n",
    "\"\"\"\n",
    "\n",
    "trained_model_paca = iterative_train(model = model, \n",
    "                                config = config, \n",
    "                                train_func = train_resnet, \n",
    "                                valid_func = validate_resnet, \n",
    "                                trainloader = train_loader, \n",
    "                                testloader = val_loader, \n",
    "                                device = device, \n",
    "                                loss_func = loss_function,\n",
    "                                optimizer = optimizer, \n",
    "                                scheduler = scheduler\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cdc72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_conv_patterns(model, 'layer1.0.conv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f651848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pquant-gpu-env]",
   "language": "python",
   "name": "conda-env-pquant-gpu-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
