{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5676e100-c255-4871-b167-01a788309112",
   "metadata": {},
   "source": [
    "## In this tutorial we create a CNN and dataloaders, and train / prune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27197caf-85a2-48b7-af76-a5ff943408ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 15:22:54.732414: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752067374.751299  879899 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752067374.757088  879899 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752067374.771854  879899 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752067374.771874  879899 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752067374.771876  879899 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752067374.771878  879899 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-09 15:22:54.776867: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "keras.backend.set_image_data_format(\"channels_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e520e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pquant\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.chdir(\"/home/das214/PQuant/mdmm_dev/src\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for f in os.listdir(os.getcwd()):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91e06ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, SeparableConv2D, Conv2D, AveragePooling2D, Flatten, Input, Activation\n",
    "from keras.models import Model\n",
    "\n",
    "def var_network(var, hidden, output):\n",
    "    var = Flatten()(var)\n",
    "    var = Dense(hidden)(var)\n",
    "    var = Activation(\"tanh\")(var)\n",
    "    var = Dense(hidden)(var)\n",
    "    var = Activation(\"tanh\")(var)\n",
    "    return Dense(output)(var)\n",
    "\n",
    "def conv_network(var, n_filters, kernel_size):\n",
    "    var = SeparableConv2D(n_filters,kernel_size)(var)\n",
    "    var = Activation(\"tanh\")(var)\n",
    "    var = Conv2D(n_filters,1)(var)\n",
    "    var = Activation(\"tanh\")(var)    \n",
    "    return var\n",
    "\n",
    "def CreateModel(shape, n_filters, kernel_size, pool_size, hidden, output):\n",
    "    x_base = x_in = Input(shape)\n",
    "    stack = conv_network(x_base,  n_filters, kernel_size)\n",
    "    stack = AveragePooling2D(\n",
    "        pool_size=(pool_size, pool_size), \n",
    "        strides=None, \n",
    "        padding=\"valid\", \n",
    "        data_format=None,        \n",
    "    )(stack)\n",
    "    stack = Activation(\"tanh\")(stack)\n",
    "    stack = var_network(stack, hidden=16, output=output)\n",
    "    model = Model(inputs=x_in, outputs=stack)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17959028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ separable_conv2d_6              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">238</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ separable_conv2d_6              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m)      │            \u001b[38;5;34m33\u001b[0m │\n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_26 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m)      │            \u001b[38;5;34m30\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_27 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_28 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_29 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_30 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │           \u001b[38;5;34m238\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,869</span> (7.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,869\u001b[0m (7.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,869</span> (7.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,869\u001b[0m (7.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=CreateModel(shape = (2,16,16), \n",
    "                  n_filters=5, kernel_size=3,\n",
    "                  pool_size=3, \n",
    "                  hidden=10,\n",
    "                  output = 14)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cd71c9-86b2-4911-aa71-bd18b1e75aa1",
   "metadata": {},
   "source": [
    "## Add pruning and quantization\n",
    "To add pruning and quantization, we need a config file that defines how to do that. Let's load a config file from pquant/configs/configs_pdp.yaml. The training function we use later will add the pruning layers and quantized activations automatically using this config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ec145f1-502c-4fd0-84ed-e87b84a27374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "batch_size": 128,
       "cosine_tmax": 200,
       "gamma": 0.1,
       "l2_decay": 0.0001,
       "label_smoothing": 0,
       "lr": 0.01,
       "lr_schedule": "multistep",
       "milestones": [
        75,
        120
       ],
       "momentum": 0.9,
       "optimizer": "sgd",
       "plot_frequency": 100,
       "pruning_parameters": {
        "constraint_type": "Equality",
        "damping": 1,
        "disable_pruning_for_layers": [
         null
        ],
        "enable_pruning": true,
        "epsilon": 0.001,
        "l0_mode": "coarse",
        "metric_type": "UnstructuredSparsity",
        "pruning_method": "mdmm",
        "rf": 1,
        "scale": 10,
        "target_sparsity": 0.9,
        "target_value": 0,
        "use_grad": false
       },
       "quantization_parameters": {
        "default_fractional_bits": 7,
        "default_integer_bits": 0,
        "enable_quantization": false,
        "hgq_gamma": 0.0003,
        "hgq_heterogeneous": true,
        "layer_specific": [],
        "use_high_granularity_quantization": false,
        "use_real_tanh": false,
        "use_symmetric_quantization": false
       },
       "training_parameters": {
        "epochs": 200,
        "fine_tuning_epochs": 30,
        "pretraining_epochs": 0,
        "pruning_first": false,
        "rewind": "never",
        "rounds": 1,
        "save_weights_epoch": -1
       }
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pquant import get_default_config\n",
    "from IPython.display import JSON\n",
    "\n",
    "# pruning_methods: \"autosparse, cl, cs, dst, pdp, wanda, mdmm\"\n",
    "pruning_method = \"mdmm\"\n",
    "config = get_default_config(pruning_method)\n",
    "JSON(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef3115-2f3d-43e1-a199-4a19d667f796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): CompressedLayerConv2d(\n",
       "    (pruning_layer): <MDMM name=mdmm, built=True>\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_1, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_2, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_3, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_4, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_5, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_6, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): CompressedLayerConv2d(\n",
       "          (pruning_layer): <MDMM name=mdmm_7, built=True>\n",
       "        )\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_8, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_9, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_10, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_11, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): CompressedLayerConv2d(\n",
       "          (pruning_layer): <MDMM name=mdmm_12, built=True>\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_13, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_14, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_15, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_16, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): CompressedLayerConv2d(\n",
       "          (pruning_layer): <MDMM name=mdmm_17, built=True>\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_18, built=True>\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): CompressedLayerConv2d(\n",
       "        (pruning_layer): <MDMM name=mdmm_19, built=True>\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): CompressedLayerLinear(\n",
       "    (pruning_layer): <MDMM name=mdmm_20, built=True>\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace layers with compressed layers\n",
    "from pquant import add_compression_layers\n",
    "input_shape = (1, 16, 16, 2)\n",
    "model = add_compression_layers(model, config, input_shape)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a7241c-0ebd-492c-b4d4-3b269e5afc4d",
   "metadata": {},
   "source": [
    "## Pruning and quantization in the config\n",
    "From the config we see that we are using the PDP pruning method, unstructured version. We aim for 80% weights pruned (sparsity 0.8), and we quantize the model to 8 bits (1 bit goes to sign). \n",
    "By default, all convolutional and linear layers, as well as activations will be quantized using the default values ```default_integer_bits``` and ```default_fractional_bits```. Similarly, by default all convolutional and linear layers will be pruned.\n",
    "\n",
    "We can disable pruning and/or quantization by setting the enable_pruning / enable_quantization to False. To change quantization bits for a specific layer, add the layers name to the list found in ```layer_specific```, followed by number of bits. To disable pruning for a single layer, add its name to the ```disable_pruning_for_layers``` list. \n",
    "\n",
    "We'll show later how to create a custom quantization / pruning config file from an existing config for a given model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bf6ec9-9fb3-4f56-bffc-8676341cde32",
   "metadata": {},
   "source": [
    "## About the different epochs\n",
    "\n",
    "The config defines 20 ```pretraining_epochs```, 100 ```epochs``` and 20 ```fine_tuning_epochs```. What happens during each of these training steps is algorithm specific. \n",
    "\n",
    "In PDP, the pretraining phase consists of training without pruning, followed by calculation of layerwise pruning budgets. After pretraining is finished and the layerwise pruning budgets have been calculated, the training with pruning begins. The mask during this training is a soft mask, consisting of values ranging between (and including) 0 and 1. \n",
    "\n",
    "The fine-tuning step in PDP is optional (not mentioned in the original paper), and during it the mask is fixed and rounded to 0s and 1s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251515c3-00ac-4110-b8d8-a8c9100f6e6b",
   "metadata": {},
   "source": [
    "## Create data set\n",
    "#### Let's create the data loader and the training and validation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90c24bff-9937-4670-8cff-022ddc7a0aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:03<00:00, 46302039.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def get_cifar10_data(batch_size):\n",
    "    normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    train_transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), \n",
    "                                          transforms.ToTensor(), normalize])\n",
    "    test_transform = transforms.Compose([transforms.ToTensor(), normalize])  \n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "    valset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                       download=True, transform=test_transform)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "from quantizers.fixed_point.fixed_point_ops import get_fixed_quantizer\n",
    "# Set up input quantizer\n",
    "quantizer = get_fixed_quantizer(overflow_mode=\"SAT\")\n",
    "\n",
    "\n",
    "def train_resnet(model, trainloader, device, loss_func, epoch, optimizer, scheduler, *args, **kwargs):\n",
    "    first_batch = True\n",
    "    for data in trainloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        inputs = quantizer(inputs, k=torch.tensor(1.), i=torch.tensor(0.), f=torch.tensor(7.)) # 8 bits input quantization\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        losses = get_model_losses(model, torch.tensor(0.).to(device))\n",
    "        loss += losses\n",
    "        loss.backward()\n",
    "        \n",
    "        if first_batch:\n",
    "            print(\"\\n ---- Checking Loss values ----\")\n",
    "            print(\"Loss:\", loss_func(outputs, labels).item())\n",
    "            print(\"Model Losses:\", losses.item())\n",
    "            print(\"--------------------------------------------------\")\n",
    "            print(f\"\\n--- Checking Gradients for lmbda at Epoch {epoch} ---\")\n",
    "            for name, module in model.named_modules():\n",
    "                if \"pruning_layer.constraint_layer.module\" in name and hasattr(module, \"lmbda\"):\n",
    "                    # Access the underlying tensor via the '.value' attribute\n",
    "                    underlying_tensor = module.lmbda.value\n",
    "                    grad_value = underlying_tensor.grad\n",
    "                    print(f\"Layer: {name}, lmbda: {underlying_tensor.item()}\")\n",
    "                    if grad_value is not None:\n",
    "                        print(f\"Layer: {name}, Gradient: {grad_value.item()}\")\n",
    "                    else:\n",
    "                        print(f\"Layer: {name}, Gradient: None\")\n",
    "                        \n",
    "                    break\n",
    "            print(\"--------------------------------------------------\\n\")\n",
    "            first_batch = False\n",
    "            \n",
    "        optimizer.step()\n",
    "        epoch += 1\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "from pquant import get_layer_keep_ratio, get_model_losses\n",
    "\n",
    "def validate_resnet(model, testloader, device, loss_func, epoch, *args, **kwargs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs = quantizer(inputs, k=torch.tensor(1.), i=torch.tensor(0.), f=torch.tensor(7.)) # 8 bits input quantization\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        ratio = get_layer_keep_ratio(model)\n",
    "        print(f'Accuracy: {100 * correct / total:.2f}%, remaining_weights: {ratio * 100:.2f}%')\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "train_loader, val_loader = get_cifar10_data(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d28865b-afdb-4773-be30-717486d9786a",
   "metadata": {},
   "source": [
    "## Create loss function, scheduler and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f88af88-ef7a-4d30-8cff-f39225d5a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0001, momentum=0.9)\n",
    "scheduler = CosineAnnealingLR(optimizer, 200)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850c23a-2abc-4904-9c69-859492b450a8",
   "metadata": {},
   "source": [
    "## Train model\n",
    "Training time. We use the train_compressed_model function from pquant to train. We need to provide some parameters such as training and validation functions, their input parameters, the model and the config file. The function automatically adds pruning layers and replaces activations with a quantized variant, trains the model, and removes the pruning layers after training is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18f2414c-1f4d-4a30-a143-920497e60ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 7.381867408752441\n",
      "Model Losses: 6.1617112159729\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 0 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 1.0016350746154785\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 48.45%, remaining_weights: 96.31%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.4272035360336304\n",
      "Model Losses: 13.90738296508789\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 197 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 1.692549705505371\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 46.08%, remaining_weights: 95.79%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.3812137842178345\n",
      "Model Losses: 17.715513229370117\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 394 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 2.184332847595215\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 58.70%, remaining_weights: 94.89%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.1874525547027588\n",
      "Model Losses: 17.93826675415039\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 591 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 2.445006847381592\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 55.45%, remaining_weights: 94.19%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.4042913913726807\n",
      "Model Losses: 18.813215255737305\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 788 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 2.69346284866333\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 63.69%, remaining_weights: 92.72%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.1718581914901733\n",
      "Model Losses: 16.624704360961914\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 985 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 2.897933006286621\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 55.20%, remaining_weights: 92.09%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.2212857007980347\n",
      "Model Losses: 17.264995574951172\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 1182 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 3.1192679405212402\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 66.83%, remaining_weights: 90.17%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.9576570391654968\n",
      "Model Losses: 14.737850189208984\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 1379 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 3.302802324295044\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 51.05%, remaining_weights: 89.60%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.3533490896224976\n",
      "Model Losses: 15.495598793029785\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 1576 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 3.49582576751709\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 68.20%, remaining_weights: 87.40%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.0316203832626343\n",
      "Model Losses: 13.193391799926758\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 1773 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 3.665933609008789\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 46.98%, remaining_weights: 86.93%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.3760179281234741\n",
      "Model Losses: 13.919857025146484\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 1970 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 3.843452215194702\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 67.18%, remaining_weights: 84.45%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.965886116027832\n",
      "Model Losses: 11.81355094909668\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 2167 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 3.996277093887329\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 52.57%, remaining_weights: 84.17%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.2664706707000732\n",
      "Model Losses: 12.600903511047363\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 2364 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 4.149644374847412\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 67.58%, remaining_weights: 81.48%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.940449595451355\n",
      "Model Losses: 10.75082778930664\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 2561 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 4.289775848388672\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 42.94%, remaining_weights: 81.18%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.24358332157135\n",
      "Model Losses: 11.373335838317871\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 2758 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 4.4309186935424805\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 66.90%, remaining_weights: 78.46%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.9517723321914673\n",
      "Model Losses: 9.835604667663574\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 2955 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 4.561779975891113\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 51.80%, remaining_weights: 78.08%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.1582865715026855\n",
      "Model Losses: 10.279292106628418\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 3152 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 4.684673309326172\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 65.58%, remaining_weights: 75.46%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.008854866027832\n",
      "Model Losses: 9.091619491577148\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 3349 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 4.813745021820068\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 59.66%, remaining_weights: 74.88%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.087447166442871\n",
      "Model Losses: 9.269918441772461\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 3546 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 4.917482376098633\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 66.65%, remaining_weights: 72.39%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.9853396415710449\n",
      "Model Losses: 8.308753967285156\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 3743 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 5.032981872558594\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 56.59%, remaining_weights: 71.80%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.1491903066635132\n",
      "Model Losses: 8.477404594421387\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 3940 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 5.132082939147949\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 63.91%, remaining_weights: 69.46%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.9869521260261536\n",
      "Model Losses: 7.664186477661133\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 4137 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 5.247113227844238\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 60.70%, remaining_weights: 68.56%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.1041706800460815\n",
      "Model Losses: 7.602200031280518\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 4334 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 5.33616304397583\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 66.07%, remaining_weights: 66.63%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.0905241966247559\n",
      "Model Losses: 7.09726095199585\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 4531 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 5.450108528137207\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 63.02%, remaining_weights: 65.47%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.9696081876754761\n",
      "Model Losses: 6.879305839538574\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 4728 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 5.533030033111572\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 58.62%, remaining_weights: 63.73%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.1324602365493774\n",
      "Model Losses: 6.547327041625977\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 4925 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 5.644649028778076\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 63.88%, remaining_weights: 62.37%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.9182525873184204\n",
      "Model Losses: 6.181056022644043\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 5122 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 5.721563339233398\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 62.14%, remaining_weights: 61.02%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.0946369171142578\n",
      "Model Losses: 6.050902366638184\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 5319 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 5.826486110687256\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 67.28%, remaining_weights: 59.47%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8738742470741272\n",
      "Model Losses: 5.593166828155518\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 5516 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 5.893636703491211\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 61.42%, remaining_weights: 58.53%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.9765946865081787\n",
      "Model Losses: 5.67402982711792\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 5713 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 6.0018310546875\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 69.17%, remaining_weights: 56.75%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8593281507492065\n",
      "Model Losses: 5.089023590087891\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 5910 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 6.063208103179932\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 61.31%, remaining_weights: 55.98%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.0344351530075073\n",
      "Model Losses: 5.294516563415527\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 6107 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 6.169462203979492\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 72.70%, remaining_weights: 54.09%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.9406042695045471\n",
      "Model Losses: 4.617823123931885\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 6304 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 6.224532127380371\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 62.99%, remaining_weights: 53.57%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.9711462259292603\n",
      "Model Losses: 4.895205974578857\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 6501 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 6.326258659362793\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 74.28%, remaining_weights: 51.70%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.9331888556480408\n",
      "Model Losses: 4.237473011016846\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 6698 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 6.380643367767334\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 61.87%, remaining_weights: 51.35%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8277404308319092\n",
      "Model Losses: 4.572026252746582\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 6895 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 6.479001998901367\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 74.92%, remaining_weights: 49.40%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7077975273132324\n",
      "Model Losses: 3.8792777061462402\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 7092 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 6.526852130889893\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 60.76%, remaining_weights: 49.13%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.131096363067627\n",
      "Model Losses: 4.272467136383057\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 7289 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 6.629488945007324\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 76.58%, remaining_weights: 47.15%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7027860879898071\n",
      "Model Losses: 3.546795606613159\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 7486 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 6.678660869598389\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 62.88%, remaining_weights: 47.01%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.1287778615951538\n",
      "Model Losses: 4.0149946212768555\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 7683 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 6.784971237182617\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 76.57%, remaining_weights: 45.05%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7287274599075317\n",
      "Model Losses: 3.2597527503967285\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 7880 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 6.83262825012207\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 57.64%, remaining_weights: 45.18%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.0404490232467651\n",
      "Model Losses: 3.7770867347717285\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 8077 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 6.934011936187744\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 77.86%, remaining_weights: 43.08%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6625791192054749\n",
      "Model Losses: 3.0046017169952393\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 8274 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 6.984060764312744\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 57.39%, remaining_weights: 43.31%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.9344286322593689\n",
      "Model Losses: 3.5295650959014893\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 8471 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 7.083836555480957\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 77.76%, remaining_weights: 41.25%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8274417519569397\n",
      "Model Losses: 2.7640469074249268\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 8668 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 7.133793354034424\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 64.05%, remaining_weights: 41.54%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.0148813724517822\n",
      "Model Losses: 3.2626309394836426\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 8865 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 7.223853588104248\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 78.40%, remaining_weights: 39.47%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7194416522979736\n",
      "Model Losses: 2.541274070739746\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 9062 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 7.2754669189453125\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 55.79%, remaining_weights: 39.78%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.0262031555175781\n",
      "Model Losses: 3.031036138534546\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 9259 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 7.363156318664551\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 78.33%, remaining_weights: 37.78%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6242156624794006\n",
      "Model Losses: 2.323930501937866\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 9456 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 7.415328502655029\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 52.88%, remaining_weights: 38.29%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.08330500125885\n",
      "Model Losses: 2.8489789962768555\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 9653 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 7.500481128692627\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 78.42%, remaining_weights: 36.38%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7432406544685364\n",
      "Model Losses: 2.162109375\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 9850 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 7.552418231964111\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 63.00%, remaining_weights: 36.82%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.998827338218689\n",
      "Model Losses: 2.681955575942993\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 10047 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 7.634130001068115\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 78.89%, remaining_weights: 34.94%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6859722137451172\n",
      "Model Losses: 1.9890141487121582\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 10244 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 7.687766075134277\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 60.99%, remaining_weights: 35.50%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.9459291696548462\n",
      "Model Losses: 2.530076742172241\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 10441 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 7.767671585083008\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 78.62%, remaining_weights: 33.67%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6909260153770447\n",
      "Model Losses: 1.8483351469039917\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 10638 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 7.821515083312988\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 63.75%, remaining_weights: 34.13%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.9881966710090637\n",
      "Model Losses: 2.3032689094543457\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 10835 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 7.8982157707214355\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 78.74%, remaining_weights: 32.51%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6802524328231812\n",
      "Model Losses: 1.7169108390808105\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 11032 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 7.951449871063232\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 58.27%, remaining_weights: 33.00%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.880268931388855\n",
      "Model Losses: 2.2032272815704346\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 11229 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 8.0264892578125\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 77.67%, remaining_weights: 31.42%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8081971406936646\n",
      "Model Losses: 1.6170586347579956\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 11426 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 8.0823335647583\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 54.17%, remaining_weights: 31.74%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.9261938333511353\n",
      "Model Losses: 2.0241920948028564\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 11623 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 8.152607917785645\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 78.54%, remaining_weights: 30.40%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6604217290878296\n",
      "Model Losses: 1.5205992460250854\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 11820 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 8.209067344665527\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 56.67%, remaining_weights: 30.70%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.962891697883606\n",
      "Model Losses: 1.9266000986099243\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 12017 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 8.28059196472168\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 77.08%, remaining_weights: 29.51%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8015444874763489\n",
      "Model Losses: 1.4497030973434448\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 12214 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 8.340235710144043\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 63.71%, remaining_weights: 29.51%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.826668381690979\n",
      "Model Losses: 1.7184689044952393\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 12411 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 8.403641700744629\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 76.62%, remaining_weights: 28.66%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7091946005821228\n",
      "Model Losses: 1.385261058807373\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 12608 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 8.464032173156738\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 59.61%, remaining_weights: 28.49%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.0788952112197876\n",
      "Model Losses: 1.5678949356079102\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 12805 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 8.51995849609375\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 75.84%, remaining_weights: 27.91%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7702509164810181\n",
      "Model Losses: 1.3397517204284668\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 13002 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 8.583282470703125\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 68.80%, remaining_weights: 27.60%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.983295738697052\n",
      "Model Losses: 1.4498721361160278\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 13199 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 8.638235092163086\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 75.66%, remaining_weights: 27.21%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.783710241317749\n",
      "Model Losses: 1.3076540231704712\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 13396 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 8.70252513885498\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 68.62%, remaining_weights: 26.72%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 1.0041489601135254\n",
      "Model Losses: 1.3266290426254272\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 13593 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 8.754683494567871\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 75.31%, remaining_weights: 26.58%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7375690937042236\n",
      "Model Losses: 1.2883274555206299\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 13790 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 8.82441234588623\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 70.29%, remaining_weights: 25.93%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.783433735370636\n",
      "Model Losses: 1.2075371742248535\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 13987 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 8.872699737548828\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 68.59%, remaining_weights: 26.00%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7113728523254395\n",
      "Model Losses: 1.2432266473770142\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 14184 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 8.940576553344727\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 72.07%, remaining_weights: 25.22%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7566051483154297\n",
      "Model Losses: 1.09331214427948\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 14381 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 8.982622146606445\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 75.14%, remaining_weights: 25.49%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8286242485046387\n",
      "Model Losses: 1.2183632850646973\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 14578 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.048185348510742\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 71.04%, remaining_weights: 24.63%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8163202404975891\n",
      "Model Losses: 1.0195621252059937\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 14775 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.088570594787598\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 72.42%, remaining_weights: 25.01%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7982461452484131\n",
      "Model Losses: 1.2495982646942139\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 14972 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.159882545471191\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 75.70%, remaining_weights: 24.06%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7456173300743103\n",
      "Model Losses: 0.9472084641456604\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 15169 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.194239616394043\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 71.17%, remaining_weights: 24.62%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8448691964149475\n",
      "Model Losses: 1.2118654251098633\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 15366 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.258623123168945\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 78.22%, remaining_weights: 23.58%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6201874613761902\n",
      "Model Losses: 0.8964270353317261\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 15563 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.295187950134277\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 66.42%, remaining_weights: 24.21%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.9014415144920349\n",
      "Model Losses: 1.2236565351486206\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 15760 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.36594295501709\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 79.27%, remaining_weights: 23.19%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6582849621772766\n",
      "Model Losses: 0.862046480178833\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 15957 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.400193214416504\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 68.46%, remaining_weights: 23.83%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8118067383766174\n",
      "Model Losses: 1.2319648265838623\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 16154 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.470876693725586\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 80.68%, remaining_weights: 22.72%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5296927690505981\n",
      "Model Losses: 0.8070644736289978\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 16351 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.502190589904785\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 67.28%, remaining_weights: 23.54%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7561831474304199\n",
      "Model Losses: 1.252364158630371\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 16548 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.572009086608887\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 80.34%, remaining_weights: 22.41%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.528443455696106\n",
      "Model Losses: 0.7923051714897156\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 16745 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.603521347045898\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 63.59%, remaining_weights: 23.26%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8225749731063843\n",
      "Model Losses: 1.2582975625991821\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 16942 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.673794746398926\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 81.49%, remaining_weights: 22.06%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7053194642066956\n",
      "Model Losses: 0.7677382230758667\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 17139 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.705721855163574\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 65.02%, remaining_weights: 22.88%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7921851277351379\n",
      "Model Losses: 1.2239623069763184\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 17336 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.76977825164795\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 81.09%, remaining_weights: 21.76%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6243874430656433\n",
      "Model Losses: 0.757280170917511\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 17533 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.801877975463867\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 67.74%, remaining_weights: 22.57%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7960591912269592\n",
      "Model Losses: 1.23490571975708\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 17730 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.866644859313965\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 81.89%, remaining_weights: 21.45%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6070716381072998\n",
      "Model Losses: 0.7419012784957886\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 17927 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.898972511291504\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 61.88%, remaining_weights: 22.34%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8784589171409607\n",
      "Model Losses: 1.2568336725234985\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 18124 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.965349197387695\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 82.25%, remaining_weights: 21.17%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.631399393081665\n",
      "Model Losses: 0.7319885492324829\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 18321 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 9.998788833618164\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 66.21%, remaining_weights: 21.96%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8723359704017639\n",
      "Model Losses: 1.2007681131362915\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 18518 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.062165260314941\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 82.19%, remaining_weights: 20.84%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6137380003929138\n",
      "Model Losses: 0.7177892923355103\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 18715 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.096578598022461\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 67.17%, remaining_weights: 21.64%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.9015247225761414\n",
      "Model Losses: 1.2129181623458862\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 18912 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.161992073059082\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 82.22%, remaining_weights: 20.56%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5666058659553528\n",
      "Model Losses: 0.7140838503837585\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 19109 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.199434280395508\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 65.82%, remaining_weights: 21.40%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8271473050117493\n",
      "Model Losses: 1.2206255197525024\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 19306 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.26563835144043\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 82.44%, remaining_weights: 20.30%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6136903762817383\n",
      "Model Losses: 0.6940582394599915\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 19503 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.303509712219238\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 63.05%, remaining_weights: 21.08%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8995329141616821\n",
      "Model Losses: 1.143215537071228\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 19700 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.359271049499512\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 82.81%, remaining_weights: 20.04%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6173575520515442\n",
      "Model Losses: 0.6848969459533691\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 19897 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.39883041381836\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 66.51%, remaining_weights: 20.72%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8492060899734497\n",
      "Model Losses: 1.1487089395523071\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 20094 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.461336135864258\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 82.51%, remaining_weights: 19.84%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5998971462249756\n",
      "Model Losses: 0.6746833920478821\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 20291 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.5005464553833\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 65.27%, remaining_weights: 20.39%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8903821706771851\n",
      "Model Losses: 1.0749152898788452\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 20488 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.55683422088623\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 82.57%, remaining_weights: 19.61%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5740230083465576\n",
      "Model Losses: 0.6647137999534607\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 20685 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.59783935546875\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 61.71%, remaining_weights: 20.12%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7795671820640564\n",
      "Model Losses: 1.0920928716659546\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 20882 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.657862663269043\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 82.34%, remaining_weights: 19.46%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5471622943878174\n",
      "Model Losses: 0.6504004001617432\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 21079 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.69881534576416\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 70.65%, remaining_weights: 19.80%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8505706191062927\n",
      "Model Losses: 0.9723954200744629\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 21276 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.748042106628418\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 82.70%, remaining_weights: 19.27%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5094663500785828\n",
      "Model Losses: 0.6524293422698975\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 21473 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.788315773010254\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 69.12%, remaining_weights: 19.57%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8406252861022949\n",
      "Model Losses: 0.9585803151130676\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 21670 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.837078094482422\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 81.76%, remaining_weights: 19.10%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5440636873245239\n",
      "Model Losses: 0.6717106699943542\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 21867 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.881731986999512\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 69.65%, remaining_weights: 19.23%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6853101253509521\n",
      "Model Losses: 0.8822130560874939\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 22064 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.9275541305542\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 80.82%, remaining_weights: 18.95%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5664010047912598\n",
      "Model Losses: 0.6639903783798218\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 22261 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 10.97066593170166\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 72.31%, remaining_weights: 18.93%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6651207804679871\n",
      "Model Losses: 0.8232789039611816\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 22458 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.011710166931152\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 81.07%, remaining_weights: 18.79%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5758170485496521\n",
      "Model Losses: 0.6761996150016785\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 22655 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.057621002197266\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 73.79%, remaining_weights: 18.59%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6899140477180481\n",
      "Model Losses: 0.760353147983551\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 22852 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.097819328308105\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 80.86%, remaining_weights: 18.69%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5256080031394958\n",
      "Model Losses: 0.6927481293678284\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 23049 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.145929336547852\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 72.07%, remaining_weights: 18.36%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7371253967285156\n",
      "Model Losses: 0.721185028553009\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 23246 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.184813499450684\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 80.35%, remaining_weights: 18.60%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5329357981681824\n",
      "Model Losses: 0.7161323428153992\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 23443 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.233325958251953\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 76.91%, remaining_weights: 18.12%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7151502370834351\n",
      "Model Losses: 0.6586316227912903\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 23640 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.267902374267578\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 79.09%, remaining_weights: 18.55%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6126556992530823\n",
      "Model Losses: 0.7480835318565369\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 23837 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.317116737365723\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 76.41%, remaining_weights: 17.95%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7329334020614624\n",
      "Model Losses: 0.6123796701431274\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 24034 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.348496437072754\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 76.52%, remaining_weights: 18.42%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6573028564453125\n",
      "Model Losses: 0.7440462708473206\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 24231 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.397954940795898\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 78.08%, remaining_weights: 17.78%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6347586512565613\n",
      "Model Losses: 0.5794310569763184\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 24428 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.427535057067871\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 76.38%, remaining_weights: 18.35%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6623498797416687\n",
      "Model Losses: 0.7906672954559326\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 24625 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.479702949523926\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 79.87%, remaining_weights: 17.67%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5788627862930298\n",
      "Model Losses: 0.5773303508758545\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 24822 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.510336875915527\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 76.47%, remaining_weights: 18.32%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7009515166282654\n",
      "Model Losses: 0.8163928985595703\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 25019 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.561525344848633\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 79.46%, remaining_weights: 17.55%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5833098888397217\n",
      "Model Losses: 0.549716591835022\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 25216 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.58967399597168\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 74.68%, remaining_weights: 18.27%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7868412733078003\n",
      "Model Losses: 0.8543305993080139\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 25413 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.643400192260742\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 82.25%, remaining_weights: 17.48%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5254569053649902\n",
      "Model Losses: 0.5466224551200867\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 25610 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.671353340148926\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 67.84%, remaining_weights: 18.22%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6214184761047363\n",
      "Model Losses: 0.8727496862411499\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 25807 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.72495174407959\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 83.74%, remaining_weights: 17.40%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.512681782245636\n",
      "Model Losses: 0.5305452942848206\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 26004 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.7513427734375\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 75.00%, remaining_weights: 18.17%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7307019233703613\n",
      "Model Losses: 0.8875747919082642\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 26201 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.803688049316406\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 84.39%, remaining_weights: 17.32%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5865941047668457\n",
      "Model Losses: 0.5268465876579285\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 26398 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.829331398010254\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 69.42%, remaining_weights: 18.18%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8130632042884827\n",
      "Model Losses: 0.9524644613265991\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 26595 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.883992195129395\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 83.64%, remaining_weights: 17.30%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.48887526988983154\n",
      "Model Losses: 0.5433266758918762\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 26792 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.911575317382812\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 67.58%, remaining_weights: 18.06%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7563343048095703\n",
      "Model Losses: 0.9225268363952637\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 26989 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.963981628417969\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 84.91%, remaining_weights: 17.23%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.4073229432106018\n",
      "Model Losses: 0.5424318909645081\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 27186 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 11.991110801696777\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 71.05%, remaining_weights: 18.08%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7688016891479492\n",
      "Model Losses: 1.001529335975647\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 27383 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.04564094543457\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 85.52%, remaining_weights: 17.13%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5199790000915527\n",
      "Model Losses: 0.5446022748947144\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 27580 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.073111534118652\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 71.53%, remaining_weights: 18.03%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7224931120872498\n",
      "Model Losses: 1.0594137907028198\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 27777 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.129389762878418\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 85.67%, remaining_weights: 17.05%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5880287885665894\n",
      "Model Losses: 0.5468512177467346\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 27974 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.157751083374023\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 73.15%, remaining_weights: 17.94%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8531529307365417\n",
      "Model Losses: 1.0241681337356567\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 28171 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.211042404174805\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 85.79%, remaining_weights: 16.99%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.41432198882102966\n",
      "Model Losses: 0.5555312633514404\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 28368 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.241050720214844\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 72.33%, remaining_weights: 17.72%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6806631088256836\n",
      "Model Losses: 0.9738467931747437\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 28565 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.291537284851074\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 85.83%, remaining_weights: 16.92%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.43295714259147644\n",
      "Model Losses: 0.5597861409187317\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 28762 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.321681022644043\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 71.48%, remaining_weights: 17.60%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6646466851234436\n",
      "Model Losses: 0.9518247842788696\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 28959 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.368012428283691\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 85.90%, remaining_weights: 16.79%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.4380947947502136\n",
      "Model Losses: 0.5543389320373535\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 29156 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.399917602539062\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 68.83%, remaining_weights: 17.60%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8234029412269592\n",
      "Model Losses: 1.0314959287643433\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 29353 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.451997756958008\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 85.95%, remaining_weights: 16.76%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.4706041216850281\n",
      "Model Losses: 0.5678372383117676\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 29550 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.485828399658203\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 68.34%, remaining_weights: 17.37%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.8459484577178955\n",
      "Model Losses: 0.9495375156402588\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 29747 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.533028602600098\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 85.99%, remaining_weights: 16.65%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5015460848808289\n",
      "Model Losses: 0.5641862154006958\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 29944 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.567327499389648\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 73.95%, remaining_weights: 17.15%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7129452228546143\n",
      "Model Losses: 0.8992061614990234\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 30141 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.61097526550293\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 86.11%, remaining_weights: 16.54%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.46550053358078003\n",
      "Model Losses: 0.563023567199707\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 30338 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.644543647766113\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 71.18%, remaining_weights: 16.94%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.667304277420044\n",
      "Model Losses: 0.8701609969139099\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 30535 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.68679141998291\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 86.38%, remaining_weights: 16.36%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.4500546455383301\n",
      "Model Losses: 0.5511148571968079\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 30732 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.72083854675293\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 71.43%, remaining_weights: 16.74%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7761747241020203\n",
      "Model Losses: 0.8649184703826904\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 30929 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.762554168701172\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 85.79%, remaining_weights: 16.26%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.49174585938453674\n",
      "Model Losses: 0.5690180659294128\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 31126 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.798876762390137\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 73.94%, remaining_weights: 16.43%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6576996445655823\n",
      "Model Losses: 0.7660847306251526\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 31323 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.836633682250977\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 85.90%, remaining_weights: 16.19%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5142594575881958\n",
      "Model Losses: 0.582141637802124\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 31520 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.872597694396973\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 67.01%, remaining_weights: 16.32%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7079930305480957\n",
      "Model Losses: 0.8215470910072327\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 31717 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.916900634765625\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 85.84%, remaining_weights: 16.10%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.4300187826156616\n",
      "Model Losses: 0.58211350440979\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 31914 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.955048561096191\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 76.35%, remaining_weights: 16.11%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6784873604774475\n",
      "Model Losses: 0.7247148156166077\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 32111 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 12.991290092468262\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 84.86%, remaining_weights: 16.08%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.44259974360466003\n",
      "Model Losses: 0.6071369647979736\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 32308 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.02914810180664\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 75.31%, remaining_weights: 15.95%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6615126132965088\n",
      "Model Losses: 0.687920331954956\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 32505 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.062897682189941\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 84.52%, remaining_weights: 16.07%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.3858930468559265\n",
      "Model Losses: 0.6310100555419922\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 32702 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.103654861450195\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 72.76%, remaining_weights: 15.79%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5875375270843506\n",
      "Model Losses: 0.6278977990150452\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 32899 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.135007858276367\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 82.71%, remaining_weights: 16.05%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5412635803222656\n",
      "Model Losses: 0.6429983973503113\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 33096 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.175281524658203\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 79.86%, remaining_weights: 15.66%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.48852047324180603\n",
      "Model Losses: 0.5793286561965942\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 33293 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.204988479614258\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 80.88%, remaining_weights: 15.99%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5254049897193909\n",
      "Model Losses: 0.6640142202377319\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 33490 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.247069358825684\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 82.24%, remaining_weights: 15.55%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5026002526283264\n",
      "Model Losses: 0.5699049234390259\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 33687 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.276086807250977\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 82.39%, remaining_weights: 16.00%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5463797450065613\n",
      "Model Losses: 0.6763159036636353\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 33884 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.317047119140625\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 82.78%, remaining_weights: 15.47%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.45478639006614685\n",
      "Model Losses: 0.5369887948036194\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 34081 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.343564987182617\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 81.70%, remaining_weights: 16.04%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6706096529960632\n",
      "Model Losses: 0.7258363366127014\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 34278 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.385332107543945\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 84.91%, remaining_weights: 15.44%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.4172361493110657\n",
      "Model Losses: 0.5278269648551941\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 34475 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.41297435760498\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 80.09%, remaining_weights: 16.06%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5216536521911621\n",
      "Model Losses: 0.7441622614860535\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 34672 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.45528793334961\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 84.51%, remaining_weights: 15.42%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5054641366004944\n",
      "Model Losses: 0.5132499933242798\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 34869 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.48006820678711\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 78.89%, remaining_weights: 16.10%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5756096839904785\n",
      "Model Losses: 0.7716856002807617\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 35066 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.523674011230469\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 85.90%, remaining_weights: 15.40%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5090237855911255\n",
      "Model Losses: 0.5058899521827698\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 35263 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.548238754272461\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 77.76%, remaining_weights: 16.05%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7268654108047485\n",
      "Model Losses: 0.7838748097419739\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 35460 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.589679718017578\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 86.55%, remaining_weights: 15.35%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.40489548444747925\n",
      "Model Losses: 0.5038045048713684\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 35657 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.614469528198242\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 81.33%, remaining_weights: 16.12%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5156038999557495\n",
      "Model Losses: 0.8317482471466064\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 35854 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.6578950881958\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 87.01%, remaining_weights: 15.39%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.4088432192802429\n",
      "Model Losses: 0.5101653933525085\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 36051 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.682312965393066\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 75.37%, remaining_weights: 16.12%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6221429109573364\n",
      "Model Losses: 0.8769259452819824\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 36248 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.728163719177246\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 88.09%, remaining_weights: 15.37%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.38796985149383545\n",
      "Model Losses: 0.5067748427391052\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 36445 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.751859664916992\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 78.82%, remaining_weights: 16.16%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6342340111732483\n",
      "Model Losses: 0.9097233414649963\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 36642 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.79590129852295\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 88.58%, remaining_weights: 15.37%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.39217397570610046\n",
      "Model Losses: 0.5132806301116943\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 36839 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.819397926330566\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 78.92%, remaining_weights: 16.20%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6864989399909973\n",
      "Model Losses: 0.9308037161827087\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 37036 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.864542961120605\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 88.87%, remaining_weights: 15.37%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.4551733136177063\n",
      "Model Losses: 0.5246323943138123\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 37233 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.889451026916504\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 69.41%, remaining_weights: 16.17%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7824751734733582\n",
      "Model Losses: 0.9700127840042114\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 37430 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.935429573059082\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 88.49%, remaining_weights: 15.38%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.4758799970149994\n",
      "Model Losses: 0.5364329814910889\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 37627 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 13.961433410644531\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 75.80%, remaining_weights: 16.15%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7002801299095154\n",
      "Model Losses: 0.9702728390693665\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 37824 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 14.006175994873047\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 88.91%, remaining_weights: 15.34%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.4726520776748657\n",
      "Model Losses: 0.5370481014251709\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 38021 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 14.032086372375488\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 78.32%, remaining_weights: 16.03%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5530702471733093\n",
      "Model Losses: 0.9658921360969543\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 38218 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 14.077596664428711\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 88.86%, remaining_weights: 15.29%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.4578494131565094\n",
      "Model Losses: 0.5390682220458984\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 38415 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 14.10461711883545\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 68.08%, remaining_weights: 16.00%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.7119211554527283\n",
      "Model Losses: 0.9568769931793213\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 38612 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 14.148807525634766\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 88.93%, remaining_weights: 15.24%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.3707123398780823\n",
      "Model Losses: 0.5309962034225464\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 38809 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 14.175504684448242\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 75.08%, remaining_weights: 16.04%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6379596590995789\n",
      "Model Losses: 1.0183403491973877\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 39006 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 14.222493171691895\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 89.20%, remaining_weights: 15.25%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.4110717177391052\n",
      "Model Losses: 0.5355037450790405\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 39203 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 14.25048828125\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 76.01%, remaining_weights: 15.89%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.6771532297134399\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 39400 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 89.57%, remaining_weights: 13.62%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.3562838137149811\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 39597 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 83.60%, remaining_weights: 12.73%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.5254791378974915\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 39794 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 91.32%, remaining_weights: 12.03%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.3951106369495392\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 39991 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 87.32%, remaining_weights: 11.70%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.3389225900173187\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 40188 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 92.30%, remaining_weights: 11.25%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.31215453147888184\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 40385 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 88.78%, remaining_weights: 11.07%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.3832609951496124\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 40582 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 93.03%, remaining_weights: 10.75%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.2965402901172638\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 40779 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 91.36%, remaining_weights: 10.64%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.31572791934013367\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 40976 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 93.76%, remaining_weights: 10.37%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.29665327072143555\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 41173 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 91.10%, remaining_weights: 10.30%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.33288195729255676\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 41370 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 94.23%, remaining_weights: 10.07%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.30373185873031616\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 41567 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 91.99%, remaining_weights: 10.02%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.301017165184021\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 41764 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 94.51%, remaining_weights: 9.82%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.2629193961620331\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 41961 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 94.10%, remaining_weights: 9.79%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.27343422174453735\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 42158 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 94.76%, remaining_weights: 9.61%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.22131098806858063\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 42355 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 94.23%, remaining_weights: 9.59%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.18990670144557953\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 42552 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 95.08%, remaining_weights: 9.43%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.2618649899959564\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 42749 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 94.76%, remaining_weights: 9.41%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.2475786656141281\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 42946 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 95.17%, remaining_weights: 9.27%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.25903773307800293\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 43143 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 95.66%, remaining_weights: 9.26%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.13716363906860352\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 43340 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 95.24%, remaining_weights: 9.13%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.23142682015895844\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 43537 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 95.97%, remaining_weights: 9.12%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.1936032772064209\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 43734 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 95.03%, remaining_weights: 9.00%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.24208959937095642\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 43931 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 96.20%, remaining_weights: 8.99%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.24695181846618652\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 44128 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 95.23%, remaining_weights: 8.88%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.18098029494285583\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 44325 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 96.44%, remaining_weights: 8.88%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.14406698942184448\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 44522 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 95.59%, remaining_weights: 8.78%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.2342434823513031\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 44719 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 96.71%, remaining_weights: 8.77%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.15558241307735443\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 44916 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 95.48%, remaining_weights: 8.68%\n",
      "\n",
      " ---- Checking Loss values ----\n",
      "Loss: 0.21180929243564606\n",
      "Model Losses: 0.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Checking Gradients for lmbda at Epoch 45113 ---\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: 0.0\n",
      "Layer: conv1.pruning_layer.constraint_layer.module, Gradient: None\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 96.97%, remaining_weights: 8.67%\n"
     ]
    }
   ],
   "source": [
    "from pquant import iterative_train\n",
    "\"\"\"\n",
    "Inputs to train_resnet we defined previously are:\n",
    "          model, trainloader, device, loss_func, epoch, optimizer, scheduler, **kwargs\n",
    "\"\"\"\n",
    "\n",
    "trained_model = iterative_train(model = model, \n",
    "                                config = config, \n",
    "                                train_func = train_resnet, \n",
    "                                valid_func = validate_resnet, \n",
    "                                trainloader = train_loader, \n",
    "                                testloader = val_loader, \n",
    "                                device = device, \n",
    "                                loss_func = loss_function,\n",
    "                                optimizer = optimizer, \n",
    "                                scheduler = scheduler\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4cb0eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv1.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm/equality_constraint/equality_constraint_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer1.0.conv1.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_1/equality_constraint_1/equality_constraint_1_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer1.0.conv2.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_2/equality_constraint_2/equality_constraint_2_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer1.1.conv1.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_3/equality_constraint_3/equality_constraint_3_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer1.1.conv2.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_4/equality_constraint_4/equality_constraint_4_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer2.0.conv1.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_5/equality_constraint_5/equality_constraint_5_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer2.0.conv2.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_6/equality_constraint_6/equality_constraint_6_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer2.0.downsample.0.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_7/equality_constraint_7/equality_constraint_7_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer2.1.conv1.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_8/equality_constraint_8/equality_constraint_8_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer2.1.conv2.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_9/equality_constraint_9/equality_constraint_9_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer3.0.conv1.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_10/equality_constraint_10/equality_constraint_10_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer3.0.conv2.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_11/equality_constraint_11/equality_constraint_11_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer3.0.downsample.0.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_12/equality_constraint_12/equality_constraint_12_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer3.1.conv1.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_13/equality_constraint_13/equality_constraint_13_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer3.1.conv2.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_14/equality_constraint_14/equality_constraint_14_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer4.0.conv1.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_15/equality_constraint_15/equality_constraint_15_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer4.0.conv2.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_16/equality_constraint_16/equality_constraint_16_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer4.0.downsample.0.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_17/equality_constraint_17/equality_constraint_17_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer4.1.conv1.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_18/equality_constraint_18/equality_constraint_18_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: layer4.1.conv2.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_19/equality_constraint_19/equality_constraint_19_lmbda, shape=(), dtype=float32, value=0.0>\n",
      "Layer: fc.pruning_layer.constraint_layer.module, lmbda: <Variable path=mdmm_20/equality_constraint_20/equality_constraint_20_lmbda, shape=(), dtype=float32, value=0.0>\n"
     ]
    }
   ],
   "source": [
    "#print layers and lmbda weights in the model\n",
    "\n",
    "for name, layer in model.named_modules():\n",
    "    if hasattr(layer, \"lmbda\"):\n",
    "        print(f\"Layer: {name}, lmbda: {layer.lmbda}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8994c123-92ad-4815-9217-c2dca2f80a6b",
   "metadata": {},
   "source": [
    "We see from that with PDP, the number of weights goes down during training, until it reaches the target sparsity (sparsity of 80%, or ~20% remaining weights). The function that calculates the remaining weights feeds the weights through the quantizer and pruning method, and calculates the ratio between non-zero weights and all weights. However, since PDP uses a soft mask during training, the percentage of remaining weights seems to go down rather noisily (can even drop from 80% to ~20% remaining weights). The algorithm actually increases the sparsity linearly.\n",
    "During fine-tuning the mask is fixed, and turned into a mask of 0s and 1s by a simple rounding operation, so the remaining weights stay the same during each epoch.\n",
    "\n",
    "In the original paper for PDP there was no fine-tuning after the creation of the final hard mask. We have added fine-tuning here as an option that can be turned off by simply setting ```fine_tuning_epochs``` to 0 in the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "678209db-91ad-4090-9480-76f6061fdf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_869604/4156412274.py:29: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax[0].set_yticklabels(new_ytick)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pquant import remove_pruning_from_model\n",
    "import matplotlib.pyplot as plt\n",
    "# Remove compression layers, leaves Quantized activations in place\n",
    "model = remove_pruning_from_model(trained_model, config)\n",
    "\n",
    "# Plot remaining weights\n",
    "names = []\n",
    "remaining = []\n",
    "total_w = []\n",
    "nonzeros = []\n",
    "for n, m in trained_model.named_modules():\n",
    "    if isinstance(m, (torch.nn.Conv1d, torch.nn.Conv2d, torch.nn.Linear)):\n",
    "        names.append(n)\n",
    "        nonzero = np.count_nonzero(m.weight.detach().cpu())\n",
    "        remaining_pct = nonzero / m.weight.numel()\n",
    "        remaining.append(remaining_pct)\n",
    "        total_w.append(m.weight.numel())\n",
    "        nonzeros.append(nonzero)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].bar(range(len(names)), remaining)\n",
    "ax[0].set_xticks(range(len(names)))\n",
    "ax[0].set_xticklabels(names)\n",
    "ax[0].tick_params(axis='x', labelrotation=270)\n",
    "new_ytick = []\n",
    "for i in ax[0].get_yticklabels():\n",
    "    ytick = f\"{float(i.get_text()) * 100}%\"\n",
    "    new_ytick.append(ytick)\n",
    "ax[0].set_yticklabels(new_ytick)\n",
    "ax[0].title.set_text(\"Remaining weights per layer\")\n",
    "\n",
    "ax[1].bar(range(len(nonzeros)), total_w, color=\"lightcoral\", label=\"total weights\")\n",
    "ax[1].bar(range(len(nonzeros)), nonzeros, color=\"steelblue\", label=\"nonzero weights\")\n",
    "ax[1].set_xticks(range(len(names)))\n",
    "ax[1].set_xticklabels(names)\n",
    "ax[1].tick_params(axis='x', labelrotation=270)\n",
    "ax[1].title.set_text(\"Weights per layer\")\n",
    "ax[1].legend()\n",
    "ax[1].set_yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98f0f07-4f01-40d8-a162-8778ec310b9a",
   "metadata": {},
   "source": [
    "## Custom config from existing config\n",
    "Using the ```pquant/configs/config_pdp.yaml``` as base, let's customize the quantization and pruning scheme. \n",
    "\n",
    "The function we use will go through the model's layers and do the following: \n",
    "\n",
    "Quantization:\n",
    "\n",
    "        1. Looks for the names of convolutional and linear layers, as well as names of the activations (layer type activations and functional types)\n",
    "        2. Adds the name of the layer to the layer_specific list, along with a default quantization scheme of 0 and 7 for weight and bias (if bias is not None)\n",
    "\n",
    "Pruning: \n",
    "\n",
    "        1. Looks for convolutional and linear layers and adds their name to the disable_pruning_for_layers list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62cc068a-4e3b-4e61-8c23-2b8ba37adcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/depot/cms/conda_envs/das214/pquant-gpu-env/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pruning_parameters': {'disable_pruning_for_layers': ['conv1',\n",
       "   'layer1.0.conv1',\n",
       "   'layer1.0.conv2',\n",
       "   'layer1.1.conv1',\n",
       "   'layer1.1.conv2',\n",
       "   'layer2.0.conv1',\n",
       "   'layer2.0.conv2',\n",
       "   'layer2.0.downsample.0',\n",
       "   'layer2.1.conv1',\n",
       "   'layer2.1.conv2',\n",
       "   'layer3.0.conv1',\n",
       "   'layer3.0.conv2',\n",
       "   'layer3.0.downsample.0',\n",
       "   'layer3.1.conv1',\n",
       "   'layer3.1.conv2',\n",
       "   'layer4.0.conv1',\n",
       "   'layer4.0.conv2',\n",
       "   'layer4.0.downsample.0',\n",
       "   'layer4.1.conv1',\n",
       "   'layer4.1.conv2',\n",
       "   'fc'],\n",
       "  'enable_pruning': True,\n",
       "  'epsilon': 0.015,\n",
       "  'pruning_method': 'pdp',\n",
       "  'sparsity': 0.8,\n",
       "  'temperature': 1e-05,\n",
       "  'threshold_decay': 0.0,\n",
       "  'structured_pruning': False},\n",
       " 'quantization_parameters': {'default_integer_bits': 0.0,\n",
       "  'default_fractional_bits': 7.0,\n",
       "  'enable_quantization': True,\n",
       "  'hgq_gamma': 0.0003,\n",
       "  'hgq_heterogeneous': True,\n",
       "  'layer_specific': {'conv1': {'weight': {'integer_bits': 0,\n",
       "     'fractional_bits': 7}},\n",
       "   'relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer1.0.conv1': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer1.0.relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer1.0.conv2': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer1.1.conv1': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer1.1.relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer1.1.conv2': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer2.0.conv1': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer2.0.relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer2.0.conv2': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer2.0.downsample.0': {'weight': {'integer_bits': 0,\n",
       "     'fractional_bits': 7}},\n",
       "   'layer2.1.conv1': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer2.1.relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer2.1.conv2': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer3.0.conv1': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer3.0.relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer3.0.conv2': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer3.0.downsample.0': {'weight': {'integer_bits': 0,\n",
       "     'fractional_bits': 7}},\n",
       "   'layer3.1.conv1': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer3.1.relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer3.1.conv2': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer4.0.conv1': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer4.0.relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer4.0.conv2': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer4.0.downsample.0': {'weight': {'integer_bits': 0,\n",
       "     'fractional_bits': 7}},\n",
       "   'layer4.1.conv1': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'layer4.1.relu': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "   'layer4.1.conv2': {'weight': {'integer_bits': 0, 'fractional_bits': 7}},\n",
       "   'fc': {'weight': {'integer_bits': 0, 'fractional_bits': 7},\n",
       "    'bias': {'integer_bits': 0, 'fractional_bits': 7}}},\n",
       "  'use_high_granularity_quantization': False,\n",
       "  'use_real_tanh': False,\n",
       "  'use_symmetric_quantization': False},\n",
       " 'training_parameters': {'epochs': 100,\n",
       "  'fine_tuning_epochs': 20,\n",
       "  'pretraining_epochs': 20,\n",
       "  'pruning_first': False,\n",
       "  'rewind': 'never',\n",
       "  'rounds': 1,\n",
       "  'save_weights_epoch': -1},\n",
       " 'batch_size': 256,\n",
       " 'cosine_tmax': 200,\n",
       " 'gamma': 0.1,\n",
       " 'l2_decay': 0.0001,\n",
       " 'label_smoothing': 0.0,\n",
       " 'lr': 0.01,\n",
       " 'lr_schedule': 'cosine',\n",
       " 'milestones': [-1, -1],\n",
       " 'momentum': 0.9,\n",
       " 'optimizer': 'sgd',\n",
       " 'plot_frequency': 100}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base config\n",
    "pruning_method = \"pdp\"\n",
    "config = get_default_config(pruning_method)\n",
    "model = torchvision.models.resnet18()\n",
    "\n",
    "\n",
    "from pquant import add_default_layer_quantization_pruning_to_config\n",
    "config = add_default_layer_quantization_pruning_to_config(model, config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cdfe45b-1432-4cec-a3dd-b46f837beb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save config\n",
    "from pquant.core.utils import write_config_to_yaml\n",
    "write_config_to_yaml(config, \"prune_quantize_example.yaml\", sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdb7669-ea71-4e86-b128-e313e83fbc96",
   "metadata": {},
   "source": [
    "Now that we have the custom config, it is up to us to modify the quantization bits for each layer that will not use the default value. If a layer uses the default value it can be removed from the ```layer_specific``` list.\n",
    "\n",
    "For pruning, leave those layers to the ```disable_pruning_for_layers``` list that will not be pruned, others need to be removed from the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742e0b00-220d-47a7-9774-af694f0afe1f",
   "metadata": {},
   "source": [
    "## About replacing layers and activations\n",
    "Layers that can currently be compressed: ```nn.Conv1d, nn.Conv2d, nn.Linear```.\n",
    "\n",
    "Activations that can currently be automatically be replaced with a quantized variant: ```nn.ReLU, nn.Tanh```. The activations are replaced by a quantized variant, found in ```pquant.core.activations_quantizer.py```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baece7d0-e23a-4e31-ba1e-1cf61cb05356",
   "metadata": {},
   "source": [
    "## More about activations\n",
    "If using layer type activations, note that if you want to keep the fine-grained control over the quantization of the activation, reusing an activation layer can cause problems, as all activations will use the quantization bits set for that particular layer. To avoid this, use a separate ```nn.Tanh``` / ```nn.ReLU``` for each activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd524cd-0145-4001-9ede-1b85e56171ff",
   "metadata": {},
   "source": [
    "## HGQ\n",
    "To use HGQ, enable it in the config: `config[\"quantization_parameters\"][\"use_high_granularity_quantization\"] = True`. Other relevant parameters to tune are `config[\"quantization_parameters\"][\"default_integer_bits\"]`, `config[\"quantization_parameters\"][\"default_fractional_bits\"]`, `config[\"quantization_parameters\"][\"hgq_gamma\"]`.\n",
    "When using HGQ, we advice using Adam instead of SGD as an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aadafd9-f0df-473c-84de-2c2a72148ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473019d7-502c-44b5-bf06-612b857756c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pquant-gpu-env]",
   "language": "python",
   "name": "conda-env-pquant-gpu-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
