{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27197caf-85a2-48b7-af76-a5ff943408ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-12 04:36:27.379145: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752287787.398239 3044776 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752287787.404062 3044776 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752287787.419402 3044776 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752287787.419433 3044776 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752287787.419435 3044776 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752287787.419437 3044776 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-12 04:36:27.424761: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras\n",
    "keras.backend.set_image_data_format(\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e520e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pquant\n",
      "smartpixels\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.chdir(\"/home/das214/PQuant/mdmm_dev/src\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for f in os.listdir(os.getcwd()):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71c59739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_file_size: 80\n",
      "val_file_size: 20\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m val_file_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(dataset_test_dir))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_file_size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_file_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mval_file_size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_file_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msmartpixels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDG\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mOptimizedDataGenerator_v2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OptimizedDataGenerator\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msmartpixels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmaxNLL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m custom_loss\n",
      "File \u001b[0;32m~/PQuant/mdmm_dev/src/smartpixels/DG/OptimizedDataGenerator_v2.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mqkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quantized_bits\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mOptimizedDataGenerator\u001b[39;00m(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     24\u001b[0m             dataset_base_dir: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m             batch_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     47\u001b[0m             ):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "dataset_base_dir = \"/depot/cms/users/das214/datasets/dataset_3sr/dataset_3sr_16x16_50x12P5_parquets/contained\"\n",
    "tfrecords_base_dir = os.path.join(dataset_base_dir, \"TFR_files\", \"2t\")\n",
    "\n",
    "dataset_train_dir = os.path.join(dataset_base_dir, \"train\")\n",
    "dataset_test_dir = os.path.join(dataset_base_dir, \"test\")\n",
    "tfrecords_dir_train = os.path.join(tfrecords_base_dir, \"TFR_train\")\n",
    "tfrecords_dir_val   = os.path.join(tfrecords_base_dir, \"TFR_val\")\n",
    "\n",
    "train_file_size = len(os.listdir(dataset_train_dir))\n",
    "val_file_size = len(os.listdir(dataset_test_dir))\n",
    "print(f\"train_file_size: {train_file_size}\\nval_file_size: {val_file_size}\")\n",
    "\n",
    "from smartpixels.DG.OptimizedDataGenerator_v2 import OptimizedDataGenerator\n",
    "from smartpixels.losses.maxNLL import custom_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141bfb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = OptimizedDataGenerator(\n",
    "    load_from_tfrecords_dir= tfrecords_dir_val,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    quantize=False,\n",
    ")\n",
    "\n",
    "train_loader = OptimizedDataGenerator(\n",
    "    load_from_tfrecords_dir = tfrecords_dir_train,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    quantize=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e06ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17959028",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CreateModel(shape = (16,16,2), \n",
    "                  n_filters=5, kernel_size=3,\n",
    "                  pool_size=3, \n",
    "                  hidden=10,\n",
    "                  output = 14)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dccb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Nadam(learning_rate=1e-3, clipnorm=1.0),\n",
    "#     loss=custom_loss,\n",
    "# )\n",
    "# history = model.fit(\n",
    "#         x=train_loader,\n",
    "#         validation_data=val_loader,\n",
    "#         epochs=5,\n",
    "#         shuffle=False,\n",
    "#         verbose=1\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cd71c9-86b2-4911-aa71-bd18b1e75aa1",
   "metadata": {},
   "source": [
    "## Add pruning and quantization\n",
    "To add pruning and quantization, we need a config file that defines how to do that. Let's load a config file from `pquant/configs/`. <br/>\n",
    "The training function we use later will add the pruning layers and quantized activations automatically using this config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec145f1-502c-4fd0-84ed-e87b84a27374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pquant import get_default_config\n",
    "from IPython.display import JSON\n",
    "\n",
    "# pruning_methods: \"autosparse, cl, cs, dst, pdp, wanda, mdmm\"\n",
    "pruning_method = \"mdmm\"\n",
    "config = get_default_config(pruning_method)\n",
    "JSON(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef3115-2f3d-43e1-a199-4a19d667f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace layers with compressed layers\n",
    "from pquant import add_compression_layers\n",
    "input_shape = (1, 16, 16, 2)\n",
    "\n",
    "model = add_compression_layers(model, config, input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251515c3-00ac-4110-b8d8-a8c9100f6e6b",
   "metadata": {},
   "source": [
    "## Create data set\n",
    "#### Let's create the data loader and the training and validation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5915162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantizers.fixed_point.fixed_point_ops import get_fixed_quantizer\n",
    "# Set up input quantizer\n",
    "quantizer = get_fixed_quantizer(overflow_mode=\"SAT\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from pquant import get_layer_keep_ratio, get_model_losses\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, inputs, logits, optimizer: keras.optimizers.Optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(inputs, training=True)\n",
    "        loss = custom_loss(logits, outputs)\n",
    "        # loss += get_model_losses(model, losses=keras.ops.convert_to_tensor(0.))\n",
    "        if model.losses:\n",
    "            loss += tf.add_n(model.losses)\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def valid_step(model, inputs, logits):\n",
    "    outputs = model(inputs, training=False)\n",
    "    loss = custom_loss(logits, outputs)\n",
    "    # loss += get_model_losses(model, losses=keras.ops.convert_to_tensor(0.))\n",
    "    if model.losses:\n",
    "            loss += tf.add_n(model.losses)\n",
    "    return loss\n",
    "\n",
    "def train_smart_pixels_tf(model, epoch, trainloader, optimizer: keras.optimizers.Optimizer, *args, **kwargs):\n",
    "    for batch_idx in tqdm(range(len(trainloader))):\n",
    "        inputs, logits = trainloader[batch_idx]\n",
    "        loss = train_step(model, inputs, logits, optimizer)\n",
    "        \n",
    "def validate_smart_pixels_tf(model, epoch, testloader, *args, **kwargs):\n",
    "    total_loss = 0.0\n",
    "    for batch_idx in tqdm(range(len(testloader))):\n",
    "        inputs, logits = testloader[batch_idx]\n",
    "        loss = valid_step(model, inputs, logits)\n",
    "        total_loss += loss\n",
    "        \n",
    "    ratio = get_layer_keep_ratio(model)\n",
    "    print(f'NLL+mdmm_loss: {total_loss/testloader.__len__():.2f}, remaining_weights: {ratio * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d28865b-afdb-4773-be30-717486d9786a",
   "metadata": {},
   "source": [
    "## Create loss function, scheduler and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e0d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=config[\"lr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850c23a-2abc-4904-9c69-859492b450a8",
   "metadata": {},
   "source": [
    "## Train model\n",
    "Training time. We use the train_compressed_model function from pquant to train. We need to provide some parameters such as training and validation functions, their input parameters, the model and the config file. The function automatically adds pruning layers and replaces activations with a quantized variant, trains the model, and removes the pruning layers after training is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520441a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "        if \"CompressedLayer\" in layer.__class__.__name__ and hasattr(layer, 'pruning_layer'):\n",
    "            pruning_layer = layer.pruning_layer # This is your MDMM instance\n",
    "            \n",
    "            # Check if the MDMM instance has the constraint_layer\n",
    "            if hasattr(pruning_layer, 'constraint_layer'):\n",
    "                constraint = pruning_layer.constraint_layer\n",
    "                \n",
    "                # Finally, check for 'lmbda' on the constraint layer\n",
    "                if hasattr(constraint, 'lmbda'):\n",
    "                    print(f\"  Layer: {layer.name}, Lambda Value: {constraint.lmbda.numpy():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74500380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f2414c-1f4d-4a30-a143-920497e60ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pquant import iterative_train\n",
    "\"\"\"\n",
    "Inputs to train_resnet we defined previously are:\n",
    "          model, trainloader, device, loss_func, epoch, optimizer, scheduler, **kwargs\n",
    "\"\"\"\n",
    "\n",
    "trained_model = iterative_train(model = model, \n",
    "                                config = config, \n",
    "                                train_func = train_smart_pixels_tf, \n",
    "                                valid_func = validate_smart_pixels_tf, \n",
    "                                trainloader = train_loader, \n",
    "                                testloader = val_loader, \n",
    "                                device = None, \n",
    "                                loss_func = custom_loss,\n",
    "                                optimizer = optimizer, \n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbfbc58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d696db81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pquant-gpu-env]",
   "language": "python",
   "name": "conda-env-pquant-gpu-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
